{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.metrics import accuracy_score\n\n# Load the test dataset\ndf = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv')  # Make sure to update the path to your dataset location\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T14:47:37.441239Z","iopub.execute_input":"2024-04-05T14:47:37.441903Z","iopub.status.idle":"2024-04-05T14:47:37.462284Z","shell.execute_reply.started":"2024-04-05T14:47:37.441871Z","shell.execute_reply":"2024-04-05T14:47:37.461451Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:47:37.463700Z","iopub.execute_input":"2024-04-05T14:47:37.464003Z","iopub.status.idle":"2024-04-05T14:47:37.475743Z","shell.execute_reply.started":"2024-04-05T14:47:37.463968Z","shell.execute_reply":"2024-04-05T14:47:37.474925Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                    uid  \\\n0  4aae63a8-fcf7-406c-a2f3-50c31c5934a9   \n1  c577b92c-78fb-4e1d-ae1d-34133609c142   \n2  26936cd9-1a5a-4a2b-9fca-899d61880ca0   \n3  cd977941-273b-4748-a5d2-6c7234a2a302   \n4  1a9eae8f-27d9-47ba-80b8-7d1402ee524a   \n\n                                             premise  \\\n0  Ernest Jones is a British jeweller and watchma...   \n1  Old Trafford is a football stadium in Old Traf...   \n2  Magnus is a Belgian joint dance project of Tom...   \n3  Shadowboxer is a 2005 crime thriller film dire...   \n4  Takaaki Kajita (梶田 隆章 , Kajita Takaaki ) is a ...   \n\n                                          hypothesis  label  \\\n0  The first Ernest Jones store was opened on the...      0   \n1  There are only 10 larger football stadiums in ...      0   \n2  \"The body gave you everything\" album was not r...      0   \n3  Shadowboxer was written and directed by Lee Da...      1   \n4  Arthur B. McDonald is a Japanese physicist, kn...      2   \n\n                                              reason  \n0  The first store was opened in London, which is...  \n1  The text says that it is the 11th largest foot...  \n2  it was released on March 29, 2004. \"not this b...  \n3  It is not know who wrote the Shadowboxer. The ...  \n4     Arthur B. McDonald is Canadian in the context.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>label</th>\n      <th>reason</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4aae63a8-fcf7-406c-a2f3-50c31c5934a9</td>\n      <td>Ernest Jones is a British jeweller and watchma...</td>\n      <td>The first Ernest Jones store was opened on the...</td>\n      <td>0</td>\n      <td>The first store was opened in London, which is...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c577b92c-78fb-4e1d-ae1d-34133609c142</td>\n      <td>Old Trafford is a football stadium in Old Traf...</td>\n      <td>There are only 10 larger football stadiums in ...</td>\n      <td>0</td>\n      <td>The text says that it is the 11th largest foot...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26936cd9-1a5a-4a2b-9fca-899d61880ca0</td>\n      <td>Magnus is a Belgian joint dance project of Tom...</td>\n      <td>\"The body gave you everything\" album was not r...</td>\n      <td>0</td>\n      <td>it was released on March 29, 2004. \"not this b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cd977941-273b-4748-a5d2-6c7234a2a302</td>\n      <td>Shadowboxer is a 2005 crime thriller film dire...</td>\n      <td>Shadowboxer was written and directed by Lee Da...</td>\n      <td>1</td>\n      <td>It is not know who wrote the Shadowboxer. The ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1a9eae8f-27d9-47ba-80b8-7d1402ee524a</td>\n      <td>Takaaki Kajita (梶田 隆章 , Kajita Takaaki ) is a ...</td>\n      <td>Arthur B. McDonald is a Japanese physicist, kn...</td>\n      <td>2</td>\n      <td>Arthur B. McDonald is Canadian in the context.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:47:37.477070Z","iopub.execute_input":"2024-04-05T14:47:37.477859Z","iopub.status.idle":"2024-04-05T14:47:37.491102Z","shell.execute_reply.started":"2024-04-05T14:47:37.477834Z","shell.execute_reply":"2024-04-05T14:47:37.490245Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   uid         1000 non-null   object\n 1   premise     1000 non-null   object\n 2   hypothesis  1000 non-null   object\n 3   label       1000 non-null   int64 \n 4   reason      1000 non-null   object\ndtypes: int64(1), object(4)\nmemory usage: 39.2+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:47:37.493735Z","iopub.execute_input":"2024-04-05T14:47:37.494097Z","iopub.status.idle":"2024-04-05T14:47:49.647624Z","shell.execute_reply.started":"2024-04-05T14:47:37.494064Z","shell.execute_reply":"2024-04-05T14:47:49.646580Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.10.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.38.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.21.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForSeq2SeqLM\n\nconfig = PeftConfig.from_pretrained(\"lorahub/flan_t5_large-anli_r1\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\nmodel = PeftModel.from_pretrained(model, \"lorahub/flan_t5_large-anli_r1\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:47:49.649026Z","iopub.execute_input":"2024-04-05T14:47:49.649359Z","iopub.status.idle":"2024-04-05T14:47:54.082707Z","shell.execute_reply.started":"2024-04-05T14:47:49.649329Z","shell.execute_reply":"2024-04-05T14:47:54.081868Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"pip install tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:47:54.083966Z","iopub.execute_input":"2024-04-05T14:47:54.084398Z","iopub.status.idle":"2024-04-05T14:48:06.216913Z","shell.execute_reply.started":"2024-04-05T14:47:54.084368Z","shell.execute_reply":"2024-04-05T14:48:06.215788Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the custom dataset\nclass ANLIDataset(Dataset):\n    def __init__(self, dataframe):\n        self.dataframe = dataframe\n        self.label_map = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        item = self.dataframe.iloc[idx]\n        premise = item['premise']\n        hypothesis = item['hypothesis']\n        reason = item['reason']\n        label = self.label_map[item['label']]\n        # Format the input text in a way that's expected by the T5 model\n        input_sequence = f\"premise: {premise} hypothesis: {hypothesis} reason: {reason}\"\n        return input_sequence, label\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:48:06.218535Z","iopub.execute_input":"2024-04-05T14:48:06.218843Z","iopub.status.idle":"2024-04-05T14:48:06.226620Z","shell.execute_reply.started":"2024-04-05T14:48:06.218813Z","shell.execute_reply":"2024-04-05T14:48:06.225597Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"dataset = ANLIDataset(df)\n\n# DataLoader setup\nloader = DataLoader(dataset, batch_size=32, shuffle=False)  \n\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:48:06.227744Z","iopub.execute_input":"2024-04-05T14:48:06.228007Z","iopub.status.idle":"2024-04-05T14:48:07.061359Z","shell.execute_reply.started":"2024-04-05T14:48:06.227985Z","shell.execute_reply":"2024-04-05T14:48:07.060457Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): T5ForConditionalGeneration(\n      (shared): Embedding(32128, 1024)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (decoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n# Evaluation loop with tqdm\npredictions = []\nlabels = []\n\nfor batch in tqdm(loader, desc=\"Evaluating\"):\n    input_sequences, batch_labels = batch\n    # Tokenize the inputs. Adjust as per your tokenizer's requirement\n    inputs = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    \n    # Move tensors to the same device as model\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        # Forward pass through the model, specifying max_new_tokens\n        output_sequences = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            max_new_tokens=50  # Adjust as needed\n        )\n        # Decode the generated sequences to text\n        pred_texts = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in output_sequences]\n    predictions.extend(pred_texts)\n    labels.extend(batch_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:48:07.064449Z","iopub.execute_input":"2024-04-05T14:48:07.064762Z","iopub.status.idle":"2024-04-05T14:48:43.424114Z","shell.execute_reply.started":"2024-04-05T14:48:07.064738Z","shell.execute_reply":"2024-04-05T14:48:43.423262Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 32/32 [00:36<00:00,  1.14s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example snippet to debug predictions\nfor i, (pred, label) in enumerate(zip(predictions, labels)):\n    if i < 10:  # Just inspect the first few\n        print(f\"Prediction: {pred.strip().lower()}, Label: {label.strip().lower()}\")\n\n# This gives you a direct comparison for the first few predictions to see if there's a mismatch pattern.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:48:43.425331Z","iopub.execute_input":"2024-04-05T14:48:43.425690Z","iopub.status.idle":"2024-04-05T14:48:43.431575Z","shell.execute_reply.started":"2024-04-05T14:48:43.425657Z","shell.execute_reply":"2024-04-05T14:48:43.430632Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Prediction: yes, Label: entailment\nPrediction: yes, Label: entailment\nPrediction: yes, Label: entailment\nPrediction: no, Label: neutral\nPrediction: no, Label: contradiction\nPrediction: it's impossible to say, Label: neutral\nPrediction: no, Label: neutral\nPrediction: no, Label: contradiction\nPrediction: no, Label: neutral\nPrediction: yes, Label: contradiction\n","output_type":"stream"}]},{"cell_type":"code","source":"def map_prediction_to_label(prediction):\n    mapping = {\n        \"yes\": \"entailment\",\n        \"no\": \"contradiction\",\n        \"it's impossible to say\": \"neutral\"\n    }\n    return mapping.get(prediction.strip().lower(), \"unknown\")\n\nmapped_predictions = [map_prediction_to_label(pred) for pred in predictions]\n\n# Recalculate accuracy with the mapped predictions\ncorrect_predictions = sum(1 for mapped_pred, label in zip(mapped_predictions, labels) if mapped_pred == label.strip().lower())\naccuracy = correct_predictions / len(labels)\nprint(f\"Corrected Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:48:43.432656Z","iopub.execute_input":"2024-04-05T14:48:43.432960Z","iopub.status.idle":"2024-04-05T14:48:43.446303Z","shell.execute_reply.started":"2024-04-05T14:48:43.432930Z","shell.execute_reply":"2024-04-05T14:48:43.445432Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Corrected Accuracy: 0.75\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the test dataset\ndf_2 = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv')  # Make sure to update the path to your dataset location\n\n\ndataset = ANLIDataset(df_2)\n\n# DataLoader setup\nloader = DataLoader(dataset, batch_size=32, shuffle=False)  \n\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:51:34.778246Z","iopub.execute_input":"2024-04-05T14:51:34.778917Z","iopub.status.idle":"2024-04-05T14:51:34.854726Z","shell.execute_reply.started":"2024-04-05T14:51:34.778887Z","shell.execute_reply":"2024-04-05T14:51:34.853747Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): T5ForConditionalGeneration(\n      (shared): Embedding(32128, 1024)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (decoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n# Evaluation loop with tqdm\npredictions = []\nlabels = []\n\nfor batch in tqdm(loader, desc=\"Evaluating\"):\n    input_sequences, batch_labels = batch\n    # Tokenize the inputs. Adjust as per your tokenizer's requirement\n    inputs = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    \n    # Move tensors to the same device as model\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        # Forward pass through the model, specifying max_new_tokens\n        output_sequences = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            max_new_tokens=50  # Adjust as needed\n        )\n        # Decode the generated sequences to text\n        pred_texts = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in output_sequences]\n    predictions.extend(pred_texts)\n    labels.extend(batch_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:51:44.720333Z","iopub.execute_input":"2024-04-05T14:51:44.721102Z","iopub.status.idle":"2024-04-05T14:52:19.485935Z","shell.execute_reply.started":"2024-04-05T14:51:44.721070Z","shell.execute_reply":"2024-04-05T14:52:19.484988Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 32/32 [00:34<00:00,  1.09s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"def map_prediction_to_label(prediction):\n    mapping = {\n        \"yes\": \"entailment\",\n        \"no\": \"contradiction\",\n        \"it's impossible to say\": \"neutral\"\n    }\n    return mapping.get(prediction.strip().lower(), \"unknown\")\n\nmapped_predictions = [map_prediction_to_label(pred) for pred in predictions]\n\n# Recalculate accuracy with the mapped predictions\ncorrect_predictions = sum(1 for mapped_pred, label in zip(mapped_predictions, labels) if mapped_pred == label.strip().lower())\naccuracy = correct_predictions / len(labels)\nprint(f\"Corrected Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:52:22.345460Z","iopub.execute_input":"2024-04-05T14:52:22.346179Z","iopub.status.idle":"2024-04-05T14:52:22.354029Z","shell.execute_reply.started":"2024-04-05T14:52:22.346148Z","shell.execute_reply":"2024-04-05T14:52:22.353117Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Corrected Accuracy: 0.64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the test dataset\ndf_3 = pd.read_csv('/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv')  # Make sure to update the path to your dataset location\n\n\ndataset = ANLIDataset(df_3)\n\n# DataLoader setup\nloader = DataLoader(dataset, batch_size=32, shuffle=False)  \n\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:53:19.849446Z","iopub.execute_input":"2024-04-05T14:53:19.849900Z","iopub.status.idle":"2024-04-05T14:53:19.925537Z","shell.execute_reply.started":"2024-04-05T14:53:19.849859Z","shell.execute_reply":"2024-04-05T14:53:19.924627Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): T5ForConditionalGeneration(\n      (shared): Embedding(32128, 1024)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (decoder): T5Stack(\n        (embed_tokens): Embedding(32128, 1024)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                  (relative_attention_bias): Embedding(32, 16)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-23): 23 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (k): Linear(in_features=1024, out_features=1024, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=1024, out_features=16, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=16, out_features=1024, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                  )\n                  (o): Linear(in_features=1024, out_features=1024, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseGatedActDense(\n                  (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n                  (wo): Linear(in_features=2816, out_features=1024, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): NewGELUActivation()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n# Evaluation loop with tqdm\npredictions = []\nlabels = []\n\nfor batch in tqdm(loader, desc=\"Evaluating\"):\n    input_sequences, batch_labels = batch\n    # Tokenize the inputs. Adjust as per your tokenizer's requirement\n    inputs = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    \n    # Move tensors to the same device as model\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n\n    with torch.no_grad():\n        # Forward pass through the model, specifying max_new_tokens\n        output_sequences = model.generate(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            max_new_tokens=50  # Adjust as needed\n        )\n        # Decode the generated sequences to text\n        pred_texts = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in output_sequences]\n    predictions.extend(pred_texts)\n    labels.extend(batch_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:53:27.838063Z","iopub.execute_input":"2024-04-05T14:53:27.838430Z","iopub.status.idle":"2024-04-05T14:54:11.873564Z","shell.execute_reply.started":"2024-04-05T14:53:27.838400Z","shell.execute_reply":"2024-04-05T14:54:11.872655Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 38/38 [00:44<00:00,  1.16s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"def map_prediction_to_label(prediction):\n    mapping = {\n        \"yes\": \"entailment\",\n        \"no\": \"contradiction\",\n        \"it's impossible to say\": \"neutral\"\n    }\n    return mapping.get(prediction.strip().lower(), \"unknown\")\n\nmapped_predictions = [map_prediction_to_label(pred) for pred in predictions]\n\n# Recalculate accuracy with the mapped predictions\ncorrect_predictions = sum(1 for mapped_pred, label in zip(mapped_predictions, labels) if mapped_pred == label.strip().lower())\naccuracy = correct_predictions / len(labels)\nprint(f\"Corrected Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T14:54:15.164811Z","iopub.execute_input":"2024-04-05T14:54:15.165182Z","iopub.status.idle":"2024-04-05T14:54:15.173714Z","shell.execute_reply.started":"2024-04-05T14:54:15.165152Z","shell.execute_reply":"2024-04-05T14:54:15.172825Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Corrected Accuracy: 0.63\n","output_type":"stream"}]}]}