{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775},{"sourceId":8083662,"sourceType":"datasetVersion","datasetId":4771616},{"sourceId":8083668,"sourceType":"datasetVersion","datasetId":4771621},{"sourceId":8083678,"sourceType":"datasetVersion","datasetId":4771629},{"sourceId":8084913,"sourceType":"datasetVersion","datasetId":4772442}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the SNLI test data (including true labels)\nsnli_test_path = \"/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\nsnli_test_df = pd.read_csv(snli_test_path)\n\n# Define file paths for SNLI prediction files\nsnli_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_snli_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_snli_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_snli_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_snli = \"/kaggle/working/combined_snli_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_snli_df = pd.DataFrame(columns=columns)\n\nlabel_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n\n# Load and merge the predictions\nfor model, path in snli_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_snli_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_snli_df['True_Label'] = snli_test_df['gold_label'].map(label_mapping)\n\n# Convert True_Label to integer type\ncombined_snli_df['True_Label'] = combined_snli_df['True_Label'].astype('Int64')\n\n# Save the combined DataFrame to CSV\ncombined_snli_df.to_csv(output_csv_path_snli, index=False)\n\nprint(f\"Combined SNLI predictions with true labels saved to {output_csv_path_snli}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T20:29:14.095710Z","iopub.execute_input":"2024-04-14T20:29:14.096106Z","iopub.status.idle":"2024-04-14T20:29:14.380114Z","shell.execute_reply.started":"2024-04-14T20:29:14.096076Z","shell.execute_reply":"2024-04-14T20:29:14.379009Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Combined SNLI predictions with true labels saved to /kaggle/working/combined_snli_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.381753Z","iopub.execute_input":"2024-04-14T20:29:14.382049Z","iopub.status.idle":"2024-04-14T20:29:14.398636Z","shell.execute_reply.started":"2024-04-14T20:29:14.382024Z","shell.execute_reply":"2024-04-14T20:29:14.397690Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.034767         0.962592               0.002641   \n1            0.001921         0.319032               0.679047   \n2            0.998783         0.000764               0.000453   \n3            0.001001         0.997708               0.001291   \n4            0.001080         0.301363               0.697557   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.012451         0.927093               0.060457   \n1            0.752766         0.242251               0.004983   \n2            0.000254         0.004494               0.995253   \n3            0.005844         0.990736               0.003419   \n4            0.278348         0.718575               0.003076   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.008653        0.947434              0.043913           1  \n1           0.740332        0.256434              0.003235           0  \n2           0.004677        0.060481              0.934843           2  \n3           0.034056        0.956687              0.009257           1  \n4           0.498761        0.499270              0.001969           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_matched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_matched.csv\"\nmnli_matched_test_df = pd.read_csv(mnli_matched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_matched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_matched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_matched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_matched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_matched = \"/kaggle/working/combined_mnli_matched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_matched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_matched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_matched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_matched_df['True_Label'] = mnli_matched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_matched_df.to_csv(output_csv_path_mnli_matched, index=False)\n\nprint(f\"Combined MNLI-matched predictions with true labels saved to {output_csv_path_mnli_matched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.399695Z","iopub.execute_input":"2024-04-14T20:29:14.399975Z","iopub.status.idle":"2024-04-14T20:29:14.595898Z","shell.execute_reply.started":"2024-04-14T20:29:14.399951Z","shell.execute_reply":"2024-04-14T20:29:14.594965Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Combined MNLI-matched predictions with true labels saved to /kaggle/working/combined_mnli_matched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.597941Z","iopub.execute_input":"2024-04-14T20:29:14.598257Z","iopub.status.idle":"2024-04-14T20:29:14.613318Z","shell.execute_reply.started":"2024-04-14T20:29:14.598209Z","shell.execute_reply":"2024-04-14T20:29:14.612354Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.010844        0.983012              0.006144           1  \n1           0.005388        0.007536              0.987076           2  \n2           0.853862        0.143483              0.002655           0  \n3           0.004128        0.070757              0.925115           2  \n4           0.003864        0.029262              0.966875           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_mismatched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_mismatched.csv\"\nmnli_mismatched_test_df = pd.read_csv(mnli_mismatched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_mismatched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_mismatched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_mismatched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_mismatched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_mismatched = \"/kaggle/working/combined_mnli_mismatched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_mismatched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_mismatched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_mismatched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_mismatched_df['True_Label'] = mnli_mismatched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_mismatched_df.to_csv(output_csv_path_mnli_mismatched, index=False)\n\nprint(f\"Combined MNLI-mismatched predictions with true labels saved to {output_csv_path_mnli_mismatched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.614452Z","iopub.execute_input":"2024-04-14T20:29:14.614742Z","iopub.status.idle":"2024-04-14T20:29:14.805473Z","shell.execute_reply.started":"2024-04-14T20:29:14.614719Z","shell.execute_reply":"2024-04-14T20:29:14.804579Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Combined MNLI-mismatched predictions with true labels saved to /kaggle/working/combined_mnli_mismatched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_mismatched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.806630Z","iopub.execute_input":"2024-04-14T20:29:14.806879Z","iopub.status.idle":"2024-04-14T20:29:14.822109Z","shell.execute_reply.started":"2024-04-14T20:29:14.806858Z","shell.execute_reply":"2024-04-14T20:29:14.821072Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.999667         0.000160               0.000173   \n1            0.998119         0.000962               0.000919   \n2            0.000552         0.004809               0.994639   \n3            0.827653         0.171961               0.000386   \n4            0.000292         0.002875               0.996833   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.000068         0.000402               0.999529   \n1            0.000183         0.001511               0.998306   \n2            0.986062         0.012020               0.001918   \n3            0.000478         0.270953               0.728569   \n4            0.975167         0.021904               0.002929   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.000894        0.003787              0.995318           2  \n1           0.006421        0.010224              0.983355           2  \n2           0.975041        0.023354              0.001605           0  \n3           0.001722        0.796122              0.202156           2  \n4           0.965952        0.032748              0.001300           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nanli_r1_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv\"\nanli_r1_test_df = pd.read_csv(anli_r1_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nanli_r1_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r1_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r1_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r1_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r1 = \"/kaggle/working/combined_anli_r1_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r1_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r1_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r1_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r1_df['True_Label'] = anli_r1_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r1_df.to_csv(output_csv_path_anli_r1, index=False)\n\nprint(f\"Combined ANLI Round 1 predictions with true labels saved to {output_csv_path_anli_r1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.823323Z","iopub.execute_input":"2024-04-14T20:29:14.823617Z","iopub.status.idle":"2024-04-14T20:29:14.872035Z","shell.execute_reply.started":"2024-04-14T20:29:14.823583Z","shell.execute_reply":"2024-04-14T20:29:14.871086Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Combined ANLI Round 1 predictions with true labels saved to /kaggle/working/combined_anli_r1_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r1_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.873045Z","iopub.execute_input":"2024-04-14T20:29:14.873345Z","iopub.status.idle":"2024-04-14T20:29:14.888634Z","shell.execute_reply.started":"2024-04-14T20:29:14.873320Z","shell.execute_reply":"2024-04-14T20:29:14.887628Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.015388         0.976305               0.008307   \n1            0.224603         0.501549               0.273848   \n2            0.006642         0.976690               0.016669   \n3            0.966494         0.032235               0.001272   \n4            0.880736         0.028293               0.090971   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.996714         0.000376               0.002910   \n1            0.875720         0.000724               0.123556   \n2            0.999484         0.000330               0.000186   \n3            0.000686         0.998181               0.001133   \n4            0.000378         0.000197               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.322974        0.667628              0.009398           0  \n1           0.998526        0.000604              0.000869           0  \n2           0.783352        0.212241              0.004407           0  \n3           0.002134        0.989523              0.008343           1  \n4           0.023283        0.013253              0.963464           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015388</td>\n      <td>0.976305</td>\n      <td>0.008307</td>\n      <td>0.996714</td>\n      <td>0.000376</td>\n      <td>0.002910</td>\n      <td>0.322974</td>\n      <td>0.667628</td>\n      <td>0.009398</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224603</td>\n      <td>0.501549</td>\n      <td>0.273848</td>\n      <td>0.875720</td>\n      <td>0.000724</td>\n      <td>0.123556</td>\n      <td>0.998526</td>\n      <td>0.000604</td>\n      <td>0.000869</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006642</td>\n      <td>0.976690</td>\n      <td>0.016669</td>\n      <td>0.999484</td>\n      <td>0.000330</td>\n      <td>0.000186</td>\n      <td>0.783352</td>\n      <td>0.212241</td>\n      <td>0.004407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.966494</td>\n      <td>0.032235</td>\n      <td>0.001272</td>\n      <td>0.000686</td>\n      <td>0.998181</td>\n      <td>0.001133</td>\n      <td>0.002134</td>\n      <td>0.989523</td>\n      <td>0.008343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880736</td>\n      <td>0.028293</td>\n      <td>0.090971</td>\n      <td>0.000378</td>\n      <td>0.000197</td>\n      <td>0.999425</td>\n      <td>0.023283</td>\n      <td>0.013253</td>\n      <td>0.963464</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 2 test data (including true labels)\nanli_r2_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv\"\nanli_r2_test_df = pd.read_csv(anli_r2_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r2_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r2_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r2_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r2_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r2 = \"/kaggle/working/combined_anli_r2_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r2_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r2_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r2_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r2_df['True_Label'] = anli_r2_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r2_df.to_csv(output_csv_path_anli_r2, index=False)\n\nprint(f\"Combined ANLI Round 2 predictions with true labels saved to {output_csv_path_anli_r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.889904Z","iopub.execute_input":"2024-04-14T20:29:14.890558Z","iopub.status.idle":"2024-04-14T20:29:14.936953Z","shell.execute_reply.started":"2024-04-14T20:29:14.890528Z","shell.execute_reply":"2024-04-14T20:29:14.935999Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Combined ANLI Round 2 predictions with true labels saved to /kaggle/working/combined_anli_r2_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r2_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.941796Z","iopub.execute_input":"2024-04-14T20:29:14.942472Z","iopub.status.idle":"2024-04-14T20:29:14.957560Z","shell.execute_reply.started":"2024-04-14T20:29:14.942444Z","shell.execute_reply":"2024-04-14T20:29:14.956494Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.001309         0.029617               0.969075   \n1            0.724144         0.273676               0.002180   \n2            0.071604         0.917894               0.010503   \n3            0.066162         0.929179               0.004659   \n4            0.906199         0.089873               0.003928   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.999506         0.000264               0.000230   \n1            0.026951         0.054230               0.918819   \n2            0.001282         0.998108               0.000610   \n3            0.007091         0.992694               0.000215   \n4            0.006259         0.989432               0.004309   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.863365        0.133388              0.003246           0  \n1           0.072900        0.904344              0.022756           1  \n2           0.027402        0.972218              0.000380           0  \n3           0.632171        0.365194              0.002635           1  \n4           0.064109        0.234642              0.701249           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001309</td>\n      <td>0.029617</td>\n      <td>0.969075</td>\n      <td>0.999506</td>\n      <td>0.000264</td>\n      <td>0.000230</td>\n      <td>0.863365</td>\n      <td>0.133388</td>\n      <td>0.003246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.724144</td>\n      <td>0.273676</td>\n      <td>0.002180</td>\n      <td>0.026951</td>\n      <td>0.054230</td>\n      <td>0.918819</td>\n      <td>0.072900</td>\n      <td>0.904344</td>\n      <td>0.022756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071604</td>\n      <td>0.917894</td>\n      <td>0.010503</td>\n      <td>0.001282</td>\n      <td>0.998108</td>\n      <td>0.000610</td>\n      <td>0.027402</td>\n      <td>0.972218</td>\n      <td>0.000380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066162</td>\n      <td>0.929179</td>\n      <td>0.004659</td>\n      <td>0.007091</td>\n      <td>0.992694</td>\n      <td>0.000215</td>\n      <td>0.632171</td>\n      <td>0.365194</td>\n      <td>0.002635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.906199</td>\n      <td>0.089873</td>\n      <td>0.003928</td>\n      <td>0.006259</td>\n      <td>0.989432</td>\n      <td>0.004309</td>\n      <td>0.064109</td>\n      <td>0.234642</td>\n      <td>0.701249</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 3 test data (including true labels)\nanli_r3_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv\"\nanli_r3_test_df = pd.read_csv(anli_r3_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r3_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r3_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r3_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r3_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r3 = \"/kaggle/working/combined_anli_r3_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r3_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r3_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r3_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r3_df['True_Label'] = anli_r3_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r3_df.to_csv(output_csv_path_anli_r3, index=False)\n\nprint(f\"Combined ANLI Round 3 predictions with true labels saved to {output_csv_path_anli_r3}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:14.958394Z","iopub.execute_input":"2024-04-14T20:29:14.958700Z","iopub.status.idle":"2024-04-14T20:29:15.011867Z","shell.execute_reply.started":"2024-04-14T20:29:14.958676Z","shell.execute_reply":"2024-04-14T20:29:15.010925Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Combined ANLI Round 3 predictions with true labels saved to /kaggle/working/combined_anli_r3_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r3_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.013163Z","iopub.execute_input":"2024-04-14T20:29:15.013579Z","iopub.status.idle":"2024-04-14T20:29:15.029140Z","shell.execute_reply.started":"2024-04-14T20:29:15.013543Z","shell.execute_reply":"2024-04-14T20:29:15.028136Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005921         0.960529               0.033551   \n1            0.009586         0.934714               0.055700   \n2            0.003428         0.976393               0.020179   \n3            0.004633         0.023985               0.971382   \n4            0.017428         0.633695               0.348877   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.022959         0.976533               0.000509   \n1            0.999611         0.000205               0.000185   \n2            0.002020         0.997897               0.000083   \n3            0.974441         0.024459               0.001100   \n4            0.984416         0.011166               0.004419   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.001848        0.998084              0.000067           0  \n1           0.951772        0.048075              0.000153           0  \n2           0.001014        0.998984              0.000002           0  \n3           0.996749        0.000989              0.002262           0  \n4           0.000518        0.128416              0.871066           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values_anli1 = combined_anli_r1_df.isnull().sum()\n\nmissing_values_anli2 = combined_anli_r2_df.isnull().sum()\n\nmissing_values_anli3 = combined_anli_r3_df.isnull().sum()\n\nmissing_values_snli = combined_snli_df.isnull().sum()\n\nmissing_values_mnli_matched = combined_mnli_matched_df.isnull().sum()\n\nmissing_values_mnli_mismatched = combined_mnli_mismatched_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.030394Z","iopub.execute_input":"2024-04-14T20:29:15.030723Z","iopub.status.idle":"2024-04-14T20:29:15.044890Z","shell.execute_reply.started":"2024-04-14T20:29:15.030699Z","shell.execute_reply":"2024-04-14T20:29:15.043955Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"missing_values_anli1","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.046113Z","iopub.execute_input":"2024-04-14T20:29:15.046464Z","iopub.status.idle":"2024-04-14T20:29:15.057027Z","shell.execute_reply.started":"2024-04-14T20:29:15.046423Z","shell.execute_reply":"2024-04-14T20:29:15.056029Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli2","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.058192Z","iopub.execute_input":"2024-04-14T20:29:15.058534Z","iopub.status.idle":"2024-04-14T20:29:15.068693Z","shell.execute_reply.started":"2024-04-14T20:29:15.058499Z","shell.execute_reply":"2024-04-14T20:29:15.067840Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli3","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.070124Z","iopub.execute_input":"2024-04-14T20:29:15.070479Z","iopub.status.idle":"2024-04-14T20:29:15.081215Z","shell.execute_reply.started":"2024-04-14T20:29:15.070454Z","shell.execute_reply":"2024-04-14T20:29:15.080058Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_snli","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.082533Z","iopub.execute_input":"2024-04-14T20:29:15.082852Z","iopub.status.idle":"2024-04-14T20:29:15.092305Z","shell.execute_reply.started":"2024-04-14T20:29:15.082807Z","shell.execute_reply":"2024-04-14T20:29:15.091478Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment         0\nDeberta_Neutral            0\nDeberta_Contradiction      0\nRoberta_Entailment         0\nRoberta_Neutral            0\nRoberta_Contradiction      0\nAlbert_Entailment          0\nAlbert_Neutral             0\nAlbert_Contradiction       0\nTrue_Label               176\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.093306Z","iopub.execute_input":"2024-04-14T20:29:15.093606Z","iopub.status.idle":"2024-04-14T20:29:15.104357Z","shell.execute_reply.started":"2024-04-14T20:29:15.093582Z","shell.execute_reply":"2024-04-14T20:29:15.103577Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.105452Z","iopub.execute_input":"2024-04-14T20:29:15.105775Z","iopub.status.idle":"2024-04-14T20:29:15.116879Z","shell.execute_reply.started":"2024-04-14T20:29:15.105750Z","shell.execute_reply":"2024-04-14T20:29:15.115878Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"combined_snli_df.dropna(subset=['True_Label'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.117956Z","iopub.execute_input":"2024-04-14T20:29:15.118316Z","iopub.status.idle":"2024-04-14T20:29:15.128940Z","shell.execute_reply.started":"2024-04-14T20:29:15.118283Z","shell.execute_reply":"2024-04-14T20:29:15.128195Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Verify missing values again after removal\nmissing_values_snli_after_removal = combined_snli_df.isnull().sum()\nprint(missing_values_snli_after_removal)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.130022Z","iopub.execute_input":"2024-04-14T20:29:15.130344Z","iopub.status.idle":"2024-04-14T20:29:15.140354Z","shell.execute_reply.started":"2024-04-14T20:29:15.130318Z","shell.execute_reply":"2024-04-14T20:29:15.139251Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.141663Z","iopub.execute_input":"2024-04-14T20:29:15.141963Z","iopub.status.idle":"2024-04-14T20:29:15.154504Z","shell.execute_reply.started":"2024-04-14T20:29:15.141938Z","shell.execute_reply":"2024-04-14T20:29:15.153426Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9824 entries, 0 to 9999\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Deberta_Entailment     9824 non-null   float64\n 1   Deberta_Neutral        9824 non-null   float64\n 2   Deberta_Contradiction  9824 non-null   float64\n 3   Roberta_Entailment     9824 non-null   float64\n 4   Roberta_Neutral        9824 non-null   float64\n 5   Roberta_Contradiction  9824 non-null   float64\n 6   Albert_Entailment      9824 non-null   float64\n 7   Albert_Neutral         9824 non-null   float64\n 8   Albert_Contradiction   9824 non-null   float64\n 9   True_Label             9824 non-null   Int64  \ndtypes: Int64(1), float64(9)\nmemory usage: 853.8 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# Assuming 'combined_snli_df' is already loaded as described\n\n# Features and Labels\nX_snli = combined_snli_df.drop('True_Label', axis=1).values\ny_snli = combined_snli_df['True_Label'].values\n\n# Features and Labels\nX_mnli_matched = combined_mnli_matched_df.drop('True_Label', axis=1).values\ny_mnli_matched = combined_mnli_matched_df['True_Label'].values\n\n# Features and Labels\nX_mnli_mismatched = combined_mnli_mismatched_df.drop('True_Label', axis=1).values\ny_mnli_mismatched = combined_mnli_mismatched_df['True_Label'].values\n\n# Features and Labels\nX_anli_r1 = combined_anli_r1_df.drop('True_Label', axis=1).values\ny_anli_r1 = combined_anli_r1_df['True_Label'].values\n\n# Features and Labels\nX_anli_r2 = combined_anli_r2_df.drop('True_Label', axis=1).values\ny_anli_r2 = combined_anli_r2_df['True_Label'].values\n\n# Features and Labels\nX_anli_r3 = combined_anli_r3_df.drop('True_Label', axis=1).values\ny_anli_r3 = combined_anli_r3_df['True_Label'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.155767Z","iopub.execute_input":"2024-04-14T20:29:15.156148Z","iopub.status.idle":"2024-04-14T20:29:15.173874Z","shell.execute_reply.started":"2024-04-14T20:29:15.156103Z","shell.execute_reply":"2024-04-14T20:29:15.172849Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# One-hot encode labels\ny_encoded_snli = tf.keras.utils.to_categorical(y_snli)\n# One-hot encode labels\ny_encoded_mnli_matched = tf.keras.utils.to_categorical(y_mnli_matched)\n# One-hot encode labels\ny_encoded_mnli_mismatched = tf.keras.utils.to_categorical(y_mnli_mismatched)\n# One-hot encode labels\ny_encoded_anli_r1 = tf.keras.utils.to_categorical(y_anli_r1)\n# One-hot encode labels\ny_encoded_anli_r2 = tf.keras.utils.to_categorical(y_anli_r2)\n# One-hot encode labels\ny_encoded_anli_r3 = tf.keras.utils.to_categorical(y_anli_r3)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:29:15.174971Z","iopub.execute_input":"2024-04-14T20:29:15.175247Z","iopub.status.idle":"2024-04-14T20:29:15.182776Z","shell.execute_reply.started":"2024-04-14T20:29:15.175202Z","shell.execute_reply":"2024-04-14T20:29:15.181778Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import KFold\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\n\n\ndef create_model(input_shape, num_classes):\n    model = Sequential([\n        Input(shape=(input_shape,)),\n        Dense(512, activation='relu'),\n        Dropout(0.5),\n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\ndef train_and_evaluate_kfold(X, y,name, n_splits=5):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    all_scores = []\n\n    for train_index, val_index in kf.split(X):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        model = create_model(X_train.shape[1], y_train.shape[1])  # Adjust dimensions\n        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n        print(\"Training fold...\")\n        history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n                            validation_data=(X_val, y_val), callbacks=[early_stopping])\n\n        val_loss, val_accuracy = model.evaluate(X_val, y_val)\n        all_scores.append(val_accuracy)\n        print(f\"Validation accuracy: {val_accuracy * 100:.2f}%\")\n\n    average_accuracy = np.mean(all_scores)\n    print(f\"Average Validation Accuracy for {name}: {average_accuracy * 100:.2f}%\")\n    return average_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:30:54.586439Z","iopub.execute_input":"2024-04-14T20:30:54.586855Z","iopub.status.idle":"2024-04-14T20:30:54.600081Z","shell.execute_reply.started":"2024-04-14T20:30:54.586823Z","shell.execute_reply":"2024-04-14T20:30:54.599059Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# MNLI SNLI\ntrain_and_evaluate_kfold(X_snli, y_encoded_snli,'SNLI' )\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:30:57.178588Z","iopub.execute_input":"2024-04-14T20:30:57.178953Z","iopub.status.idle":"2024-04-14T20:32:01.539955Z","shell.execute_reply.started":"2024-04-14T20:30:57.178923Z","shell.execute_reply":"2024-04-14T20:32:01.538975Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8949 - loss: 0.3625 - val_accuracy: 0.9323 - val_loss: 0.2198\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2208 - val_accuracy: 0.9338 - val_loss: 0.2137\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2229 - val_accuracy: 0.9333 - val_loss: 0.2096\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2273 - val_accuracy: 0.9333 - val_loss: 0.2046\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9313 - loss: 0.2121 - val_accuracy: 0.9328 - val_loss: 0.2058\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2229 - val_accuracy: 0.9333 - val_loss: 0.2119\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9334 - loss: 0.2066 - val_accuracy: 0.9303 - val_loss: 0.2031\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2184 - val_accuracy: 0.9333 - val_loss: 0.2053\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2049 - val_accuracy: 0.9323 - val_loss: 0.2037\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2137 - val_accuracy: 0.9318 - val_loss: 0.1992\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.1931\nValidation accuracy: 93.18%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.8992 - loss: 0.3348 - val_accuracy: 0.9221 - val_loss: 0.2463\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9335 - loss: 0.2200 - val_accuracy: 0.9226 - val_loss: 0.2323\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9299 - loss: 0.2147 - val_accuracy: 0.9196 - val_loss: 0.2376\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2150 - val_accuracy: 0.9226 - val_loss: 0.2291\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.2001 - val_accuracy: 0.9226 - val_loss: 0.2268\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.2094 - val_accuracy: 0.9221 - val_loss: 0.2258\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.2117 - val_accuracy: 0.9201 - val_loss: 0.2328\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2007 - val_accuracy: 0.9211 - val_loss: 0.2291\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2058 - val_accuracy: 0.9216 - val_loss: 0.2279\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9245 - loss: 0.2197\nValidation accuracy: 92.21%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8950 - loss: 0.3593 - val_accuracy: 0.9293 - val_loss: 0.2232\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.2174 - val_accuracy: 0.9293 - val_loss: 0.2155\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2189 - val_accuracy: 0.9308 - val_loss: 0.2182\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2211 - val_accuracy: 0.9293 - val_loss: 0.2146\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2158 - val_accuracy: 0.9288 - val_loss: 0.2169\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2304 - val_accuracy: 0.9308 - val_loss: 0.2115\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.2223 - val_accuracy: 0.9272 - val_loss: 0.2098\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2387 - val_accuracy: 0.9282 - val_loss: 0.2140\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2207 - val_accuracy: 0.9282 - val_loss: 0.2101\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2034 - val_accuracy: 0.9298 - val_loss: 0.2118\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.2149\nValidation accuracy: 92.72%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.9055 - loss: 0.3402 - val_accuracy: 0.9318 - val_loss: 0.2079\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2319 - val_accuracy: 0.9313 - val_loss: 0.2095\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2272 - val_accuracy: 0.9323 - val_loss: 0.2099\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.2074 - val_accuracy: 0.9328 - val_loss: 0.2015\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2154 - val_accuracy: 0.9374 - val_loss: 0.2031\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2446 - val_accuracy: 0.9333 - val_loss: 0.2026\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2148 - val_accuracy: 0.9344 - val_loss: 0.2046\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1978\nValidation accuracy: 93.28%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8928 - loss: 0.3590 - val_accuracy: 0.9231 - val_loss: 0.2258\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.2319 - val_accuracy: 0.9246 - val_loss: 0.2132\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2332 - val_accuracy: 0.9236 - val_loss: 0.2134\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2267 - val_accuracy: 0.9221 - val_loss: 0.2062\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9289 - loss: 0.2207 - val_accuracy: 0.9236 - val_loss: 0.2083\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2144 - val_accuracy: 0.9216 - val_loss: 0.2051\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2222 - val_accuracy: 0.9226 - val_loss: 0.2068\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.2038 - val_accuracy: 0.9236 - val_loss: 0.2096\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.2050 - val_accuracy: 0.9216 - val_loss: 0.2055\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2037\nValidation accuracy: 92.16%\nAverage Validation Accuracy for SNLI: 92.71%\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"0.9271167039871215"},"metadata":{}}]},{"cell_type":"code","source":"# MNLI Matched\ntrain_and_evaluate_kfold(X_mnli_matched, y_encoded_mnli_matched, 'MNLI-matched')\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:32:47.217116Z","iopub.execute_input":"2024-04-14T20:32:47.217850Z","iopub.status.idle":"2024-04-14T20:33:48.453823Z","shell.execute_reply.started":"2024-04-14T20:32:47.217818Z","shell.execute_reply":"2024-04-14T20:33:48.452960Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8962 - loss: 0.3637 - val_accuracy: 0.9200 - val_loss: 0.2185\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2607 - val_accuracy: 0.9195 - val_loss: 0.2139\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2536 - val_accuracy: 0.9180 - val_loss: 0.2099\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2495 - val_accuracy: 0.9190 - val_loss: 0.2113\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2411 - val_accuracy: 0.9149 - val_loss: 0.2132\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2526 - val_accuracy: 0.9200 - val_loss: 0.2118\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2014\nValidation accuracy: 91.80%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8970 - loss: 0.3593 - val_accuracy: 0.9317 - val_loss: 0.2141\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2620 - val_accuracy: 0.9317 - val_loss: 0.2073\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2574 - val_accuracy: 0.9292 - val_loss: 0.2129\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2486 - val_accuracy: 0.9307 - val_loss: 0.2049\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2339 - val_accuracy: 0.9297 - val_loss: 0.2031\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2409 - val_accuracy: 0.9307 - val_loss: 0.2008\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2432 - val_accuracy: 0.9317 - val_loss: 0.2053\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2529 - val_accuracy: 0.9282 - val_loss: 0.2064\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2563 - val_accuracy: 0.9322 - val_loss: 0.1997\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2474 - val_accuracy: 0.9302 - val_loss: 0.2016\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2170\nValidation accuracy: 93.22%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8829 - loss: 0.3702 - val_accuracy: 0.9165 - val_loss: 0.2574\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2418 - val_accuracy: 0.9144 - val_loss: 0.2631\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2442 - val_accuracy: 0.9139 - val_loss: 0.2654\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2412 - val_accuracy: 0.9165 - val_loss: 0.2508\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2254 - val_accuracy: 0.9139 - val_loss: 0.2519\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2373 - val_accuracy: 0.9134 - val_loss: 0.2475\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2387 - val_accuracy: 0.9144 - val_loss: 0.2500\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2346 - val_accuracy: 0.9139 - val_loss: 0.2516\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2188 - val_accuracy: 0.9149 - val_loss: 0.2523\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9230 - loss: 0.2264\nValidation accuracy: 91.34%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8991 - loss: 0.3632 - val_accuracy: 0.9170 - val_loss: 0.2398\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2633 - val_accuracy: 0.9165 - val_loss: 0.2389\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2541 - val_accuracy: 0.9185 - val_loss: 0.2275\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9244 - loss: 0.2234 - val_accuracy: 0.9119 - val_loss: 0.2310\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2396 - val_accuracy: 0.9175 - val_loss: 0.2326\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2426 - val_accuracy: 0.9165 - val_loss: 0.2259\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2339 - val_accuracy: 0.9175 - val_loss: 0.2314\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2505 - val_accuracy: 0.9109 - val_loss: 0.2314\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2482 - val_accuracy: 0.9159 - val_loss: 0.2328\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2354\nValidation accuracy: 91.65%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8868 - loss: 0.3707 - val_accuracy: 0.9093 - val_loss: 0.2661\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2536 - val_accuracy: 0.9068 - val_loss: 0.2635\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2222 - val_accuracy: 0.9068 - val_loss: 0.2604\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2395 - val_accuracy: 0.9063 - val_loss: 0.2591\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2460 - val_accuracy: 0.9129 - val_loss: 0.2608\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2384 - val_accuracy: 0.9078 - val_loss: 0.2563\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2278 - val_accuracy: 0.9093 - val_loss: 0.2573\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2383 - val_accuracy: 0.9088 - val_loss: 0.2514\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2252 - val_accuracy: 0.9098 - val_loss: 0.2521\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.2263 - val_accuracy: 0.9052 - val_loss: 0.2526\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2460\nValidation accuracy: 90.88%\nAverage Validation Accuracy for MNLI-matched: 91.78%\n","output_type":"stream"},{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"0.9177789211273193"},"metadata":{}}]},{"cell_type":"code","source":"# MNLI Mismatched\ntrain_and_evaluate_kfold(X_mnli_mismatched, y_encoded_mnli_mismatched,'MNLI-mismatched')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:34:27.553624Z","iopub.execute_input":"2024-04-14T20:34:27.554026Z","iopub.status.idle":"2024-04-14T20:35:30.890882Z","shell.execute_reply.started":"2024-04-14T20:34:27.553994Z","shell.execute_reply":"2024-04-14T20:35:30.890030Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8885 - loss: 0.3724 - val_accuracy: 0.9171 - val_loss: 0.2549\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2515 - val_accuracy: 0.9181 - val_loss: 0.2468\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2465 - val_accuracy: 0.9161 - val_loss: 0.2544\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2449 - val_accuracy: 0.9161 - val_loss: 0.2444\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2482 - val_accuracy: 0.9187 - val_loss: 0.2396\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2423 - val_accuracy: 0.9176 - val_loss: 0.2381\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2358 - val_accuracy: 0.9171 - val_loss: 0.2463\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2385 - val_accuracy: 0.9202 - val_loss: 0.2364\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2420 - val_accuracy: 0.9166 - val_loss: 0.2341\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2410 - val_accuracy: 0.9181 - val_loss: 0.2393\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2320\nValidation accuracy: 91.66%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8856 - loss: 0.3747 - val_accuracy: 0.9136 - val_loss: 0.2359\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2759 - val_accuracy: 0.9207 - val_loss: 0.2253\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2484 - val_accuracy: 0.9161 - val_loss: 0.2234\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2531 - val_accuracy: 0.9176 - val_loss: 0.2196\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2524 - val_accuracy: 0.9197 - val_loss: 0.2161\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2444 - val_accuracy: 0.9207 - val_loss: 0.2198\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2435 - val_accuracy: 0.9207 - val_loss: 0.2158\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2353 - val_accuracy: 0.9197 - val_loss: 0.2131\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2373 - val_accuracy: 0.9181 - val_loss: 0.2132\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2419 - val_accuracy: 0.9161 - val_loss: 0.2165\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2201\nValidation accuracy: 91.97%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8824 - loss: 0.3834 - val_accuracy: 0.9166 - val_loss: 0.2561\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2598 - val_accuracy: 0.9191 - val_loss: 0.2450\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2386 - val_accuracy: 0.9191 - val_loss: 0.2415\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2399 - val_accuracy: 0.9120 - val_loss: 0.2429\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2437 - val_accuracy: 0.9140 - val_loss: 0.2403\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2523 - val_accuracy: 0.9166 - val_loss: 0.2379\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2387 - val_accuracy: 0.9130 - val_loss: 0.2531\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2344 - val_accuracy: 0.9105 - val_loss: 0.2452\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2380 - val_accuracy: 0.9176 - val_loss: 0.2357\nEpoch 10/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2343 - val_accuracy: 0.9130 - val_loss: 0.2476\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.2638\nValidation accuracy: 91.76%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8876 - loss: 0.3689 - val_accuracy: 0.9242 - val_loss: 0.2364\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2641 - val_accuracy: 0.9237 - val_loss: 0.2282\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2475 - val_accuracy: 0.9232 - val_loss: 0.2343\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2550 - val_accuracy: 0.9222 - val_loss: 0.2294\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2440 - val_accuracy: 0.9212 - val_loss: 0.2299\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9247 - loss: 0.2292\nValidation accuracy: 92.37%\nTraining fold...\nEpoch 1/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8796 - loss: 0.3747 - val_accuracy: 0.9049 - val_loss: 0.2685\nEpoch 2/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2426 - val_accuracy: 0.9084 - val_loss: 0.2596\nEpoch 3/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2446 - val_accuracy: 0.9054 - val_loss: 0.2557\nEpoch 4/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2384 - val_accuracy: 0.9039 - val_loss: 0.2552\nEpoch 5/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2369 - val_accuracy: 0.9074 - val_loss: 0.2605\nEpoch 6/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2423 - val_accuracy: 0.9039 - val_loss: 0.2529\nEpoch 7/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2266 - val_accuracy: 0.9034 - val_loss: 0.2535\nEpoch 8/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2294 - val_accuracy: 0.9074 - val_loss: 0.2538\nEpoch 9/10\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2473 - val_accuracy: 0.9069 - val_loss: 0.2568\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2463\nValidation accuracy: 90.39%\nAverage Validation Accuracy for MNLI-mismatched: 91.63%\n","output_type":"stream"},{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"0.9162933588027954"},"metadata":{}}]},{"cell_type":"code","source":"# ANLI Round 1\ntrain_and_evaluate_kfold(X_anli_r1, y_encoded_anli_r1, 'ANLI round 1')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:36:37.739669Z","iopub.execute_input":"2024-04-14T20:36:37.740039Z","iopub.status.idle":"2024-04-14T20:37:02.268119Z","shell.execute_reply.started":"2024-04-14T20:36:37.740011Z","shell.execute_reply":"2024-04-14T20:37:02.267239Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.5730 - loss: 0.9451 - val_accuracy: 0.7150 - val_loss: 0.7374\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 0.6197 - val_accuracy: 0.7150 - val_loss: 0.7322\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.6173 - val_accuracy: 0.6950 - val_loss: 0.7123\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.6047 - val_accuracy: 0.7100 - val_loss: 0.7128\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7813 - loss: 0.5896 - val_accuracy: 0.7100 - val_loss: 0.7030\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7602 - loss: 0.6475 - val_accuracy: 0.7150 - val_loss: 0.7104\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7795 - loss: 0.6118 - val_accuracy: 0.7150 - val_loss: 0.7021\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.6123 - val_accuracy: 0.7100 - val_loss: 0.7188\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5702 - val_accuracy: 0.7000 - val_loss: 0.7009\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7559 - loss: 0.5954 - val_accuracy: 0.7100 - val_loss: 0.7068\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.7352 \nValidation accuracy: 70.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6239 - loss: 0.9325 - val_accuracy: 0.7250 - val_loss: 0.6521\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.6440 - val_accuracy: 0.7250 - val_loss: 0.6379\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.6356 - val_accuracy: 0.7250 - val_loss: 0.6278\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.6009 - val_accuracy: 0.7250 - val_loss: 0.6256\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.6492 - val_accuracy: 0.7300 - val_loss: 0.6401\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 0.5994 - val_accuracy: 0.7200 - val_loss: 0.6219\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.6154 - val_accuracy: 0.7300 - val_loss: 0.6215\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.6275 - val_accuracy: 0.7200 - val_loss: 0.6319\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.6419 - val_accuracy: 0.7100 - val_loss: 0.6192\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6211 - val_accuracy: 0.7200 - val_loss: 0.6281\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.6651 \nValidation accuracy: 71.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.5923 - loss: 0.9283 - val_accuracy: 0.7900 - val_loss: 0.6152\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.6448 - val_accuracy: 0.7850 - val_loss: 0.5989\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 0.6158 - val_accuracy: 0.7800 - val_loss: 0.5982\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.6165 - val_accuracy: 0.7800 - val_loss: 0.5927\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7691 - loss: 0.6046 - val_accuracy: 0.7850 - val_loss: 0.6104\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.6426 - val_accuracy: 0.7800 - val_loss: 0.5861\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.6380 - val_accuracy: 0.7750 - val_loss: 0.5850\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 0.6403 - val_accuracy: 0.7700 - val_loss: 0.5872\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.6555 - val_accuracy: 0.7850 - val_loss: 0.5712\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.6766 - val_accuracy: 0.7800 - val_loss: 0.5851\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.5286 \nValidation accuracy: 78.50%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6001 - loss: 0.9273 - val_accuracy: 0.7700 - val_loss: 0.5753\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.6692 - val_accuracy: 0.8050 - val_loss: 0.5605\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.6582 - val_accuracy: 0.8000 - val_loss: 0.5551\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.6212 - val_accuracy: 0.7850 - val_loss: 0.5556\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.6945 - val_accuracy: 0.7850 - val_loss: 0.5627\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.5978 - val_accuracy: 0.7800 - val_loss: 0.5589\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.6475 \nValidation accuracy: 80.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.6521 - loss: 0.9258 - val_accuracy: 0.7400 - val_loss: 0.6568\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.6430 - val_accuracy: 0.7400 - val_loss: 0.6349\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7584 - loss: 0.6264 - val_accuracy: 0.7500 - val_loss: 0.6251\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.5583 - val_accuracy: 0.7650 - val_loss: 0.6209\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.6512 - val_accuracy: 0.7550 - val_loss: 0.6313\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.5863 - val_accuracy: 0.7550 - val_loss: 0.6326\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.6577 - val_accuracy: 0.7400 - val_loss: 0.6346\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.6029 \nValidation accuracy: 76.50%\nAverage Validation Accuracy for ANLI round 1: 75.20%\n","output_type":"stream"},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"0.7519999980926514"},"metadata":{}}]},{"cell_type":"code","source":"# ANLI Round 1\ntrain_and_evaluate_kfold(X_anli_r2, y_encoded_anli_r2, 'ANLI round 2')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:38:07.824349Z","iopub.execute_input":"2024-04-14T20:38:07.824726Z","iopub.status.idle":"2024-04-14T20:38:32.925506Z","shell.execute_reply.started":"2024-04-14T20:38:07.824697Z","shell.execute_reply":"2024-04-14T20:38:32.924578Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5469 - loss: 0.9780 - val_accuracy: 0.7300 - val_loss: 0.7435\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6629 - loss: 0.8009 - val_accuracy: 0.7450 - val_loss: 0.7334\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.7751 - val_accuracy: 0.7400 - val_loss: 0.7271\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6488 - loss: 0.8347 - val_accuracy: 0.7250 - val_loss: 0.7376\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6692 - loss: 0.7882 - val_accuracy: 0.7300 - val_loss: 0.7239\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6520 - loss: 0.7858 - val_accuracy: 0.7450 - val_loss: 0.7361\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6804 - loss: 0.7668 - val_accuracy: 0.7500 - val_loss: 0.7315\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6694 - loss: 0.7707 - val_accuracy: 0.7350 - val_loss: 0.7216\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.7546 - val_accuracy: 0.7450 - val_loss: 0.7308\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6944 - loss: 0.7215 - val_accuracy: 0.7500 - val_loss: 0.7239\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7259 - loss: 0.7317 \nValidation accuracy: 73.50%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4769 - loss: 1.0194 - val_accuracy: 0.6650 - val_loss: 0.8223\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6357 - loss: 0.8466 - val_accuracy: 0.6850 - val_loss: 0.7679\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6814 - loss: 0.7785 - val_accuracy: 0.6900 - val_loss: 0.7712\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6794 - loss: 0.7868 - val_accuracy: 0.6900 - val_loss: 0.7382\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6937 - loss: 0.7678 - val_accuracy: 0.7050 - val_loss: 0.7500\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6872 - loss: 0.7647 - val_accuracy: 0.7000 - val_loss: 0.7601\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 0.7789 - val_accuracy: 0.6850 - val_loss: 0.7362\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.7820 - val_accuracy: 0.7000 - val_loss: 0.7322\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6623 - loss: 0.7889 - val_accuracy: 0.6600 - val_loss: 0.7409\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7098 - loss: 0.7156 - val_accuracy: 0.7000 - val_loss: 0.7262\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.7076 \nValidation accuracy: 70.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5021 - loss: 0.9969 - val_accuracy: 0.6100 - val_loss: 0.8698\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.7422 - val_accuracy: 0.6200 - val_loss: 0.8525\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7027 - loss: 0.7418 - val_accuracy: 0.6350 - val_loss: 0.8510\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.7610 - val_accuracy: 0.6350 - val_loss: 0.8560\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6808 - loss: 0.7623 - val_accuracy: 0.6200 - val_loss: 0.8488\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6984 - loss: 0.7249 - val_accuracy: 0.6400 - val_loss: 0.8499\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6983 - loss: 0.7528 - val_accuracy: 0.6350 - val_loss: 0.8437\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6951 - loss: 0.7426 - val_accuracy: 0.6450 - val_loss: 0.8316\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6645 - loss: 0.8063 - val_accuracy: 0.6350 - val_loss: 0.8271\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.7170 - val_accuracy: 0.6400 - val_loss: 0.8315\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6445 - loss: 0.8307 \nValidation accuracy: 63.50%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4610 - loss: 1.0136 - val_accuracy: 0.7000 - val_loss: 0.7020\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6505 - loss: 0.8075 - val_accuracy: 0.7100 - val_loss: 0.6786\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.7855 - val_accuracy: 0.7250 - val_loss: 0.6894\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6735 - loss: 0.7684 - val_accuracy: 0.7200 - val_loss: 0.6694\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6790 - loss: 0.7806 - val_accuracy: 0.7150 - val_loss: 0.6910\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6537 - loss: 0.8149 - val_accuracy: 0.7250 - val_loss: 0.6692\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.8140 - val_accuracy: 0.7200 - val_loss: 0.6687\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.7378 - val_accuracy: 0.7200 - val_loss: 0.6571\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.7595 - val_accuracy: 0.7200 - val_loss: 0.6563\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6634 - loss: 0.7640 - val_accuracy: 0.7200 - val_loss: 0.6637\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7568 - loss: 0.6237 \nValidation accuracy: 72.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.4974 - loss: 0.9956 - val_accuracy: 0.6250 - val_loss: 0.8754\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6918 - loss: 0.7449 - val_accuracy: 0.6350 - val_loss: 0.8712\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.7397 - val_accuracy: 0.6300 - val_loss: 0.8593\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.7603 - val_accuracy: 0.6150 - val_loss: 0.8691\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6754 - loss: 0.7529 - val_accuracy: 0.6200 - val_loss: 0.8686\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.7586 - val_accuracy: 0.6250 - val_loss: 0.8704\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6468 - loss: 0.8214 \nValidation accuracy: 63.00%\nAverage Validation Accuracy for ANLI round 2: 68.40%\n","output_type":"stream"},{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"0.6840000033378602"},"metadata":{}}]},{"cell_type":"code","source":"# ANLI Round 1\ntrain_and_evaluate_kfold(X_anli_r3, y_encoded_anli_r3, 'ANLI round 3')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:38:49.717259Z","iopub.execute_input":"2024-04-14T20:38:49.717947Z","iopub.status.idle":"2024-04-14T20:39:16.729197Z","shell.execute_reply.started":"2024-04-14T20:38:49.717913Z","shell.execute_reply":"2024-04-14T20:39:16.728265Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.4786 - loss: 1.0031 - val_accuracy: 0.6792 - val_loss: 0.7049\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6133 - loss: 0.8255 - val_accuracy: 0.6917 - val_loss: 0.6822\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6495 - loss: 0.7957 - val_accuracy: 0.7042 - val_loss: 0.6659\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.7743 - val_accuracy: 0.7083 - val_loss: 0.6748\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6624 - loss: 0.7820 - val_accuracy: 0.7042 - val_loss: 0.6639\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6362 - loss: 0.8039 - val_accuracy: 0.6958 - val_loss: 0.6532\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7039 - loss: 0.7070 - val_accuracy: 0.7083 - val_loss: 0.6565\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6697 - loss: 0.7640 - val_accuracy: 0.7250 - val_loss: 0.6624\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6791 - loss: 0.7461 - val_accuracy: 0.7208 - val_loss: 0.6673\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6920 - loss: 0.6551 \nValidation accuracy: 69.58%\nTraining fold...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5344 - loss: 0.9807 - val_accuracy: 0.6417 - val_loss: 0.8107\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6668 - loss: 0.7748 - val_accuracy: 0.6583 - val_loss: 0.8149\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6486 - loss: 0.7760 - val_accuracy: 0.6333 - val_loss: 0.8241\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.7345 - val_accuracy: 0.6333 - val_loss: 0.8010\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.7126 - val_accuracy: 0.6500 - val_loss: 0.7954\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6685 - loss: 0.7648 - val_accuracy: 0.6458 - val_loss: 0.7953\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6829 - loss: 0.7528 - val_accuracy: 0.6500 - val_loss: 0.7933\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.7494 - val_accuracy: 0.6667 - val_loss: 0.7914\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6775 - loss: 0.7492 - val_accuracy: 0.6542 - val_loss: 0.7945\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6838 - loss: 0.7308 - val_accuracy: 0.6542 - val_loss: 0.7896\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.7846 \nValidation accuracy: 65.42%\nTraining fold...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5225 - loss: 0.9829 - val_accuracy: 0.6125 - val_loss: 0.8438\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6812 - loss: 0.7385 - val_accuracy: 0.6333 - val_loss: 0.8376\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.7373 - val_accuracy: 0.6542 - val_loss: 0.8235\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.7274 - val_accuracy: 0.6583 - val_loss: 0.8218\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.7006 - val_accuracy: 0.6333 - val_loss: 0.8171\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6899 - loss: 0.7260 - val_accuracy: 0.6458 - val_loss: 0.8212\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.7418 - val_accuracy: 0.6417 - val_loss: 0.8252\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6939 - loss: 0.7401 - val_accuracy: 0.6167 - val_loss: 0.8317\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.7643 \nValidation accuracy: 63.33%\nTraining fold...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.5289 - loss: 0.9786 - val_accuracy: 0.6875 - val_loss: 0.7798\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6487 - loss: 0.7929 - val_accuracy: 0.7000 - val_loss: 0.7464\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6523 - loss: 0.7690 - val_accuracy: 0.7000 - val_loss: 0.7412\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.7781 - val_accuracy: 0.6917 - val_loss: 0.7486\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6930 - loss: 0.7233 - val_accuracy: 0.6958 - val_loss: 0.7532\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6980 - loss: 0.7046 - val_accuracy: 0.7042 - val_loss: 0.7565\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6859 - loss: 0.7860 \nValidation accuracy: 70.00%\nTraining fold...\nEpoch 1/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.5411 - loss: 0.9938 - val_accuracy: 0.6625 - val_loss: 0.7661\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.7822 - val_accuracy: 0.6875 - val_loss: 0.7233\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.7860 - val_accuracy: 0.6833 - val_loss: 0.7100\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6716 - loss: 0.7613 - val_accuracy: 0.7042 - val_loss: 0.7106\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.7328 - val_accuracy: 0.6958 - val_loss: 0.7107\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.7370 - val_accuracy: 0.6958 - val_loss: 0.7073\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.7352 - val_accuracy: 0.6875 - val_loss: 0.7061\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6645 - loss: 0.7855 - val_accuracy: 0.6792 - val_loss: 0.7156\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6627 - loss: 0.7698 - val_accuracy: 0.6875 - val_loss: 0.7117\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6898 - loss: 0.7367 - val_accuracy: 0.7042 - val_loss: 0.7122\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6940 - loss: 0.7069 \nValidation accuracy: 68.75%\nAverage Validation Accuracy for ANLI round 3: 67.42%\n","output_type":"stream"},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"0.6741666555404663"},"metadata":{}}]},{"cell_type":"code","source":"final_combined_df = pd.concat([\n    combined_snli_df,\n    combined_mnli_matched_df,\n    combined_mnli_mismatched_df,\n    combined_anli_r1_df,\n    combined_anli_r2_df,\n    combined_anli_r3_df\n], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:41:41.195055Z","iopub.execute_input":"2024-04-14T20:41:41.195846Z","iopub.status.idle":"2024-04-14T20:41:41.204162Z","shell.execute_reply.started":"2024-04-14T20:41:41.195810Z","shell.execute_reply":"2024-04-14T20:41:41.203163Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"final_combined_df","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:41:50.337100Z","iopub.execute_input":"2024-04-14T20:41:50.338009Z","iopub.status.idle":"2024-04-14T20:41:50.357587Z","shell.execute_reply.started":"2024-04-14T20:41:50.337975Z","shell.execute_reply":"2024-04-14T20:41:50.356617Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"       Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0                0.034767         0.962592               0.002641   \n1                0.001921         0.319032               0.679047   \n2                0.998783         0.000764               0.000453   \n3                0.001001         0.997708               0.001291   \n4                0.001080         0.301363               0.697557   \n...                   ...              ...                    ...   \n32666            0.150312         0.806051               0.043637   \n32667            0.971834         0.026294               0.001872   \n32668            0.973818         0.025074               0.001109   \n32669            0.341781         0.226539               0.431681   \n32670            0.472737         0.477215               0.050049   \n\n       Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0                0.012451         0.927093               0.060457   \n1                0.752766         0.242251               0.004983   \n2                0.000254         0.004494               0.995253   \n3                0.005844         0.990736               0.003419   \n4                0.278348         0.718575               0.003076   \n...                   ...              ...                    ...   \n32666            0.032452         0.068553               0.898994   \n32667            0.009070         0.824654               0.166276   \n32668            0.000352         0.000972               0.998677   \n32669            0.006147         0.073669               0.920184   \n32670            0.000420         0.991832               0.007748   \n\n       Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0               0.008653        0.947434              0.043913           1  \n1               0.740332        0.256434              0.003235           0  \n2               0.004677        0.060481              0.934843           2  \n3               0.034056        0.956687              0.009257           1  \n4               0.498761        0.499270              0.001969           0  \n...                  ...             ...                   ...         ...  \n32666           0.122045        0.254093              0.623862           2  \n32667           0.001115        0.003229              0.995656           2  \n32668           0.310862        0.618914              0.070225           2  \n32669           0.054172        0.317935              0.627893           2  \n32670           0.015091        0.121354              0.863554           2  \n\n[32671 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32666</th>\n      <td>0.150312</td>\n      <td>0.806051</td>\n      <td>0.043637</td>\n      <td>0.032452</td>\n      <td>0.068553</td>\n      <td>0.898994</td>\n      <td>0.122045</td>\n      <td>0.254093</td>\n      <td>0.623862</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32667</th>\n      <td>0.971834</td>\n      <td>0.026294</td>\n      <td>0.001872</td>\n      <td>0.009070</td>\n      <td>0.824654</td>\n      <td>0.166276</td>\n      <td>0.001115</td>\n      <td>0.003229</td>\n      <td>0.995656</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32668</th>\n      <td>0.973818</td>\n      <td>0.025074</td>\n      <td>0.001109</td>\n      <td>0.000352</td>\n      <td>0.000972</td>\n      <td>0.998677</td>\n      <td>0.310862</td>\n      <td>0.618914</td>\n      <td>0.070225</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32669</th>\n      <td>0.341781</td>\n      <td>0.226539</td>\n      <td>0.431681</td>\n      <td>0.006147</td>\n      <td>0.073669</td>\n      <td>0.920184</td>\n      <td>0.054172</td>\n      <td>0.317935</td>\n      <td>0.627893</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32670</th>\n      <td>0.472737</td>\n      <td>0.477215</td>\n      <td>0.050049</td>\n      <td>0.000420</td>\n      <td>0.991832</td>\n      <td>0.007748</td>\n      <td>0.015091</td>\n      <td>0.121354</td>\n      <td>0.863554</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>32671 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Features and Labels\nX_final = final_combined_df.drop('True_Label', axis=1).values\ny_final = final_combined_df['True_Label'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:44:09.693244Z","iopub.execute_input":"2024-04-14T20:44:09.693645Z","iopub.status.idle":"2024-04-14T20:44:09.701646Z","shell.execute_reply.started":"2024-04-14T20:44:09.693604Z","shell.execute_reply":"2024-04-14T20:44:09.700706Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# One-hot encode labels\ny_encoded_final = tf.keras.utils.to_categorical(y_final)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:44:11.793981Z","iopub.execute_input":"2024-04-14T20:44:11.794407Z","iopub.status.idle":"2024-04-14T20:44:11.800335Z","shell.execute_reply.started":"2024-04-14T20:44:11.794361Z","shell.execute_reply":"2024-04-14T20:44:11.799103Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# Final Combined Model\ntrain_and_evaluate_kfold(X_final, y_encoded_final, 'final combined model on all datasets')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:45:15.704356Z","iopub.execute_input":"2024-04-14T20:45:15.704740Z","iopub.status.idle":"2024-04-14T20:47:05.251517Z","shell.execute_reply.started":"2024-04-14T20:45:15.704709Z","shell.execute_reply":"2024-04-14T20:47:05.250605Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Training fold...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8810 - loss: 0.3594 - val_accuracy: 0.8920 - val_loss: 0.3043\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.3089 - val_accuracy: 0.8940 - val_loss: 0.2975\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2987 - val_accuracy: 0.8920 - val_loss: 0.2942\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8993 - loss: 0.2938 - val_accuracy: 0.8946 - val_loss: 0.2966\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2948 - val_accuracy: 0.8941 - val_loss: 0.2893\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2950 - val_accuracy: 0.8936 - val_loss: 0.2987\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2881 - val_accuracy: 0.8929 - val_loss: 0.2941\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3010 - val_accuracy: 0.8935 - val_loss: 0.2941\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2314\nValidation accuracy: 89.41%\nTraining fold...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8866 - loss: 0.3496 - val_accuracy: 0.8913 - val_loss: 0.3090\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8969 - loss: 0.3013 - val_accuracy: 0.8926 - val_loss: 0.3001\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3015 - val_accuracy: 0.8929 - val_loss: 0.2974\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2918 - val_accuracy: 0.8938 - val_loss: 0.2977\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.3022 - val_accuracy: 0.8947 - val_loss: 0.2999\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2960 - val_accuracy: 0.8946 - val_loss: 0.2975\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2301\nValidation accuracy: 89.29%\nTraining fold...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8906 - loss: 0.3534 - val_accuracy: 0.8999 - val_loss: 0.2790\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.3028 - val_accuracy: 0.8990 - val_loss: 0.2803\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2982 - val_accuracy: 0.9005 - val_loss: 0.2763\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3047 - val_accuracy: 0.9004 - val_loss: 0.2736\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3037 - val_accuracy: 0.8990 - val_loss: 0.2757\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.3055 - val_accuracy: 0.9005 - val_loss: 0.2802\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.3058 - val_accuracy: 0.9007 - val_loss: 0.2735\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.3026 - val_accuracy: 0.8996 - val_loss: 0.2749\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2958 - val_accuracy: 0.8973 - val_loss: 0.2740\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.2966 - val_accuracy: 0.9027 - val_loss: 0.2741\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2129\nValidation accuracy: 90.07%\nTraining fold...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8856 - loss: 0.3572 - val_accuracy: 0.9002 - val_loss: 0.2920\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.3032 - val_accuracy: 0.9010 - val_loss: 0.2906\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2975 - val_accuracy: 0.9024 - val_loss: 0.2885\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2964 - val_accuracy: 0.9017 - val_loss: 0.2922\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2956 - val_accuracy: 0.8990 - val_loss: 0.2906\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.3038 - val_accuracy: 0.9025 - val_loss: 0.2810\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.2946 - val_accuracy: 0.9033 - val_loss: 0.2813\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.3026 - val_accuracy: 0.9011 - val_loss: 0.2831\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2979 - val_accuracy: 0.9002 - val_loss: 0.2836\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.2130\nValidation accuracy: 90.25%\nTraining fold...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8803 - loss: 0.3547 - val_accuracy: 0.8946 - val_loss: 0.3075\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.3000 - val_accuracy: 0.8946 - val_loss: 0.3078\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.3015 - val_accuracy: 0.8895 - val_loss: 0.3059\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8967 - loss: 0.3006 - val_accuracy: 0.8915 - val_loss: 0.3053\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2914 - val_accuracy: 0.8923 - val_loss: 0.3012\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2937 - val_accuracy: 0.8924 - val_loss: 0.2994\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2920 - val_accuracy: 0.8932 - val_loss: 0.3003\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2848 - val_accuracy: 0.8946 - val_loss: 0.2982\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2877 - val_accuracy: 0.8939 - val_loss: 0.2945\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2897 - val_accuracy: 0.8939 - val_loss: 0.2987\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2192\nValidation accuracy: 89.39%\nAverage Validation Accuracy for final combined model on all datasets: 89.68%\n","output_type":"stream"},{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"0.8968198895454407"},"metadata":{}}]},{"cell_type":"code","source":"def train_and_evaluate_kfold_and_save_final(X, y, name, n_splits=5, model_dir='/kaggle/working/'):\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    all_scores = []\n\n    # Cross-validation process to evaluate the model\n    for i, (train_index, val_index) in enumerate(kf.split(X), 1):\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n\n        model = create_model(X_train.shape[1], y_train.shape[1])\n        print(f\"Training fold {i}...\")\n        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n\n        val_loss, val_accuracy = model.evaluate(X_val, y_val)\n        all_scores.append(val_accuracy)\n        print(f\"Validation accuracy for fold {i}: {val_accuracy * 100:.2f}%\")\n\n    average_accuracy = np.mean(all_scores)\n    print(f\"Average Validation Accuracy for {name}: {average_accuracy * 100:.2f}%\")\n\n    # Training the final model on the entire dataset\n    print(\"Training the final combined model on the entire dataset...\")\n    final_model = create_model(X.shape[1], y.shape[1])\n    final_model.fit(X, y, epochs=10, batch_size=32)\n\n    # Save the final model\n    final_model_save_path = f\"{model_dir}{name}_final_model.h5\"\n    final_model.save(final_model_save_path)\n    print(f\"Final model saved at {final_model_save_path}\")\n\n    return average_accuracy, final_model\n\n# Example usage\ntrain_and_evaluate_kfold_and_save_final(X_final, y_encoded_final, 'for the combined final model', model_dir='/kaggle/working/')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T20:59:06.226466Z","iopub.execute_input":"2024-04-14T20:59:06.227117Z","iopub.status.idle":"2024-04-14T21:01:34.162093Z","shell.execute_reply.started":"2024-04-14T20:59:06.227088Z","shell.execute_reply":"2024-04-14T21:01:34.161183Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"Training fold 1...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8824 - loss: 0.3510 - val_accuracy: 0.8923 - val_loss: 0.3014\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3072 - val_accuracy: 0.8921 - val_loss: 0.3067\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.2931 - val_accuracy: 0.8943 - val_loss: 0.2957\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2986 - val_accuracy: 0.8895 - val_loss: 0.2963\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2978 - val_accuracy: 0.8918 - val_loss: 0.2954\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2915 - val_accuracy: 0.8930 - val_loss: 0.2955\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2938 - val_accuracy: 0.8949 - val_loss: 0.2915\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8976 - loss: 0.2930 - val_accuracy: 0.8940 - val_loss: 0.2891\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2901 - val_accuracy: 0.8958 - val_loss: 0.2902\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2860 - val_accuracy: 0.8952 - val_loss: 0.2892\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2312\nValidation accuracy for fold 1: 89.52%\nTraining fold 2...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8839 - loss: 0.3553 - val_accuracy: 0.8959 - val_loss: 0.3039\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3007 - val_accuracy: 0.8958 - val_loss: 0.3013\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2987 - val_accuracy: 0.8958 - val_loss: 0.2978\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8946 - loss: 0.3016 - val_accuracy: 0.8936 - val_loss: 0.2943\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.2883 - val_accuracy: 0.8932 - val_loss: 0.3000\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 0.2975 - val_accuracy: 0.8950 - val_loss: 0.3028\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2902 - val_accuracy: 0.8941 - val_loss: 0.2928\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2958 - val_accuracy: 0.8956 - val_loss: 0.3014\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2894 - val_accuracy: 0.8939 - val_loss: 0.2916\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2916 - val_accuracy: 0.8959 - val_loss: 0.2967\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9228 - loss: 0.2335\nValidation accuracy for fold 2: 89.59%\nTraining fold 3...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8793 - loss: 0.3631 - val_accuracy: 0.8994 - val_loss: 0.2896\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3159 - val_accuracy: 0.8998 - val_loss: 0.2806\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2997 - val_accuracy: 0.8988 - val_loss: 0.2759\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2953 - val_accuracy: 0.9004 - val_loss: 0.2752\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.3057 - val_accuracy: 0.8988 - val_loss: 0.2738\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.3082 - val_accuracy: 0.8987 - val_loss: 0.2797\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.2902 - val_accuracy: 0.9007 - val_loss: 0.2733\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.3007 - val_accuracy: 0.8991 - val_loss: 0.2758\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.3012 - val_accuracy: 0.8998 - val_loss: 0.2725\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.3066 - val_accuracy: 0.9008 - val_loss: 0.2709\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2136\nValidation accuracy for fold 3: 90.08%\nTraining fold 4...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.3595 - val_accuracy: 0.9013 - val_loss: 0.2899\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8928 - loss: 0.3036 - val_accuracy: 0.8975 - val_loss: 0.2886\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.3022 - val_accuracy: 0.9025 - val_loss: 0.2886\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.3059 - val_accuracy: 0.8994 - val_loss: 0.2850\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.3000 - val_accuracy: 0.9022 - val_loss: 0.2878\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2998 - val_accuracy: 0.9013 - val_loss: 0.2851\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.2971 - val_accuracy: 0.8998 - val_loss: 0.2906\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.2975 - val_accuracy: 0.9014 - val_loss: 0.2846\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.2930 - val_accuracy: 0.8998 - val_loss: 0.2839\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.2942 - val_accuracy: 0.9030 - val_loss: 0.2809\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9284 - loss: 0.2164\nValidation accuracy for fold 4: 90.30%\nTraining fold 5...\nEpoch 1/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8818 - loss: 0.3578 - val_accuracy: 0.8923 - val_loss: 0.3130\nEpoch 2/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.3013 - val_accuracy: 0.8927 - val_loss: 0.3111\nEpoch 3/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.2987 - val_accuracy: 0.8933 - val_loss: 0.3048\nEpoch 4/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.2993 - val_accuracy: 0.8942 - val_loss: 0.3105\nEpoch 5/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3026 - val_accuracy: 0.8946 - val_loss: 0.3014\nEpoch 6/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2931 - val_accuracy: 0.8949 - val_loss: 0.2999\nEpoch 7/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3027 - val_accuracy: 0.8953 - val_loss: 0.2944\nEpoch 8/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2868 - val_accuracy: 0.8941 - val_loss: 0.2962\nEpoch 9/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2878 - val_accuracy: 0.8923 - val_loss: 0.2959\nEpoch 10/10\n\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.2969 - val_accuracy: 0.8947 - val_loss: 0.2973\n\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9231 - loss: 0.2172\nValidation accuracy for fold 5: 89.47%\nAverage Validation Accuracy for for the combined final model: 89.79%\nTraining the final combined model on the entire dataset...\nEpoch 1/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8855 - loss: 0.3490\nEpoch 2/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3047\nEpoch 3/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.3048\nEpoch 4/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.2945\nEpoch 5/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2983\nEpoch 6/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8965 - loss: 0.2951\nEpoch 7/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8940 - loss: 0.2975\nEpoch 8/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.2944\nEpoch 9/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2951\nEpoch 10/10\n\u001b[1m1021/1021\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.3022\nFinal model saved at /kaggle/working/for the combined final model_final_model.h5\n","output_type":"stream"},{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"(0.8979217886924744, <Sequential name=sequential_57, built=True>)"},"metadata":{}}]}]}