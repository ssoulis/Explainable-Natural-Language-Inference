{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775},{"sourceId":8083662,"sourceType":"datasetVersion","datasetId":4771616},{"sourceId":8083668,"sourceType":"datasetVersion","datasetId":4771621},{"sourceId":8083678,"sourceType":"datasetVersion","datasetId":4771629},{"sourceId":8084913,"sourceType":"datasetVersion","datasetId":4772442}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the SNLI test data (including true labels)\nsnli_test_path = \"/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\nsnli_test_df = pd.read_csv(snli_test_path)\n\n# Define file paths for SNLI prediction files\nsnli_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_snli_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_snli_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_snli_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_snli = \"/kaggle/working/combined_snli_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_snli_df = pd.DataFrame(columns=columns)\n\nlabel_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n\n# Load and merge the predictions\nfor model, path in snli_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_snli_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_snli_df['True_Label'] = snli_test_df['gold_label'].map(label_mapping)\n\n# Convert True_Label to integer type\ncombined_snli_df['True_Label'] = combined_snli_df['True_Label'].astype('Int64')\n\n# Save the combined DataFrame to CSV\ncombined_snli_df.to_csv(output_csv_path_snli, index=False)\n\nprint(f\"Combined SNLI predictions with true labels saved to {output_csv_path_snli}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T13:09:08.243830Z","iopub.execute_input":"2024-08-20T13:09:08.244243Z","iopub.status.idle":"2024-08-20T13:09:08.548950Z","shell.execute_reply.started":"2024-08-20T13:09:08.244212Z","shell.execute_reply":"2024-08-20T13:09:08.547813Z"},"trusted":true},"execution_count":396,"outputs":[{"name":"stdout","text":"Combined SNLI predictions with true labels saved to /kaggle/working/combined_snli_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:08.551272Z","iopub.execute_input":"2024-08-20T13:09:08.551662Z","iopub.status.idle":"2024-08-20T13:09:08.582562Z","shell.execute_reply.started":"2024-08-20T13:09:08.551620Z","shell.execute_reply":"2024-08-20T13:09:08.581436Z"},"trusted":true},"execution_count":397,"outputs":[{"execution_count":397,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.034767         0.962592               0.002641   \n1            0.001921         0.319032               0.679047   \n2            0.998783         0.000764               0.000453   \n3            0.001001         0.997708               0.001291   \n4            0.001080         0.301363               0.697557   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.012451         0.927093               0.060457   \n1            0.752766         0.242251               0.004983   \n2            0.000254         0.004494               0.995253   \n3            0.005844         0.990736               0.003419   \n4            0.278348         0.718575               0.003076   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.008653        0.947434              0.043913           1  \n1           0.740332        0.256434              0.003235           0  \n2           0.004677        0.060481              0.934843           2  \n3           0.034056        0.956687              0.009257           1  \n4           0.498761        0.499270              0.001969           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_matched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_matched.csv\"\nmnli_matched_test_df = pd.read_csv(mnli_matched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_matched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_matched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_matched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_matched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_matched = \"/kaggle/working/combined_mnli_matched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_matched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_matched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_matched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_matched_df['True_Label'] = mnli_matched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_matched_df.to_csv(output_csv_path_mnli_matched, index=False)\n\nprint(f\"Combined MNLI-matched predictions with true labels saved to {output_csv_path_mnli_matched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:08.584078Z","iopub.execute_input":"2024-08-20T13:09:08.584511Z","iopub.status.idle":"2024-08-20T13:09:08.788333Z","shell.execute_reply.started":"2024-08-20T13:09:08.584470Z","shell.execute_reply":"2024-08-20T13:09:08.787308Z"},"trusted":true},"execution_count":398,"outputs":[{"name":"stdout","text":"Combined MNLI-matched predictions with true labels saved to /kaggle/working/combined_mnli_matched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:08.791244Z","iopub.execute_input":"2024-08-20T13:09:08.791638Z","iopub.status.idle":"2024-08-20T13:09:08.806559Z","shell.execute_reply.started":"2024-08-20T13:09:08.791599Z","shell.execute_reply":"2024-08-20T13:09:08.805361Z"},"trusted":true},"execution_count":399,"outputs":[{"execution_count":399,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.010844        0.983012              0.006144           1  \n1           0.005388        0.007536              0.987076           2  \n2           0.853862        0.143483              0.002655           0  \n3           0.004128        0.070757              0.925115           2  \n4           0.003864        0.029262              0.966875           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_mismatched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_mismatched.csv\"\nmnli_mismatched_test_df = pd.read_csv(mnli_mismatched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_mismatched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_mismatched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_mismatched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_mismatched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_mismatched = \"/kaggle/working/combined_mnli_mismatched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_mismatched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_mismatched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_mismatched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_mismatched_df['True_Label'] = mnli_mismatched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_mismatched_df.to_csv(output_csv_path_mnli_mismatched, index=False)\n\nprint(f\"Combined MNLI-mismatched predictions with true labels saved to {output_csv_path_mnli_mismatched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:08.807918Z","iopub.execute_input":"2024-08-20T13:09:08.808236Z","iopub.status.idle":"2024-08-20T13:09:08.999484Z","shell.execute_reply.started":"2024-08-20T13:09:08.808209Z","shell.execute_reply":"2024-08-20T13:09:08.998523Z"},"trusted":true},"execution_count":400,"outputs":[{"name":"stdout","text":"Combined MNLI-mismatched predictions with true labels saved to /kaggle/working/combined_mnli_mismatched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_mismatched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.000784Z","iopub.execute_input":"2024-08-20T13:09:09.001168Z","iopub.status.idle":"2024-08-20T13:09:09.017001Z","shell.execute_reply.started":"2024-08-20T13:09:09.001131Z","shell.execute_reply":"2024-08-20T13:09:09.015932Z"},"trusted":true},"execution_count":401,"outputs":[{"execution_count":401,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.999667         0.000160               0.000173   \n1            0.998119         0.000962               0.000919   \n2            0.000552         0.004809               0.994639   \n3            0.827653         0.171961               0.000386   \n4            0.000292         0.002875               0.996833   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.000068         0.000402               0.999529   \n1            0.000183         0.001511               0.998306   \n2            0.986062         0.012020               0.001918   \n3            0.000478         0.270953               0.728569   \n4            0.975167         0.021904               0.002929   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.000894        0.003787              0.995318           2  \n1           0.006421        0.010224              0.983355           2  \n2           0.975041        0.023354              0.001605           0  \n3           0.001722        0.796122              0.202156           2  \n4           0.965952        0.032748              0.001300           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nanli_r1_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv\"\nanli_r1_test_df = pd.read_csv(anli_r1_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nanli_r1_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r1_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r1_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r1_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r1 = \"/kaggle/working/combined_anli_r1_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r1_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r1_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r1_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r1_df['True_Label'] = anli_r1_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r1_df.to_csv(output_csv_path_anli_r1, index=False)\n\nprint(f\"Combined ANLI Round 1 predictions with true labels saved to {output_csv_path_anli_r1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.018241Z","iopub.execute_input":"2024-08-20T13:09:09.018539Z","iopub.status.idle":"2024-08-20T13:09:09.067986Z","shell.execute_reply.started":"2024-08-20T13:09:09.018513Z","shell.execute_reply":"2024-08-20T13:09:09.067010Z"},"trusted":true},"execution_count":402,"outputs":[{"name":"stdout","text":"Combined ANLI Round 1 predictions with true labels saved to /kaggle/working/combined_anli_r1_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r1_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.069355Z","iopub.execute_input":"2024-08-20T13:09:09.070227Z","iopub.status.idle":"2024-08-20T13:09:09.085060Z","shell.execute_reply.started":"2024-08-20T13:09:09.070189Z","shell.execute_reply":"2024-08-20T13:09:09.084083Z"},"trusted":true},"execution_count":403,"outputs":[{"execution_count":403,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.015388         0.976305               0.008307   \n1            0.224603         0.501549               0.273848   \n2            0.006642         0.976690               0.016669   \n3            0.966494         0.032235               0.001272   \n4            0.880736         0.028293               0.090971   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.996714         0.000376               0.002910   \n1            0.875720         0.000724               0.123556   \n2            0.999484         0.000330               0.000186   \n3            0.000686         0.998181               0.001133   \n4            0.000378         0.000197               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.322974        0.667628              0.009398           0  \n1           0.998526        0.000604              0.000869           0  \n2           0.783352        0.212241              0.004407           0  \n3           0.002134        0.989523              0.008343           1  \n4           0.023283        0.013253              0.963464           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015388</td>\n      <td>0.976305</td>\n      <td>0.008307</td>\n      <td>0.996714</td>\n      <td>0.000376</td>\n      <td>0.002910</td>\n      <td>0.322974</td>\n      <td>0.667628</td>\n      <td>0.009398</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224603</td>\n      <td>0.501549</td>\n      <td>0.273848</td>\n      <td>0.875720</td>\n      <td>0.000724</td>\n      <td>0.123556</td>\n      <td>0.998526</td>\n      <td>0.000604</td>\n      <td>0.000869</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006642</td>\n      <td>0.976690</td>\n      <td>0.016669</td>\n      <td>0.999484</td>\n      <td>0.000330</td>\n      <td>0.000186</td>\n      <td>0.783352</td>\n      <td>0.212241</td>\n      <td>0.004407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.966494</td>\n      <td>0.032235</td>\n      <td>0.001272</td>\n      <td>0.000686</td>\n      <td>0.998181</td>\n      <td>0.001133</td>\n      <td>0.002134</td>\n      <td>0.989523</td>\n      <td>0.008343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880736</td>\n      <td>0.028293</td>\n      <td>0.090971</td>\n      <td>0.000378</td>\n      <td>0.000197</td>\n      <td>0.999425</td>\n      <td>0.023283</td>\n      <td>0.013253</td>\n      <td>0.963464</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 2 test data (including true labels)\nanli_r2_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv\"\nanli_r2_test_df = pd.read_csv(anli_r2_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r2_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r2_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r2_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r2_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r2 = \"/kaggle/working/combined_anli_r2_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r2_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r2_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r2_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r2_df['True_Label'] = anli_r2_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r2_df.to_csv(output_csv_path_anli_r2, index=False)\n\nprint(f\"Combined ANLI Round 2 predictions with true labels saved to {output_csv_path_anli_r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.086616Z","iopub.execute_input":"2024-08-20T13:09:09.087420Z","iopub.status.idle":"2024-08-20T13:09:09.132929Z","shell.execute_reply.started":"2024-08-20T13:09:09.087383Z","shell.execute_reply":"2024-08-20T13:09:09.131900Z"},"trusted":true},"execution_count":404,"outputs":[{"name":"stdout","text":"Combined ANLI Round 2 predictions with true labels saved to /kaggle/working/combined_anli_r2_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r2_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.137675Z","iopub.execute_input":"2024-08-20T13:09:09.137996Z","iopub.status.idle":"2024-08-20T13:09:09.153281Z","shell.execute_reply.started":"2024-08-20T13:09:09.137968Z","shell.execute_reply":"2024-08-20T13:09:09.152327Z"},"trusted":true},"execution_count":405,"outputs":[{"execution_count":405,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.001309         0.029617               0.969075   \n1            0.724144         0.273676               0.002180   \n2            0.071604         0.917894               0.010503   \n3            0.066162         0.929179               0.004659   \n4            0.906199         0.089873               0.003928   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.999506         0.000264               0.000230   \n1            0.026951         0.054230               0.918819   \n2            0.001282         0.998108               0.000610   \n3            0.007091         0.992694               0.000215   \n4            0.006259         0.989432               0.004309   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.863365        0.133388              0.003246           0  \n1           0.072900        0.904344              0.022756           1  \n2           0.027402        0.972218              0.000380           0  \n3           0.632171        0.365194              0.002635           1  \n4           0.064109        0.234642              0.701249           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001309</td>\n      <td>0.029617</td>\n      <td>0.969075</td>\n      <td>0.999506</td>\n      <td>0.000264</td>\n      <td>0.000230</td>\n      <td>0.863365</td>\n      <td>0.133388</td>\n      <td>0.003246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.724144</td>\n      <td>0.273676</td>\n      <td>0.002180</td>\n      <td>0.026951</td>\n      <td>0.054230</td>\n      <td>0.918819</td>\n      <td>0.072900</td>\n      <td>0.904344</td>\n      <td>0.022756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071604</td>\n      <td>0.917894</td>\n      <td>0.010503</td>\n      <td>0.001282</td>\n      <td>0.998108</td>\n      <td>0.000610</td>\n      <td>0.027402</td>\n      <td>0.972218</td>\n      <td>0.000380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066162</td>\n      <td>0.929179</td>\n      <td>0.004659</td>\n      <td>0.007091</td>\n      <td>0.992694</td>\n      <td>0.000215</td>\n      <td>0.632171</td>\n      <td>0.365194</td>\n      <td>0.002635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.906199</td>\n      <td>0.089873</td>\n      <td>0.003928</td>\n      <td>0.006259</td>\n      <td>0.989432</td>\n      <td>0.004309</td>\n      <td>0.064109</td>\n      <td>0.234642</td>\n      <td>0.701249</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 3 test data (including true labels)\nanli_r3_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv\"\nanli_r3_test_df = pd.read_csv(anli_r3_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r3_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r3_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r3_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r3_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r3 = \"/kaggle/working/combined_anli_r3_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r3_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r3_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r3_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r3_df['True_Label'] = anli_r3_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r3_df.to_csv(output_csv_path_anli_r3, index=False)\n\nprint(f\"Combined ANLI Round 3 predictions with true labels saved to {output_csv_path_anli_r3}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.154577Z","iopub.execute_input":"2024-08-20T13:09:09.154901Z","iopub.status.idle":"2024-08-20T13:09:09.209687Z","shell.execute_reply.started":"2024-08-20T13:09:09.154874Z","shell.execute_reply":"2024-08-20T13:09:09.208698Z"},"trusted":true},"execution_count":406,"outputs":[{"name":"stdout","text":"Combined ANLI Round 3 predictions with true labels saved to /kaggle/working/combined_anli_r3_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r3_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.210999Z","iopub.execute_input":"2024-08-20T13:09:09.211326Z","iopub.status.idle":"2024-08-20T13:09:09.226506Z","shell.execute_reply.started":"2024-08-20T13:09:09.211299Z","shell.execute_reply":"2024-08-20T13:09:09.225432Z"},"trusted":true},"execution_count":407,"outputs":[{"execution_count":407,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005921         0.960529               0.033551   \n1            0.009586         0.934714               0.055700   \n2            0.003428         0.976393               0.020179   \n3            0.004633         0.023985               0.971382   \n4            0.017428         0.633695               0.348877   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.022959         0.976533               0.000509   \n1            0.999611         0.000205               0.000185   \n2            0.002020         0.997897               0.000083   \n3            0.974441         0.024459               0.001100   \n4            0.984416         0.011166               0.004419   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.001848        0.998084              0.000067           0  \n1           0.951772        0.048075              0.000153           0  \n2           0.001014        0.998984              0.000002           0  \n3           0.996749        0.000989              0.002262           0  \n4           0.000518        0.128416              0.871066           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values_anli1 = combined_anli_r1_df.isnull().sum()\n\nmissing_values_anli2 = combined_anli_r2_df.isnull().sum()\n\nmissing_values_anli3 = combined_anli_r3_df.isnull().sum()\n\nmissing_values_snli = combined_snli_df.isnull().sum()\n\nmissing_values_mnli_matched = combined_mnli_matched_df.isnull().sum()\n\nmissing_values_mnli_mismatched = combined_mnli_mismatched_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.227699Z","iopub.execute_input":"2024-08-20T13:09:09.227995Z","iopub.status.idle":"2024-08-20T13:09:09.241297Z","shell.execute_reply.started":"2024-08-20T13:09:09.227955Z","shell.execute_reply":"2024-08-20T13:09:09.240410Z"},"trusted":true},"execution_count":408,"outputs":[]},{"cell_type":"code","source":"missing_values_anli1","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.242486Z","iopub.execute_input":"2024-08-20T13:09:09.242826Z","iopub.status.idle":"2024-08-20T13:09:09.253084Z","shell.execute_reply.started":"2024-08-20T13:09:09.242789Z","shell.execute_reply":"2024-08-20T13:09:09.252061Z"},"trusted":true},"execution_count":409,"outputs":[{"execution_count":409,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli2","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.254395Z","iopub.execute_input":"2024-08-20T13:09:09.255009Z","iopub.status.idle":"2024-08-20T13:09:09.265968Z","shell.execute_reply.started":"2024-08-20T13:09:09.254976Z","shell.execute_reply":"2024-08-20T13:09:09.265091Z"},"trusted":true},"execution_count":410,"outputs":[{"execution_count":410,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli3","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.267040Z","iopub.execute_input":"2024-08-20T13:09:09.267360Z","iopub.status.idle":"2024-08-20T13:09:09.277487Z","shell.execute_reply.started":"2024-08-20T13:09:09.267332Z","shell.execute_reply":"2024-08-20T13:09:09.276521Z"},"trusted":true},"execution_count":411,"outputs":[{"execution_count":411,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_snli","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.278611Z","iopub.execute_input":"2024-08-20T13:09:09.278882Z","iopub.status.idle":"2024-08-20T13:09:09.288186Z","shell.execute_reply.started":"2024-08-20T13:09:09.278857Z","shell.execute_reply":"2024-08-20T13:09:09.287350Z"},"trusted":true},"execution_count":412,"outputs":[{"execution_count":412,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment         0\nDeberta_Neutral            0\nDeberta_Contradiction      0\nRoberta_Entailment         0\nRoberta_Neutral            0\nRoberta_Contradiction      0\nAlbert_Entailment          0\nAlbert_Neutral             0\nAlbert_Contradiction       0\nTrue_Label               176\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.289419Z","iopub.execute_input":"2024-08-20T13:09:09.289752Z","iopub.status.idle":"2024-08-20T13:09:09.298437Z","shell.execute_reply.started":"2024-08-20T13:09:09.289721Z","shell.execute_reply":"2024-08-20T13:09:09.297542Z"},"trusted":true},"execution_count":413,"outputs":[{"execution_count":413,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.299697Z","iopub.execute_input":"2024-08-20T13:09:09.300462Z","iopub.status.idle":"2024-08-20T13:09:09.309740Z","shell.execute_reply.started":"2024-08-20T13:09:09.300436Z","shell.execute_reply":"2024-08-20T13:09:09.308858Z"},"trusted":true},"execution_count":414,"outputs":[{"execution_count":414,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"combined_snli_df.dropna(subset=['True_Label'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.311016Z","iopub.execute_input":"2024-08-20T13:09:09.311675Z","iopub.status.idle":"2024-08-20T13:09:09.322468Z","shell.execute_reply.started":"2024-08-20T13:09:09.311642Z","shell.execute_reply":"2024-08-20T13:09:09.321599Z"},"trusted":true},"execution_count":415,"outputs":[]},{"cell_type":"code","source":"# Verify missing values again after removal\nmissing_values_snli_after_removal = combined_snli_df.isnull().sum()\nprint(missing_values_snli_after_removal)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.323716Z","iopub.execute_input":"2024-08-20T13:09:09.324361Z","iopub.status.idle":"2024-08-20T13:09:09.333231Z","shell.execute_reply.started":"2024-08-20T13:09:09.324333Z","shell.execute_reply":"2024-08-20T13:09:09.332097Z"},"trusted":true},"execution_count":416,"outputs":[{"name":"stdout","text":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.334355Z","iopub.execute_input":"2024-08-20T13:09:09.334734Z","iopub.status.idle":"2024-08-20T13:09:09.346378Z","shell.execute_reply.started":"2024-08-20T13:09:09.334696Z","shell.execute_reply":"2024-08-20T13:09:09.345336Z"},"trusted":true},"execution_count":417,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9824 entries, 0 to 9999\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Deberta_Entailment     9824 non-null   float64\n 1   Deberta_Neutral        9824 non-null   float64\n 2   Deberta_Contradiction  9824 non-null   float64\n 3   Roberta_Entailment     9824 non-null   float64\n 4   Roberta_Neutral        9824 non-null   float64\n 5   Roberta_Contradiction  9824 non-null   float64\n 6   Albert_Entailment      9824 non-null   float64\n 7   Albert_Neutral         9824 non-null   float64\n 8   Albert_Contradiction   9824 non-null   float64\n 9   True_Label             9824 non-null   Int64  \ndtypes: Int64(1), float64(9)\nmemory usage: 853.8 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.347612Z","iopub.execute_input":"2024-08-20T13:09:09.347872Z","iopub.status.idle":"2024-08-20T13:09:09.366444Z","shell.execute_reply.started":"2024-08-20T13:09:09.347848Z","shell.execute_reply":"2024-08-20T13:09:09.365525Z"},"trusted":true},"execution_count":418,"outputs":[{"execution_count":418,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.034767         0.962592               0.002641   \n1               0.001921         0.319032               0.679047   \n2               0.998783         0.000764               0.000453   \n3               0.001001         0.997708               0.001291   \n4               0.001080         0.301363               0.697557   \n...                  ...              ...                    ...   \n9995            0.998825         0.001033               0.000142   \n9996            0.000704         0.009793               0.989503   \n9997            0.999171         0.000493               0.000336   \n9998            0.000267         0.002178               0.997556   \n9999            0.003641         0.995224               0.001135   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.012451         0.927093               0.060457   \n1               0.752766         0.242251               0.004983   \n2               0.000254         0.004494               0.995253   \n3               0.005844         0.990736               0.003419   \n4               0.278348         0.718575               0.003076   \n...                  ...              ...                    ...   \n9995            0.001264         0.028942               0.969794   \n9996            0.780946         0.217053               0.002001   \n9997            0.000054         0.000765               0.999181   \n9998            0.983402         0.015884               0.000714   \n9999            0.000904         0.995495               0.003601   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0              0.008653        0.947434              0.043913           1  \n1              0.740332        0.256434              0.003235           0  \n2              0.004677        0.060481              0.934843           2  \n3              0.034056        0.956687              0.009257           1  \n4              0.498761        0.499270              0.001969           0  \n...                 ...             ...                   ...         ...  \n9995           0.006420        0.057240              0.936340           2  \n9996           0.894637        0.104095              0.001267           0  \n9997           0.000838        0.002670              0.996493           2  \n9998           0.984347        0.015223              0.000430           0  \n9999           0.005047        0.990218              0.004735           1  \n\n[9824 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>0.998825</td>\n      <td>0.001033</td>\n      <td>0.000142</td>\n      <td>0.001264</td>\n      <td>0.028942</td>\n      <td>0.969794</td>\n      <td>0.006420</td>\n      <td>0.057240</td>\n      <td>0.936340</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.000704</td>\n      <td>0.009793</td>\n      <td>0.989503</td>\n      <td>0.780946</td>\n      <td>0.217053</td>\n      <td>0.002001</td>\n      <td>0.894637</td>\n      <td>0.104095</td>\n      <td>0.001267</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.999171</td>\n      <td>0.000493</td>\n      <td>0.000336</td>\n      <td>0.000054</td>\n      <td>0.000765</td>\n      <td>0.999181</td>\n      <td>0.000838</td>\n      <td>0.002670</td>\n      <td>0.996493</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>0.000267</td>\n      <td>0.002178</td>\n      <td>0.997556</td>\n      <td>0.983402</td>\n      <td>0.015884</td>\n      <td>0.000714</td>\n      <td>0.984347</td>\n      <td>0.015223</td>\n      <td>0.000430</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.003641</td>\n      <td>0.995224</td>\n      <td>0.001135</td>\n      <td>0.000904</td>\n      <td>0.995495</td>\n      <td>0.003601</td>\n      <td>0.005047</td>\n      <td>0.990218</td>\n      <td>0.004735</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9824 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef calculate_margin(row):\n    # Assuming the row only contains the probabilities\n    sorted_probs = np.sort(row)  # Sort probabilities in ascending order\n    if len(sorted_probs) > 1:\n        return sorted_probs[-1] - sorted_probs[-2]  # Difference between the highest and second highest\n    else:\n        return 0  # This handles the edge case where there is only one probability value\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.367617Z","iopub.execute_input":"2024-08-20T13:09:09.367904Z","iopub.status.idle":"2024-08-20T13:09:09.375765Z","shell.execute_reply.started":"2024-08-20T13:09:09.367877Z","shell.execute_reply":"2024-08-20T13:09:09.375005Z"},"trusted":true},"execution_count":419,"outputs":[]},{"cell_type":"code","source":"# Applying to a sample DataFrame with made-up column names\ncombined_snli_df['confidence_margin_entailment'] = combined_snli_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_snli_df['confidence_margin_neutral'] = combined_snli_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_snli_df['confidence_margin_contradiction'] = combined_snli_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n\n\n# Applying to a sample DataFrame with made-up column names\ncombined_mnli_matched_df['confidence_margin_entailment'] = combined_mnli_matched_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_mnli_matched_df['confidence_margin_neutral'] = combined_mnli_matched_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_mnli_matched_df['confidence_margin_contradiction'] = combined_mnli_matched_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n\n# Applying to a sample DataFrame with made-up column names\ncombined_mnli_mismatched_df['confidence_margin_entailment'] = combined_mnli_mismatched_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_mnli_mismatched_df['confidence_margin_neutral'] = combined_mnli_mismatched_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_mnli_mismatched_df['confidence_margin_contradiction'] = combined_mnli_mismatched_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n\n# Applying to a sample DataFrame with made-up column names\ncombined_anli_r1_df['confidence_margin_entailment'] = combined_anli_r1_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_anli_r1_df['confidence_margin_neutral'] = combined_anli_r1_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_anli_r1_df['confidence_margin_contradiction'] = combined_anli_r1_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n\n\n# Applying to a sample DataFrame with made-up column names\ncombined_anli_r2_df['confidence_margin_entailment'] = combined_anli_r2_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_anli_r2_df['confidence_margin_neutral'] = combined_anli_r2_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_anli_r2_df['confidence_margin_contradiction'] = combined_anli_r2_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n\n\n# Applying to a sample DataFrame with made-up column names\ncombined_anli_r3_df['confidence_margin_entailment'] = combined_anli_r3_df[['Deberta_Entailment', 'Roberta_Entailment', 'Albert_Entailment']].apply(calculate_margin, axis=1)\ncombined_anli_r3_df['confidence_margin_neutral'] = combined_anli_r3_df[['Deberta_Neutral', 'Roberta_Neutral', 'Albert_Neutral']].apply(calculate_margin, axis=1)\ncombined_anli_r3_df['confidence_margin_contradiction'] = combined_anli_r3_df[['Deberta_Contradiction', 'Roberta_Contradiction', 'Albert_Contradiction']].apply(calculate_margin, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:09.377098Z","iopub.execute_input":"2024-08-20T13:09:09.377428Z","iopub.status.idle":"2024-08-20T13:09:12.242501Z","shell.execute_reply.started":"2024-08-20T13:09:09.377397Z","shell.execute_reply":"2024-08-20T13:09:12.241667Z"},"trusted":true},"execution_count":420,"outputs":[]},{"cell_type":"code","source":"combined_anli_r3_df","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:12.243648Z","iopub.execute_input":"2024-08-20T13:09:12.243948Z","iopub.status.idle":"2024-08-20T13:09:12.265484Z","shell.execute_reply.started":"2024-08-20T13:09:12.243922Z","shell.execute_reply":"2024-08-20T13:09:12.264539Z"},"trusted":true},"execution_count":421,"outputs":[{"execution_count":421,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.005921         0.960529               0.033551   \n1               0.009586         0.934714               0.055700   \n2               0.003428         0.976393               0.020179   \n3               0.004633         0.023985               0.971382   \n4               0.017428         0.633695               0.348877   \n...                  ...              ...                    ...   \n1195            0.150312         0.806051               0.043637   \n1196            0.971834         0.026294               0.001872   \n1197            0.973818         0.025074               0.001109   \n1198            0.341781         0.226539               0.431681   \n1199            0.472737         0.477215               0.050049   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.022959         0.976533               0.000509   \n1               0.999611         0.000205               0.000185   \n2               0.002020         0.997897               0.000083   \n3               0.974441         0.024459               0.001100   \n4               0.984416         0.011166               0.004419   \n...                  ...              ...                    ...   \n1195            0.032452         0.068553               0.898994   \n1196            0.009070         0.824654               0.166276   \n1197            0.000352         0.000972               0.998677   \n1198            0.006147         0.073669               0.920184   \n1199            0.000420         0.991832               0.007748   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n0              0.001848        0.998084              0.000067           0   \n1              0.951772        0.048075              0.000153           0   \n2              0.001014        0.998984              0.000002           0   \n3              0.996749        0.000989              0.002262           0   \n4              0.000518        0.128416              0.871066           0   \n...                 ...             ...                   ...         ...   \n1195           0.122045        0.254093              0.623862           2   \n1196           0.001115        0.003229              0.995656           2   \n1197           0.310862        0.618914              0.070225           2   \n1198           0.054172        0.317935              0.627893           2   \n1199           0.015091        0.121354              0.863554           2   \n\n      confidence_margin_entailment  confidence_margin_neutral  \\\n0                         0.017038                   0.021552   \n1                         0.047839                   0.886640   \n2                         0.001408                   0.001087   \n3                         0.022308                   0.000474   \n4                         0.966988                   0.505279   \n...                            ...                        ...   \n1195                      0.028268                   0.551958   \n1196                      0.962764                   0.798360   \n1197                      0.662956                   0.593840   \n1198                      0.287609                   0.091397   \n1199                      0.457646                   0.514617   \n\n      confidence_margin_contradiction  \n0                            0.033042  \n1                            0.055515  \n2                            0.020096  \n3                            0.969120  \n4                            0.522189  \n...                               ...  \n1195                         0.275132  \n1196                         0.829379  \n1197                         0.928452  \n1198                         0.292291  \n1199                         0.813506  \n\n[1200 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>confidence_margin_entailment</th>\n      <th>confidence_margin_neutral</th>\n      <th>confidence_margin_contradiction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n      <td>0.017038</td>\n      <td>0.021552</td>\n      <td>0.033042</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n      <td>0.047839</td>\n      <td>0.886640</td>\n      <td>0.055515</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n      <td>0.001408</td>\n      <td>0.001087</td>\n      <td>0.020096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n      <td>0.022308</td>\n      <td>0.000474</td>\n      <td>0.969120</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n      <td>0.966988</td>\n      <td>0.505279</td>\n      <td>0.522189</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>0.150312</td>\n      <td>0.806051</td>\n      <td>0.043637</td>\n      <td>0.032452</td>\n      <td>0.068553</td>\n      <td>0.898994</td>\n      <td>0.122045</td>\n      <td>0.254093</td>\n      <td>0.623862</td>\n      <td>2</td>\n      <td>0.028268</td>\n      <td>0.551958</td>\n      <td>0.275132</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>0.971834</td>\n      <td>0.026294</td>\n      <td>0.001872</td>\n      <td>0.009070</td>\n      <td>0.824654</td>\n      <td>0.166276</td>\n      <td>0.001115</td>\n      <td>0.003229</td>\n      <td>0.995656</td>\n      <td>2</td>\n      <td>0.962764</td>\n      <td>0.798360</td>\n      <td>0.829379</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>0.973818</td>\n      <td>0.025074</td>\n      <td>0.001109</td>\n      <td>0.000352</td>\n      <td>0.000972</td>\n      <td>0.998677</td>\n      <td>0.310862</td>\n      <td>0.618914</td>\n      <td>0.070225</td>\n      <td>2</td>\n      <td>0.662956</td>\n      <td>0.593840</td>\n      <td>0.928452</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>0.341781</td>\n      <td>0.226539</td>\n      <td>0.431681</td>\n      <td>0.006147</td>\n      <td>0.073669</td>\n      <td>0.920184</td>\n      <td>0.054172</td>\n      <td>0.317935</td>\n      <td>0.627893</td>\n      <td>2</td>\n      <td>0.287609</td>\n      <td>0.091397</td>\n      <td>0.292291</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>0.472737</td>\n      <td>0.477215</td>\n      <td>0.050049</td>\n      <td>0.000420</td>\n      <td>0.991832</td>\n      <td>0.007748</td>\n      <td>0.015091</td>\n      <td>0.121354</td>\n      <td>0.863554</td>\n      <td>2</td>\n      <td>0.457646</td>\n      <td>0.514617</td>\n      <td>0.813506</td>\n    </tr>\n  </tbody>\n</table>\n<p>1200 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot histograms for the confidence margins\ndef plot_confidence_margins(df):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.hist(df['confidence_margin_entailment'], bins=50, alpha=0.75, label='Entailment')\n    plt.title('Confidence Margin Histogram - Entailment')\n    plt.xlabel('Margin')\n    plt.ylabel('Frequency')\n    \n    plt.subplot(1, 3, 2)\n    plt.hist(df['confidence_margin_neutral'], bins=50, alpha=0.75, label='Neutral', color='green')\n    plt.title('Confidence Margin Histogram - Neutral')\n    plt.xlabel('Margin')\n    plt.ylabel('Frequency')\n    \n    plt.subplot(1, 3, 3)\n    plt.hist(df['confidence_margin_contradiction'], bins=50, alpha=0.75, label='Contradiction', color='red')\n    plt.title('Confidence Margin Histogram - Contradiction')\n    plt.xlabel('Margin')\n    plt.ylabel('Frequency')\n    \n    plt.tight_layout()\n    plt.show()\n\nplot_confidence_margins(combined_snli_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:12.266799Z","iopub.execute_input":"2024-08-20T13:09:12.267185Z","iopub.status.idle":"2024-08-20T13:09:13.229663Z","shell.execute_reply.started":"2024-08-20T13:09:12.267150Z","shell.execute_reply":"2024-08-20T13:09:13.228593Z"},"trusted":true},"execution_count":422,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 3 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Define thresholds based on the distribution\nconfidence_threshold = 0.8\n\n# Apply threshold and create a new copy of the DataFrame\nhigh_confidence_snli = combined_snli_df[\n    (combined_snli_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_snli_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_snli_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()\n\n\n# Apply threshold and create a new copy of the DataFrame\nhigh_confidence_mnli_matched = combined_mnli_matched_df[\n    (combined_mnli_matched_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_mnli_matched_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_mnli_matched_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()\n\n# Apply threshold and create a new copy of the DataFrame\nhigh_confidence_mnli_mismatched = combined_mnli_mismatched_df[\n    (combined_mnli_mismatched_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_mnli_mismatched_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_mnli_mismatched_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()\n\n# Filter high confidence samples for ANLI round 1\nhigh_confidence_anli_r1 = combined_anli_r1_df[\n    (combined_anli_r1_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_anli_r1_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_anli_r1_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()\n\n# Filter high confidence samples for ANLI round 2\nhigh_confidence_anli_r2 = combined_anli_r2_df[\n    (combined_anli_r2_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_anli_r2_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_anli_r2_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()\n\n# Filter high confidence samples for ANLI round 3\nhigh_confidence_anli_r3 = combined_anli_r3_df[\n    (combined_anli_r3_df['confidence_margin_entailment'] >= confidence_threshold) | \n    (combined_anli_r3_df['confidence_margin_neutral'] >= confidence_threshold) |\n    (combined_anli_r3_df['confidence_margin_contradiction'] >= confidence_threshold)\n].copy()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:13.235240Z","iopub.execute_input":"2024-08-20T13:09:13.235559Z","iopub.status.idle":"2024-08-20T13:09:13.261980Z","shell.execute_reply.started":"2024-08-20T13:09:13.235530Z","shell.execute_reply":"2024-08-20T13:09:13.260891Z"},"trusted":true},"execution_count":423,"outputs":[]},{"cell_type":"code","source":"# Majority vote logic with weights for numeric labels\ndef majority_vote_with_threshold(row):\n    votes = [0, 0, 0]  # Index 0 for entailment, 1 for neutral, 2 for contradiction\n    if row['confidence_margin_entailment'] >= confidence_threshold:\n        votes[0] += row['confidence_margin_entailment']\n    if row['confidence_margin_neutral'] >= confidence_threshold:\n        votes[1] += row['confidence_margin_neutral']\n    if row['confidence_margin_contradiction'] >= confidence_threshold:\n        votes[2] += row['confidence_margin_contradiction']\n    \n    # Return the index of the highest vote\n    return np.argmax(votes)\n\n# Apply the majority vote logic using .loc\nhigh_confidence_snli.loc[:, 'majority_vote'] = high_confidence_snli.apply(majority_vote_with_threshold, axis=1)\n# Apply the majority vote logic using .loc\nhigh_confidence_mnli_matched.loc[:, 'majority_vote'] = high_confidence_mnli_matched.apply(majority_vote_with_threshold, axis=1)\n# Apply majority vote logic\nhigh_confidence_mnli_mismatched.loc[:, 'majority_vote'] = high_confidence_mnli_mismatched.apply(majority_vote_with_threshold, axis=1)\n# Apply majority vote logic\nhigh_confidence_anli_r1.loc[:, 'majority_vote'] = high_confidence_anli_r1.apply(majority_vote_with_threshold, axis=1)\n# Apply majority vote logic\nhigh_confidence_anli_r2.loc[:, 'majority_vote'] = high_confidence_anli_r2.apply(majority_vote_with_threshold, axis=1)\n# Apply majority vote logic\nhigh_confidence_anli_r3.loc[:, 'majority_vote'] = high_confidence_anli_r3.apply(majority_vote_with_threshold, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:13.264954Z","iopub.execute_input":"2024-08-20T13:09:13.265277Z","iopub.status.idle":"2024-08-20T13:09:14.824164Z","shell.execute_reply.started":"2024-08-20T13:09:13.265251Z","shell.execute_reply":"2024-08-20T13:09:14.823250Z"},"trusted":true},"execution_count":424,"outputs":[]},{"cell_type":"code","source":"high_confidence_anli_r3","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.825256Z","iopub.execute_input":"2024-08-20T13:09:14.825572Z","iopub.status.idle":"2024-08-20T13:09:14.849742Z","shell.execute_reply.started":"2024-08-20T13:09:14.825544Z","shell.execute_reply":"2024-08-20T13:09:14.848574Z"},"trusted":true},"execution_count":425,"outputs":[{"execution_count":425,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n1               0.009586         0.934714               0.055700   \n3               0.004633         0.023985               0.971382   \n4               0.017428         0.633695               0.348877   \n5               0.002461         0.150678               0.846861   \n8               0.131793         0.776056               0.092151   \n...                  ...              ...                    ...   \n1193            0.957103         0.040533               0.002363   \n1194            0.945850         0.052813               0.001337   \n1196            0.971834         0.026294               0.001872   \n1197            0.973818         0.025074               0.001109   \n1199            0.472737         0.477215               0.050049   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n1               0.999611         0.000205               0.000185   \n3               0.974441         0.024459               0.001100   \n4               0.984416         0.011166               0.004419   \n5               0.999220         0.000554               0.000227   \n8               0.000384         0.002570               0.997046   \n...                  ...              ...                    ...   \n1193            0.000066         0.000316               0.999618   \n1194            0.000607         0.000853               0.998540   \n1196            0.009070         0.824654               0.166276   \n1197            0.000352         0.000972               0.998677   \n1199            0.000420         0.991832               0.007748   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n1              0.951772        0.048075              0.000153           0   \n3              0.996749        0.000989              0.002262           0   \n4              0.000518        0.128416              0.871066           0   \n5              0.985221        0.014745              0.000034           0   \n8              0.049409        0.904356              0.046236           0   \n...                 ...             ...                   ...         ...   \n1193           0.009265        0.016116              0.974619           2   \n1194           0.000205        0.000291              0.999504           2   \n1196           0.001115        0.003229              0.995656           2   \n1197           0.310862        0.618914              0.070225           2   \n1199           0.015091        0.121354              0.863554           2   \n\n      confidence_margin_entailment  confidence_margin_neutral  \\\n1                         0.047839                   0.886640   \n3                         0.022308                   0.000474   \n4                         0.966988                   0.505279   \n5                         0.013998                   0.135933   \n8                         0.082384                   0.128299   \n...                            ...                        ...   \n1193                      0.947838                   0.024417   \n1194                      0.945243                   0.051960   \n1196                      0.962764                   0.798360   \n1197                      0.662956                   0.593840   \n1199                      0.457646                   0.514617   \n\n      confidence_margin_contradiction  majority_vote  \n1                            0.055515              1  \n3                            0.969120              2  \n4                            0.522189              0  \n5                            0.846635              2  \n8                            0.904895              2  \n...                               ...            ...  \n1193                         0.024999              0  \n1194                         0.000965              0  \n1196                         0.829379              0  \n1197                         0.928452              2  \n1199                         0.813506              2  \n\n[530 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>confidence_margin_entailment</th>\n      <th>confidence_margin_neutral</th>\n      <th>confidence_margin_contradiction</th>\n      <th>majority_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n      <td>0.047839</td>\n      <td>0.886640</td>\n      <td>0.055515</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n      <td>0.022308</td>\n      <td>0.000474</td>\n      <td>0.969120</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n      <td>0.966988</td>\n      <td>0.505279</td>\n      <td>0.522189</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.002461</td>\n      <td>0.150678</td>\n      <td>0.846861</td>\n      <td>0.999220</td>\n      <td>0.000554</td>\n      <td>0.000227</td>\n      <td>0.985221</td>\n      <td>0.014745</td>\n      <td>0.000034</td>\n      <td>0</td>\n      <td>0.013998</td>\n      <td>0.135933</td>\n      <td>0.846635</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.131793</td>\n      <td>0.776056</td>\n      <td>0.092151</td>\n      <td>0.000384</td>\n      <td>0.002570</td>\n      <td>0.997046</td>\n      <td>0.049409</td>\n      <td>0.904356</td>\n      <td>0.046236</td>\n      <td>0</td>\n      <td>0.082384</td>\n      <td>0.128299</td>\n      <td>0.904895</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1193</th>\n      <td>0.957103</td>\n      <td>0.040533</td>\n      <td>0.002363</td>\n      <td>0.000066</td>\n      <td>0.000316</td>\n      <td>0.999618</td>\n      <td>0.009265</td>\n      <td>0.016116</td>\n      <td>0.974619</td>\n      <td>2</td>\n      <td>0.947838</td>\n      <td>0.024417</td>\n      <td>0.024999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1194</th>\n      <td>0.945850</td>\n      <td>0.052813</td>\n      <td>0.001337</td>\n      <td>0.000607</td>\n      <td>0.000853</td>\n      <td>0.998540</td>\n      <td>0.000205</td>\n      <td>0.000291</td>\n      <td>0.999504</td>\n      <td>2</td>\n      <td>0.945243</td>\n      <td>0.051960</td>\n      <td>0.000965</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>0.971834</td>\n      <td>0.026294</td>\n      <td>0.001872</td>\n      <td>0.009070</td>\n      <td>0.824654</td>\n      <td>0.166276</td>\n      <td>0.001115</td>\n      <td>0.003229</td>\n      <td>0.995656</td>\n      <td>2</td>\n      <td>0.962764</td>\n      <td>0.798360</td>\n      <td>0.829379</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>0.973818</td>\n      <td>0.025074</td>\n      <td>0.001109</td>\n      <td>0.000352</td>\n      <td>0.000972</td>\n      <td>0.998677</td>\n      <td>0.310862</td>\n      <td>0.618914</td>\n      <td>0.070225</td>\n      <td>2</td>\n      <td>0.662956</td>\n      <td>0.593840</td>\n      <td>0.928452</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1199</th>\n      <td>0.472737</td>\n      <td>0.477215</td>\n      <td>0.050049</td>\n      <td>0.000420</td>\n      <td>0.991832</td>\n      <td>0.007748</td>\n      <td>0.015091</td>\n      <td>0.121354</td>\n      <td>0.863554</td>\n      <td>2</td>\n      <td>0.457646</td>\n      <td>0.514617</td>\n      <td>0.813506</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>530 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"high_confidence_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.850940Z","iopub.execute_input":"2024-08-20T13:09:14.851270Z","iopub.status.idle":"2024-08-20T13:09:14.880154Z","shell.execute_reply.started":"2024-08-20T13:09:14.851241Z","shell.execute_reply":"2024-08-20T13:09:14.879035Z"},"trusted":true},"execution_count":426,"outputs":[{"execution_count":426,"output_type":"execute_result","data":{"text/plain":"      Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0               0.999667         0.000160               0.000173   \n1               0.998119         0.000962               0.000919   \n2               0.000552         0.004809               0.994639   \n3               0.827653         0.171961               0.000386   \n4               0.000292         0.002875               0.996833   \n...                  ...              ...                    ...   \n9824            0.000760         0.013837               0.985402   \n9825            0.000145         0.003906               0.995949   \n9826            0.996226         0.003656               0.000118   \n9828            0.997044         0.001226               0.001730   \n9829            0.999685         0.000112               0.000202   \n\n      Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0               0.000068         0.000402               0.999529   \n1               0.000183         0.001511               0.998306   \n2               0.986062         0.012020               0.001918   \n3               0.000478         0.270953               0.728569   \n4               0.975167         0.021904               0.002929   \n...                  ...              ...                    ...   \n9824            0.972984         0.025382               0.001634   \n9825            0.952827         0.045891               0.001281   \n9826            0.000353         0.104717               0.894930   \n9828            0.000364         0.000717               0.998919   \n9829            0.000085         0.000289               0.999626   \n\n      Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \\\n0              0.000894        0.003787              0.995318           2   \n1              0.006421        0.010224              0.983355           2   \n2              0.975041        0.023354              0.001605           0   \n3              0.001722        0.796122              0.202156           2   \n4              0.965952        0.032748              0.001300           0   \n...                 ...             ...                   ...         ...   \n9824           0.925212        0.069991              0.004798           0   \n9825           0.965645        0.032757              0.001598           0   \n9826           0.004991        0.039946              0.955062           2   \n9828           0.019078        0.039258              0.941663           2   \n9829           0.000420        0.001810              0.997770           2   \n\n      confidence_margin_entailment  confidence_margin_neutral  \\\n0                         0.998773                   0.003385   \n1                         0.991698                   0.008714   \n2                         0.011021                   0.011334   \n3                         0.825931                   0.525168   \n4                         0.009215                   0.010844   \n...                            ...                        ...   \n9824                      0.047772                   0.044608   \n9825                      0.012818                   0.013134   \n9826                      0.991234                   0.064771   \n9828                      0.977966                   0.038033   \n9829                      0.999265                   0.001521   \n\n      confidence_margin_contradiction  majority_vote  \n0                            0.004211              0  \n1                            0.014951              0  \n2                            0.992721              2  \n3                            0.526413              0  \n4                            0.993904              2  \n...                               ...            ...  \n9824                         0.980605              2  \n9825                         0.994351              2  \n9826                         0.060132              0  \n9828                         0.057256              0  \n9829                         0.001856              0  \n\n[5910 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n      <th>confidence_margin_entailment</th>\n      <th>confidence_margin_neutral</th>\n      <th>confidence_margin_contradiction</th>\n      <th>majority_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n      <td>0.998773</td>\n      <td>0.003385</td>\n      <td>0.004211</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n      <td>0.991698</td>\n      <td>0.008714</td>\n      <td>0.014951</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n      <td>0.011021</td>\n      <td>0.011334</td>\n      <td>0.992721</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n      <td>0.825931</td>\n      <td>0.525168</td>\n      <td>0.526413</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n      <td>0.009215</td>\n      <td>0.010844</td>\n      <td>0.993904</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9824</th>\n      <td>0.000760</td>\n      <td>0.013837</td>\n      <td>0.985402</td>\n      <td>0.972984</td>\n      <td>0.025382</td>\n      <td>0.001634</td>\n      <td>0.925212</td>\n      <td>0.069991</td>\n      <td>0.004798</td>\n      <td>0</td>\n      <td>0.047772</td>\n      <td>0.044608</td>\n      <td>0.980605</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9825</th>\n      <td>0.000145</td>\n      <td>0.003906</td>\n      <td>0.995949</td>\n      <td>0.952827</td>\n      <td>0.045891</td>\n      <td>0.001281</td>\n      <td>0.965645</td>\n      <td>0.032757</td>\n      <td>0.001598</td>\n      <td>0</td>\n      <td>0.012818</td>\n      <td>0.013134</td>\n      <td>0.994351</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9826</th>\n      <td>0.996226</td>\n      <td>0.003656</td>\n      <td>0.000118</td>\n      <td>0.000353</td>\n      <td>0.104717</td>\n      <td>0.894930</td>\n      <td>0.004991</td>\n      <td>0.039946</td>\n      <td>0.955062</td>\n      <td>2</td>\n      <td>0.991234</td>\n      <td>0.064771</td>\n      <td>0.060132</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9828</th>\n      <td>0.997044</td>\n      <td>0.001226</td>\n      <td>0.001730</td>\n      <td>0.000364</td>\n      <td>0.000717</td>\n      <td>0.998919</td>\n      <td>0.019078</td>\n      <td>0.039258</td>\n      <td>0.941663</td>\n      <td>2</td>\n      <td>0.977966</td>\n      <td>0.038033</td>\n      <td>0.057256</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9829</th>\n      <td>0.999685</td>\n      <td>0.000112</td>\n      <td>0.000202</td>\n      <td>0.000085</td>\n      <td>0.000289</td>\n      <td>0.999626</td>\n      <td>0.000420</td>\n      <td>0.001810</td>\n      <td>0.997770</td>\n      <td>2</td>\n      <td>0.999265</td>\n      <td>0.001521</td>\n      <td>0.001856</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5910 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n\n\n# Features and Labels\nX_snli = high_confidence_snli.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_snli = high_confidence_snli['True_Label'].values\n\n# Features and Labels\nX_mnli_matched = high_confidence_mnli_matched.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_mnli_matched = high_confidence_mnli_matched['True_Label'].values\n\n# Features and Labels\nX_mnli_mismatched = high_confidence_mnli_mismatched.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_mnli_mismatched = high_confidence_mnli_mismatched['True_Label'].values\n\n# Features and Labels\nX_anli_r1 = high_confidence_anli_r1.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_anli_r1 = high_confidence_anli_r1['True_Label'].values\n\n# Features and Labels\nX_anli_r2 = high_confidence_anli_r2.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_anli_r2 = high_confidence_anli_r2['True_Label'].values\n\n# Features and Labels\nX_anli_r3 = high_confidence_anli_r3.drop(['True_Label','confidence_margin_entailment','confidence_margin_neutral','confidence_margin_contradiction','majority_vote'], axis=1).values\ny_anli_r3 = high_confidence_anli_r3['True_Label'].values\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.881576Z","iopub.execute_input":"2024-08-20T13:09:14.882235Z","iopub.status.idle":"2024-08-20T13:09:14.896691Z","shell.execute_reply.started":"2024-08-20T13:09:14.882199Z","shell.execute_reply":"2024-08-20T13:09:14.895699Z"},"trusted":true},"execution_count":427,"outputs":[]},{"cell_type":"code","source":"# Extract only the additional features from each dataset\nfeatures_snli = high_confidence_snli[['confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\nfeatures_mnli_matched = high_confidence_mnli_matched[[ 'confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\nfeatures_mnli_mismatched = high_confidence_mnli_mismatched[[ 'confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\nfeatures_anli_r1 = high_confidence_anli_r1[[ 'confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\nfeatures_anli_r2 = high_confidence_anli_r2[[ 'confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\nfeatures_anli_r3 = high_confidence_anli_r3[[ 'confidence_margin_entailment', 'confidence_margin_neutral', 'confidence_margin_contradiction']].values\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.897933Z","iopub.execute_input":"2024-08-20T13:09:14.898250Z","iopub.status.idle":"2024-08-20T13:09:14.911243Z","shell.execute_reply.started":"2024-08-20T13:09:14.898224Z","shell.execute_reply":"2024-08-20T13:09:14.910390Z"},"trusted":true},"execution_count":428,"outputs":[]},{"cell_type":"code","source":"X_snli","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.912459Z","iopub.execute_input":"2024-08-20T13:09:14.912834Z","iopub.status.idle":"2024-08-20T13:09:14.922819Z","shell.execute_reply.started":"2024-08-20T13:09:14.912807Z","shell.execute_reply":"2024-08-20T13:09:14.921813Z"},"trusted":true},"execution_count":429,"outputs":[{"execution_count":429,"output_type":"execute_result","data":{"text/plain":"array([[9.9878270e-01, 7.6433434e-04, 4.5297167e-04, ..., 4.6765395e-03,\n        6.0480673e-02, 9.3484277e-01],\n       [5.0442386e-04, 4.3001700e-03, 9.9519530e-01, ..., 9.7817034e-01,\n        2.1051416e-02, 7.7824460e-04],\n       [9.8957914e-01, 5.4418677e-03, 4.9790350e-03, ..., 8.5550435e-02,\n        7.5036585e-02, 8.3941300e-01],\n       ...,\n       [7.0376875e-04, 9.7931010e-03, 9.8950315e-01, ..., 8.9463750e-01,\n        1.0409502e-01, 1.2674012e-03],\n       [9.9917114e-01, 4.9286430e-04, 3.3603658e-04, ..., 8.3751883e-04,\n        2.6697412e-03, 9.9649280e-01],\n       [2.6664520e-04, 2.1777824e-03, 9.9755560e-01, ..., 9.8434700e-01,\n        1.5223468e-02, 4.2961346e-04]])"},"metadata":{}}]},{"cell_type":"code","source":"features_snli","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.924052Z","iopub.execute_input":"2024-08-20T13:09:14.924856Z","iopub.status.idle":"2024-08-20T13:09:14.932873Z","shell.execute_reply.started":"2024-08-20T13:09:14.924821Z","shell.execute_reply":"2024-08-20T13:09:14.931938Z"},"trusted":true},"execution_count":430,"outputs":[{"execution_count":430,"output_type":"execute_result","data":{"text/plain":"array([[9.94106161e-01, 5.59870956e-02, 6.04100800e-02],\n       [5.73736000e-03, 5.89017100e-03, 9.94264296e-01],\n       [9.04028705e-01, 1.89172950e-02, 3.66324000e-02],\n       ...,\n       [1.13691360e-01, 1.12957690e-01, 9.87502096e-01],\n       [9.98333621e-01, 1.90469200e-03, 2.68793000e-03],\n       [9.45200000e-04, 6.61004000e-04, 9.96841898e-01]])"},"metadata":{}}]},{"cell_type":"code","source":"# One-hot encode labels for each dataset using TensorFlow/Keras utility\ny_encoded_snli = tf.keras.utils.to_categorical(y_snli)\ny_encoded_mnli_matched = tf.keras.utils.to_categorical(y_mnli_matched)\ny_encoded_mnli_mismatched = tf.keras.utils.to_categorical(y_mnli_mismatched)\ny_encoded_anli_r1 = tf.keras.utils.to_categorical(y_anli_r1)\ny_encoded_anli_r2 = tf.keras.utils.to_categorical(y_anli_r2)\ny_encoded_anli_r3 = tf.keras.utils.to_categorical(y_anli_r3)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.933989Z","iopub.execute_input":"2024-08-20T13:09:14.934286Z","iopub.status.idle":"2024-08-20T13:09:14.942305Z","shell.execute_reply.started":"2024-08-20T13:09:14.934261Z","shell.execute_reply":"2024-08-20T13:09:14.941513Z"},"trusted":true},"execution_count":431,"outputs":[]},{"cell_type":"code","source":"X_snli_rnn = X_snli.reshape(X_snli.shape[0], 1, X_snli.shape[1])\nX_mnli_matched_rnn = X_mnli_matched.reshape(X_mnli_matched.shape[0], 1, X_mnli_matched.shape[1])\nX_mnli_mismatched_rnn = X_mnli_mismatched.reshape(X_mnli_mismatched.shape[0], 1, X_mnli_mismatched.shape[1])\nX_anli_r1_rnn = X_anli_r1.reshape(X_anli_r1.shape[0], 1, X_anli_r1.shape[1])\nX_anli_r2_rnn = X_anli_r2.reshape(X_anli_r2.shape[0], 1, X_anli_r2.shape[1])\nX_anli_r3_rnn = X_anli_r3.reshape(X_anli_r3.shape[0], 1, X_anli_r3.shape[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.943602Z","iopub.execute_input":"2024-08-20T13:09:14.944404Z","iopub.status.idle":"2024-08-20T13:09:14.951546Z","shell.execute_reply.started":"2024-08-20T13:09:14.944375Z","shell.execute_reply":"2024-08-20T13:09:14.950642Z"},"trusted":true},"execution_count":432,"outputs":[]},{"cell_type":"code","source":"# Reshape feature arrays to match the RNN input shape\nfeatures_snli = features_snli.reshape(features_snli.shape[0], 1, features_snli.shape[1])\nfeatures_mnli_matched = features_mnli_matched.reshape(features_mnli_matched.shape[0], 1, features_mnli_matched.shape[1])\nfeatures_mnli_mismatched = features_mnli_mismatched.reshape(features_mnli_mismatched.shape[0], 1, features_mnli_mismatched.shape[1])\nfeatures_anli_r1 = features_anli_r1.reshape(features_anli_r1.shape[0], 1, features_anli_r1.shape[1])\nfeatures_anli_r2 = features_anli_r2.reshape(features_anli_r2.shape[0], 1, features_anli_r2.shape[1])\nfeatures_anli_r3 = features_anli_r3.reshape(features_anli_r3.shape[0], 1, features_anli_r3.shape[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.952901Z","iopub.execute_input":"2024-08-20T13:09:14.953181Z","iopub.status.idle":"2024-08-20T13:09:14.963325Z","shell.execute_reply.started":"2024-08-20T13:09:14.953157Z","shell.execute_reply":"2024-08-20T13:09:14.962434Z"},"trusted":true},"execution_count":433,"outputs":[]},{"cell_type":"code","source":"features_snli.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.964475Z","iopub.execute_input":"2024-08-20T13:09:14.964804Z","iopub.status.idle":"2024-08-20T13:09:14.980993Z","shell.execute_reply.started":"2024-08-20T13:09:14.964772Z","shell.execute_reply":"2024-08-20T13:09:14.980143Z"},"trusted":true},"execution_count":434,"outputs":[{"execution_count":434,"output_type":"execute_result","data":{"text/plain":"(6032, 1, 3)"},"metadata":{}}]},{"cell_type":"code","source":"X_snli_rnn","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.982183Z","iopub.execute_input":"2024-08-20T13:09:14.982484Z","iopub.status.idle":"2024-08-20T13:09:14.993205Z","shell.execute_reply.started":"2024-08-20T13:09:14.982458Z","shell.execute_reply":"2024-08-20T13:09:14.992230Z"},"trusted":true},"execution_count":435,"outputs":[{"execution_count":435,"output_type":"execute_result","data":{"text/plain":"array([[[9.9878270e-01, 7.6433434e-04, 4.5297167e-04, ...,\n         4.6765395e-03, 6.0480673e-02, 9.3484277e-01]],\n\n       [[5.0442386e-04, 4.3001700e-03, 9.9519530e-01, ...,\n         9.7817034e-01, 2.1051416e-02, 7.7824460e-04]],\n\n       [[9.8957914e-01, 5.4418677e-03, 4.9790350e-03, ...,\n         8.5550435e-02, 7.5036585e-02, 8.3941300e-01]],\n\n       ...,\n\n       [[7.0376875e-04, 9.7931010e-03, 9.8950315e-01, ...,\n         8.9463750e-01, 1.0409502e-01, 1.2674012e-03]],\n\n       [[9.9917114e-01, 4.9286430e-04, 3.3603658e-04, ...,\n         8.3751883e-04, 2.6697412e-03, 9.9649280e-01]],\n\n       [[2.6664520e-04, 2.1777824e-03, 9.9755560e-01, ...,\n         9.8434700e-01, 1.5223468e-02, 4.2961346e-04]]])"},"metadata":{}}]},{"cell_type":"code","source":"X_snli_rnn.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:14.994228Z","iopub.execute_input":"2024-08-20T13:09:14.994489Z","iopub.status.idle":"2024-08-20T13:09:15.003586Z","shell.execute_reply.started":"2024-08-20T13:09:14.994466Z","shell.execute_reply":"2024-08-20T13:09:15.002714Z"},"trusted":true},"execution_count":436,"outputs":[{"execution_count":436,"output_type":"execute_result","data":{"text/plain":"(6032, 1, 9)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef prepare_data_splits(X_rnn, features, y_encoded, test_size=0.1, random_state=42):\n    # Split the data for the RNN inputs\n    X_train_rnn, X_val_rnn, y_train, y_val = train_test_split(\n        X_rnn, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded)\n\n    # Split the data for the additional features\n    features_train, features_val, _, _ = train_test_split(\n        features, y_encoded, test_size=test_size, random_state=random_state, stratify=y_encoded)\n\n    return X_train_rnn, X_val_rnn, features_train, features_val, y_train, y_val\n\n# Example for SNLI data\nX_train_snli_rnn, X_val_snli_rnn, features_train_snli, features_val_snli, y_train_snli, y_val_snli = prepare_data_splits(X_snli_rnn, features_snli, y_encoded_snli)\n# Example for MNLI-m data\nX_train_mnli_matched_rnn, X_val_mnli_matched_rnn, features_train_mnli_matched, features_val_mnli_matched, y_train_mnli_matched, y_val_mnli_matched = prepare_data_splits(X_mnli_matched_rnn, features_mnli_matched, y_encoded_mnli_matched)\n# Example for MNLI-mm data\nX_train_mnli_mismatched_rnn, X_val_mnli_mismatched_rnn, features_train_mnli_mismatched, features_val_mnli_mismatched, y_train_mnli_mismatched, y_val_mnli_mismatched = prepare_data_splits(X_mnli_mismatched_rnn, features_mnli_mismatched, y_encoded_mnli_mismatched)\n# Example for ANLI round 1 data\nX_train_anli_r1_rnn, X_val_anli_r1_rnn, features_train_anli_r1, features_val_anli_r1, y_train_anli_r1, y_val_anli_r1 = prepare_data_splits(X_anli_r1_rnn, features_anli_r1, y_encoded_anli_r1)\n# Example for ANLI round 2 data\nX_train_anli_r2_rnn, X_val_anli_r2_rnn, features_train_anli_r2, features_val_anli_r2, y_train_anli_r2, y_val_anli_r2 = prepare_data_splits(X_anli_r2_rnn, features_anli_r2, y_encoded_anli_r2)\n# Example for ANLI round 3 data\nX_train_anli_r3_rnn, X_val_anli_r3_rnn, features_train_anli_r3, features_val_anli_r3, y_train_anli_r3, y_val_anli_r3 = prepare_data_splits(X_anli_r3_rnn, features_anli_r3, y_encoded_anli_r3)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:15.004986Z","iopub.execute_input":"2024-08-20T13:09:15.005338Z","iopub.status.idle":"2024-08-20T13:09:15.345923Z","shell.execute_reply.started":"2024-08-20T13:09:15.005307Z","shell.execute_reply":"2024-08-20T13:09:15.345084Z"},"trusted":true},"execution_count":437,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,  LSTM, Dense, Dropout, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Flatten\nfrom sklearn.metrics import recall_score, f1_score\n\n\ndef build_and_train_lstm_model(X_train_rnn, features_train, y_train, X_val_rnn, features_val, y_val, epochs=20, batch_size=32):\n    sequence_input_shape = X_train_rnn.shape[1:]\n    features_input_shape = features_train.shape[1:]\n\n    sequence_input = Input(shape=sequence_input_shape, name='sequence_input')\n    lstm = LSTM(64, return_sequences=False)(sequence_input)\n    lstm = Dropout(0.5)(lstm)\n\n    features_input = Input(shape=features_input_shape, name='features_input')\n    features_layer = Dense(32, activation='relu')(features_input)\n    features_layer = Dropout(0.2)(features_layer)\n    features_layer = Flatten()(features_layer)\n\n    concatenated = Concatenate()([lstm, features_layer])\n    output = Dense(3, activation='softmax')(concatenated)\n\n    model = Model(inputs=[sequence_input, features_input], outputs=output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy')\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\n    history = model.fit(\n        [X_train_rnn, features_train], y_train,\n        validation_data=([X_val_rnn, features_val], y_val),\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=[early_stopping]\n    )\n\n    y_val_pred = model.predict([X_val_rnn, features_val])\n    y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n    y_val_true_labels = np.argmax(y_val, axis=1)\n\n    recall = recall_score(y_val_true_labels, y_val_pred_labels, average='macro')\n    f1 = f1_score(y_val_true_labels, y_val_pred_labels, average='macro')\n\n    return model, history, recall, f1\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:15.347336Z","iopub.execute_input":"2024-08-20T13:09:15.347748Z","iopub.status.idle":"2024-08-20T13:09:15.360484Z","shell.execute_reply.started":"2024-08-20T13:09:15.347708Z","shell.execute_reply":"2024-08-20T13:09:15.359623Z"},"trusted":true},"execution_count":438,"outputs":[]},{"cell_type":"code","source":"# Training and evaluation for the SNLI data with LSTM\nmodel_snli_lstm, history_snli_lstm, recall_snli, f1_snli = build_and_train_lstm_model(\n    X_train_snli_rnn, features_train_snli, y_train_snli, \n    X_val_snli_rnn, features_val_snli, y_val_snli, \n    epochs=20, batch_size=32\n)\nprint(f\"SNLI - Recall: {recall_snli:.3f}, F1-Score: {f1_snli:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:40.209803Z","iopub.execute_input":"2024-08-20T13:09:40.210448Z","iopub.status.idle":"2024-08-20T13:09:50.072924Z","shell.execute_reply.started":"2024-08-20T13:09:40.210412Z","shell.execute_reply":"2024-08-20T13:09:50.071900Z"},"trusted":true},"execution_count":440,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6858 - val_loss: 0.1750\nEpoch 2/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1763 - val_loss: 0.1368\nEpoch 3/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1462 - val_loss: 0.1234\nEpoch 4/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1530 - val_loss: 0.1190\nEpoch 5/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1347 - val_loss: 0.1179\nEpoch 6/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1397 - val_loss: 0.1176\nEpoch 7/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1370 - val_loss: 0.1182\nEpoch 8/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1405 - val_loss: 0.1173\nEpoch 9/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1427 - val_loss: 0.1175\nEpoch 10/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1270 - val_loss: 0.1183\nEpoch 11/20\n\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1524 - val_loss: 0.1184\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\nSNLI - Recall: 0.787, F1-Score: 0.812\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training and evaluation for the MNLI Matched data with LSTM\nmodel_mnli_matched_lstm, history_mnli_matched_lstm, recall_mnli_matched, f1_mnli_matched = build_and_train_lstm_model(\n    X_train_mnli_matched_rnn, features_train_mnli_matched, y_train_mnli_matched,\n    X_val_mnli_matched_rnn, features_val_mnli_matched, y_val_mnli_matched,\n    epochs=20, batch_size=32\n)\nprint(f\"MNLI Matched - Recall: {recall_mnli_matched:.3f}, F1-Score: {f1_mnli_matched:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:09:58.825650Z","iopub.execute_input":"2024-08-20T13:09:58.826505Z","iopub.status.idle":"2024-08-20T13:10:15.114482Z","shell.execute_reply.started":"2024-08-20T13:09:58.826472Z","shell.execute_reply":"2024-08-20T13:10:15.113470Z"},"trusted":true},"execution_count":441,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.7251 - val_loss: 0.1663\nEpoch 2/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1651 - val_loss: 0.1438\nEpoch 3/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1492 - val_loss: 0.1366\nEpoch 4/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1331 - val_loss: 0.1318\nEpoch 5/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1454 - val_loss: 0.1288\nEpoch 6/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1203 - val_loss: 0.1268\nEpoch 7/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1360 - val_loss: 0.1255\nEpoch 8/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1293 - val_loss: 0.1252\nEpoch 9/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1277 - val_loss: 0.1241\nEpoch 10/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1334 - val_loss: 0.1237\nEpoch 11/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1335 - val_loss: 0.1234\nEpoch 12/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1244 - val_loss: 0.1237\nEpoch 13/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1552 - val_loss: 0.1234\nEpoch 14/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1314 - val_loss: 0.1231\nEpoch 15/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1366 - val_loss: 0.1234\nEpoch 16/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1284 - val_loss: 0.1233\nEpoch 17/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1356 - val_loss: 0.1229\nEpoch 18/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1321 - val_loss: 0.1231\nEpoch 19/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1364 - val_loss: 0.1234\nEpoch 20/20\n\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1380 - val_loss: 0.1229\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\nMNLI Matched - Recall: 0.701, F1-Score: 0.722\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training and evaluation for the MNLI Mismatched data with LSTM\nmodel_mnli_mismatched_lstm, history_mnli_mismatched_lstm, recall_mnli_mismatched, f1_mnli_mismatched = build_and_train_lstm_model(\n    X_train_mnli_mismatched_rnn, features_train_mnli_mismatched, y_train_mnli_mismatched,\n    X_val_mnli_mismatched_rnn, features_val_mnli_mismatched, y_val_mnli_mismatched,\n    epochs=20, batch_size=32\n)\nprint(f\"MNLI Mismatched - Recall: {recall_mnli_mismatched:.3f}, F1-Score: {f1_mnli_mismatched:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:10:15.117949Z","iopub.execute_input":"2024-08-20T13:10:15.118274Z","iopub.status.idle":"2024-08-20T13:10:24.640536Z","shell.execute_reply.started":"2024-08-20T13:10:15.118247Z","shell.execute_reply":"2024-08-20T13:10:24.639508Z"},"trusted":true},"execution_count":442,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.7183 - val_loss: 0.1773\nEpoch 2/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1447 - val_loss: 0.1560\nEpoch 3/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1424 - val_loss: 0.1519\nEpoch 4/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1249 - val_loss: 0.1492\nEpoch 5/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1180 - val_loss: 0.1509\nEpoch 6/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1274 - val_loss: 0.1508\nEpoch 7/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1129 - val_loss: 0.1487\nEpoch 8/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1286 - val_loss: 0.1505\nEpoch 9/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1264 - val_loss: 0.1519\nEpoch 10/20\n\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1195 - val_loss: 0.1503\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\nMNLI Mismatched - Recall: 0.697, F1-Score: 0.713\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training and evaluation for the ANLI Round 1 data with LSTM\nmodel_anli_r1_lstm, history_anli_r1_lstm, recall_anli_r1, f1_anli_r1 = build_and_train_lstm_model(\n    X_train_anli_r1_rnn, features_train_anli_r1, y_train_anli_r1,\n    X_val_anli_r1_rnn, features_val_anli_r1, y_val_anli_r1,\n    epochs=20, batch_size=32\n)\nprint(f\"ANLI R1 - Recall: {recall_anli_r1:.3f}, F1-Score: {f1_anli_r1:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:10:24.642368Z","iopub.execute_input":"2024-08-20T13:10:24.642673Z","iopub.status.idle":"2024-08-20T13:10:30.248017Z","shell.execute_reply.started":"2024-08-20T13:10:24.642646Z","shell.execute_reply":"2024-08-20T13:10:30.246998Z"},"trusted":true},"execution_count":443,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 1.0377 - val_loss: 0.9989\nEpoch 2/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9777 - val_loss: 0.9485\nEpoch 3/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9422 - val_loss: 0.9021\nEpoch 4/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8879 - val_loss: 0.8564\nEpoch 5/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.8590 - val_loss: 0.8103\nEpoch 6/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7928 - val_loss: 0.7660\nEpoch 7/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7609 - val_loss: 0.7228\nEpoch 8/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6876 - val_loss: 0.6827\nEpoch 9/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6811 - val_loss: 0.6456\nEpoch 10/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6504 - val_loss: 0.6132\nEpoch 11/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6158 - val_loss: 0.5869\nEpoch 12/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5899 - val_loss: 0.5670\nEpoch 13/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5346 - val_loss: 0.5516\nEpoch 14/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5657 - val_loss: 0.5371\nEpoch 15/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5606 - val_loss: 0.5295\nEpoch 16/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5167 - val_loss: 0.5250\nEpoch 17/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4911 - val_loss: 0.5187\nEpoch 18/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5398 - val_loss: 0.5098\nEpoch 19/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4765 - val_loss: 0.5071\nEpoch 20/20\n\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5006 - val_loss: 0.5039\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\nANLI R1 - Recall: 0.690, F1-Score: 0.679\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training and evaluation for the ANLI Round 2 data with LSTM\nmodel_anli_r2_lstm, history_anli_r2_lstm, recall_anli_r2, f1_anli_r2 = build_and_train_lstm_model(\n    X_train_anli_r2_rnn, features_train_anli_r2, y_train_anli_r2,\n    X_val_anli_r2_rnn, features_val_anli_r2, y_val_anli_r2,\n    epochs=20, batch_size=32\n)\nprint(f\"ANLI R2 - Recall: {recall_anli_r2:.3f}, F1-Score: {f1_anli_r2:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:10:30.249447Z","iopub.execute_input":"2024-08-20T13:10:30.250160Z","iopub.status.idle":"2024-08-20T13:10:34.249337Z","shell.execute_reply.started":"2024-08-20T13:10:30.250119Z","shell.execute_reply":"2024-08-20T13:10:34.248387Z"},"trusted":true},"execution_count":444,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 1.1190 - val_loss: 1.0909\nEpoch 2/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0751 - val_loss: 1.0499\nEpoch 3/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0221 - val_loss: 1.0136\nEpoch 4/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9955 - val_loss: 0.9740\nEpoch 5/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9454 - val_loss: 0.9350\nEpoch 6/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9310 - val_loss: 0.8961\nEpoch 7/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8687 - val_loss: 0.8589\nEpoch 8/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8628 - val_loss: 0.8243\nEpoch 9/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8122 - val_loss: 0.7950\nEpoch 10/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7881 - val_loss: 0.7714\nEpoch 11/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7624 - val_loss: 0.7494\nEpoch 12/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7892 - val_loss: 0.7304\nEpoch 13/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7574 - val_loss: 0.7184\nEpoch 14/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7013 - val_loss: 0.7065\nEpoch 15/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7452 - val_loss: 0.6975\nEpoch 16/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6944 - val_loss: 0.6902\nEpoch 17/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7079 - val_loss: 0.6846\nEpoch 18/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7026 - val_loss: 0.6798\nEpoch 19/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7214 - val_loss: 0.6749\nEpoch 20/20\n\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6682 - val_loss: 0.6724\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\nANLI R2 - Recall: 0.739, F1-Score: 0.737\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training and evaluation for the ANLI Round 3 data with LSTM\nmodel_anli_r3_lstm, history_anli_r3_lstm, recall_anli_r3, f1_anli_r3 = build_and_train_lstm_model(\n    X_train_anli_r3_rnn, features_train_anli_r3, y_train_anli_r3,\n    X_val_anli_r3_rnn, features_val_anli_r3, y_val_anli_r3,\n    epochs=20, batch_size=32\n)\nprint(f\"ANLI R3 - Recall: {recall_anli_r3:.3f}, F1-Score: {f1_anli_r3:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:10:34.251487Z","iopub.execute_input":"2024-08-20T13:10:34.252226Z","iopub.status.idle":"2024-08-20T13:10:38.352926Z","shell.execute_reply.started":"2024-08-20T13:10:34.252189Z","shell.execute_reply":"2024-08-20T13:10:38.351977Z"},"trusted":true},"execution_count":445,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.1379 - val_loss: 1.0693\nEpoch 2/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0697 - val_loss: 1.0158\nEpoch 3/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0113 - val_loss: 0.9670\nEpoch 4/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9619 - val_loss: 0.9227\nEpoch 5/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9029 - val_loss: 0.8787\nEpoch 6/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8801 - val_loss: 0.8377\nEpoch 7/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8173 - val_loss: 0.8025\nEpoch 8/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8054 - val_loss: 0.7715\nEpoch 9/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7619 - val_loss: 0.7485\nEpoch 10/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7649 - val_loss: 0.7311\nEpoch 11/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7423 - val_loss: 0.7184\nEpoch 12/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7031 - val_loss: 0.7074\nEpoch 13/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6789 - val_loss: 0.6996\nEpoch 14/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6950 - val_loss: 0.6954\nEpoch 15/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7099 - val_loss: 0.6876\nEpoch 16/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6836 - val_loss: 0.6860\nEpoch 17/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6412 - val_loss: 0.6808\nEpoch 18/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6020 - val_loss: 0.6814\nEpoch 19/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6612 - val_loss: 0.6800\nEpoch 20/20\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6878 - val_loss: 0.6803\n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\nANLI R3 - Recall: 0.655, F1-Score: 0.613\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combining all datasets for a comprehensive training set\nX_rnn_all_tasks = np.concatenate([\n    X_snli_rnn, X_mnli_matched_rnn, X_mnli_mismatched_rnn,\n    X_anli_r1_rnn, X_anli_r2_rnn, X_anli_r3_rnn\n])\n\nfeatures_all_tasks = np.concatenate([\n    features_snli, features_mnli_matched, features_mnli_mismatched,\n    features_anli_r1, features_anli_r2, features_anli_r3\n])\n\ny_encoded_all_tasks = np.concatenate([\n    y_encoded_snli, y_encoded_mnli_matched, y_encoded_mnli_mismatched,\n    y_encoded_anli_r1, y_encoded_anli_r2, y_encoded_anli_r3\n])\n\n# Prepare data splits for combined dataset\nX_train_all_rnn, X_val_all_rnn, features_train_all, features_val_all, y_train_all, y_val_all = prepare_data_splits(\n    X_rnn_all_tasks, features_all_tasks, y_encoded_all_tasks\n)\n\n# Combined training and evaluation\nmodel_all, history_all, recall_all, f1_all = build_and_train_lstm_model(\n    X_train_all_rnn, features_train_all, y_train_all,\n    X_val_all_rnn, features_val_all, y_val_all,\n    epochs=20, batch_size=32\n)\nprint(f\"Combined Tasks - Recall: {recall_all:.3f}, F1-Score: {f1_all:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:10:40.190967Z","iopub.execute_input":"2024-08-20T13:10:40.191636Z","iopub.status.idle":"2024-08-20T13:10:55.488673Z","shell.execute_reply.started":"2024-08-20T13:10:40.191601Z","shell.execute_reply":"2024-08-20T13:10:55.487614Z"},"trusted":true},"execution_count":446,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.4725 - val_loss: 0.1734\nEpoch 2/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1883 - val_loss: 0.1735\nEpoch 3/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1826 - val_loss: 0.1714\nEpoch 4/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1771 - val_loss: 0.1717\nEpoch 5/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1855 - val_loss: 0.1714\nEpoch 6/20\n\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1869 - val_loss: 0.1717\n\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\nCombined Tasks - Recall: 0.737, F1-Score: 0.760\n","output_type":"stream"}]}]}