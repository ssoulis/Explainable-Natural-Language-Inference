{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2933,"sourceType":"datasetVersion","datasetId":1670},{"sourceId":4548821,"sourceType":"datasetVersion","datasetId":2655798},{"sourceId":4550791,"sourceType":"datasetVersion","datasetId":2656775},{"sourceId":8083662,"sourceType":"datasetVersion","datasetId":4771616},{"sourceId":8083668,"sourceType":"datasetVersion","datasetId":4771621},{"sourceId":8083678,"sourceType":"datasetVersion","datasetId":4771629},{"sourceId":8084913,"sourceType":"datasetVersion","datasetId":4772442}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the SNLI test data (including true labels)\nsnli_test_path = \"/kaggle/input/stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\nsnli_test_df = pd.read_csv(snli_test_path)\n\n# Define file paths for SNLI prediction files\nsnli_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_snli_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_snli_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_snli_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_snli = \"/kaggle/working/combined_snli_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_snli_df = pd.DataFrame(columns=columns)\n\nlabel_mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n\n# Load and merge the predictions\nfor model, path in snli_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_snli_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_snli_df['True_Label'] = snli_test_df['gold_label'].map(label_mapping)\n\n# Convert True_Label to integer type\ncombined_snli_df['True_Label'] = combined_snli_df['True_Label'].astype('Int64')\n\n# Save the combined DataFrame to CSV\ncombined_snli_df.to_csv(output_csv_path_snli, index=False)\n\nprint(f\"Combined SNLI predictions with true labels saved to {output_csv_path_snli}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T13:53:31.876854Z","iopub.execute_input":"2024-08-20T13:53:31.877789Z","iopub.status.idle":"2024-08-20T13:53:32.164634Z","shell.execute_reply.started":"2024-08-20T13:53:31.877750Z","shell.execute_reply":"2024-08-20T13:53:32.163725Z"},"trusted":true},"execution_count":649,"outputs":[{"name":"stdout","text":"Combined SNLI predictions with true labels saved to /kaggle/working/combined_snli_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.166715Z","iopub.execute_input":"2024-08-20T13:53:32.167488Z","iopub.status.idle":"2024-08-20T13:53:32.182771Z","shell.execute_reply.started":"2024-08-20T13:53:32.167447Z","shell.execute_reply":"2024-08-20T13:53:32.181857Z"},"trusted":true},"execution_count":650,"outputs":[{"execution_count":650,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.034767         0.962592               0.002641   \n1            0.001921         0.319032               0.679047   \n2            0.998783         0.000764               0.000453   \n3            0.001001         0.997708               0.001291   \n4            0.001080         0.301363               0.697557   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.012451         0.927093               0.060457   \n1            0.752766         0.242251               0.004983   \n2            0.000254         0.004494               0.995253   \n3            0.005844         0.990736               0.003419   \n4            0.278348         0.718575               0.003076   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.008653        0.947434              0.043913           1  \n1           0.740332        0.256434              0.003235           0  \n2           0.004677        0.060481              0.934843           2  \n3           0.034056        0.956687              0.009257           1  \n4           0.498761        0.499270              0.001969           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.034767</td>\n      <td>0.962592</td>\n      <td>0.002641</td>\n      <td>0.012451</td>\n      <td>0.927093</td>\n      <td>0.060457</td>\n      <td>0.008653</td>\n      <td>0.947434</td>\n      <td>0.043913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001921</td>\n      <td>0.319032</td>\n      <td>0.679047</td>\n      <td>0.752766</td>\n      <td>0.242251</td>\n      <td>0.004983</td>\n      <td>0.740332</td>\n      <td>0.256434</td>\n      <td>0.003235</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998783</td>\n      <td>0.000764</td>\n      <td>0.000453</td>\n      <td>0.000254</td>\n      <td>0.004494</td>\n      <td>0.995253</td>\n      <td>0.004677</td>\n      <td>0.060481</td>\n      <td>0.934843</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001001</td>\n      <td>0.997708</td>\n      <td>0.001291</td>\n      <td>0.005844</td>\n      <td>0.990736</td>\n      <td>0.003419</td>\n      <td>0.034056</td>\n      <td>0.956687</td>\n      <td>0.009257</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001080</td>\n      <td>0.301363</td>\n      <td>0.697557</td>\n      <td>0.278348</td>\n      <td>0.718575</td>\n      <td>0.003076</td>\n      <td>0.498761</td>\n      <td>0.499270</td>\n      <td>0.001969</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_matched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_matched.csv\"\nmnli_matched_test_df = pd.read_csv(mnli_matched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_matched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_matched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_matched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_matched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_matched = \"/kaggle/working/combined_mnli_matched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_matched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_matched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_matched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_matched_df['True_Label'] = mnli_matched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_matched_df.to_csv(output_csv_path_mnli_matched, index=False)\n\nprint(f\"Combined MNLI-matched predictions with true labels saved to {output_csv_path_mnli_matched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.184017Z","iopub.execute_input":"2024-08-20T13:53:32.184438Z","iopub.status.idle":"2024-08-20T13:53:32.379534Z","shell.execute_reply.started":"2024-08-20T13:53:32.184404Z","shell.execute_reply":"2024-08-20T13:53:32.378536Z"},"trusted":true},"execution_count":651,"outputs":[{"name":"stdout","text":"Combined MNLI-matched predictions with true labels saved to /kaggle/working/combined_mnli_matched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_matched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.380808Z","iopub.execute_input":"2024-08-20T13:53:32.381142Z","iopub.status.idle":"2024-08-20T13:53:32.396050Z","shell.execute_reply.started":"2024-08-20T13:53:32.381114Z","shell.execute_reply":"2024-08-20T13:53:32.395075Z"},"trusted":true},"execution_count":652,"outputs":[{"execution_count":652,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005164         0.993364               0.001472   \n1            0.999153         0.000526               0.000321   \n2            0.000989         0.044792               0.954219   \n3            0.994965         0.004808               0.000228   \n4            0.999657         0.000220               0.000123   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.017844         0.950246               0.031909   \n1            0.001413         0.002030               0.996557   \n2            0.954781         0.042249               0.002970   \n3            0.000343         0.003511               0.996146   \n4            0.000079         0.000496               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.010844        0.983012              0.006144           1  \n1           0.005388        0.007536              0.987076           2  \n2           0.853862        0.143483              0.002655           0  \n3           0.004128        0.070757              0.925115           2  \n4           0.003864        0.029262              0.966875           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005164</td>\n      <td>0.993364</td>\n      <td>0.001472</td>\n      <td>0.017844</td>\n      <td>0.950246</td>\n      <td>0.031909</td>\n      <td>0.010844</td>\n      <td>0.983012</td>\n      <td>0.006144</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.999153</td>\n      <td>0.000526</td>\n      <td>0.000321</td>\n      <td>0.001413</td>\n      <td>0.002030</td>\n      <td>0.996557</td>\n      <td>0.005388</td>\n      <td>0.007536</td>\n      <td>0.987076</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000989</td>\n      <td>0.044792</td>\n      <td>0.954219</td>\n      <td>0.954781</td>\n      <td>0.042249</td>\n      <td>0.002970</td>\n      <td>0.853862</td>\n      <td>0.143483</td>\n      <td>0.002655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.994965</td>\n      <td>0.004808</td>\n      <td>0.000228</td>\n      <td>0.000343</td>\n      <td>0.003511</td>\n      <td>0.996146</td>\n      <td>0.004128</td>\n      <td>0.070757</td>\n      <td>0.925115</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.999657</td>\n      <td>0.000220</td>\n      <td>0.000123</td>\n      <td>0.000079</td>\n      <td>0.000496</td>\n      <td>0.999425</td>\n      <td>0.003864</td>\n      <td>0.029262</td>\n      <td>0.966875</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nmnli_mismatched_test_path = \"/kaggle/input/nli-dataset-for-sentence-understanding/mnli_validation_mismatched.csv\"\nmnli_mismatched_test_df = pd.read_csv(mnli_mismatched_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nmnli_mismatched_predictions_paths = {\n    \"deberta\": \"/kaggle/input/validation/deberta_mnli_mismatched_val_predictions.csv\",\n    \"roberta\": \"/kaggle/input/validation/roberta_mnli_mismatched_val_predictions.csv\",\n    \"albert\": \"/kaggle/input/validation/albert_mnli_mismatched_val_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_mnli_mismatched = \"/kaggle/working/combined_mnli_mismatched_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_mnli_mismatched_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in mnli_mismatched_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_mnli_mismatched_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_mnli_mismatched_df['True_Label'] = mnli_mismatched_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_mnli_mismatched_df.to_csv(output_csv_path_mnli_mismatched, index=False)\n\nprint(f\"Combined MNLI-mismatched predictions with true labels saved to {output_csv_path_mnli_mismatched}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.398694Z","iopub.execute_input":"2024-08-20T13:53:32.399335Z","iopub.status.idle":"2024-08-20T13:53:32.593192Z","shell.execute_reply.started":"2024-08-20T13:53:32.399307Z","shell.execute_reply":"2024-08-20T13:53:32.592179Z"},"trusted":true},"execution_count":653,"outputs":[{"name":"stdout","text":"Combined MNLI-mismatched predictions with true labels saved to /kaggle/working/combined_mnli_mismatched_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_mnli_mismatched_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.594196Z","iopub.execute_input":"2024-08-20T13:53:32.594464Z","iopub.status.idle":"2024-08-20T13:53:32.609129Z","shell.execute_reply.started":"2024-08-20T13:53:32.594440Z","shell.execute_reply":"2024-08-20T13:53:32.608081Z"},"trusted":true},"execution_count":654,"outputs":[{"execution_count":654,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.999667         0.000160               0.000173   \n1            0.998119         0.000962               0.000919   \n2            0.000552         0.004809               0.994639   \n3            0.827653         0.171961               0.000386   \n4            0.000292         0.002875               0.996833   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.000068         0.000402               0.999529   \n1            0.000183         0.001511               0.998306   \n2            0.986062         0.012020               0.001918   \n3            0.000478         0.270953               0.728569   \n4            0.975167         0.021904               0.002929   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.000894        0.003787              0.995318           2  \n1           0.006421        0.010224              0.983355           2  \n2           0.975041        0.023354              0.001605           0  \n3           0.001722        0.796122              0.202156           2  \n4           0.965952        0.032748              0.001300           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.999667</td>\n      <td>0.000160</td>\n      <td>0.000173</td>\n      <td>0.000068</td>\n      <td>0.000402</td>\n      <td>0.999529</td>\n      <td>0.000894</td>\n      <td>0.003787</td>\n      <td>0.995318</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.998119</td>\n      <td>0.000962</td>\n      <td>0.000919</td>\n      <td>0.000183</td>\n      <td>0.001511</td>\n      <td>0.998306</td>\n      <td>0.006421</td>\n      <td>0.010224</td>\n      <td>0.983355</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000552</td>\n      <td>0.004809</td>\n      <td>0.994639</td>\n      <td>0.986062</td>\n      <td>0.012020</td>\n      <td>0.001918</td>\n      <td>0.975041</td>\n      <td>0.023354</td>\n      <td>0.001605</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.827653</td>\n      <td>0.171961</td>\n      <td>0.000386</td>\n      <td>0.000478</td>\n      <td>0.270953</td>\n      <td>0.728569</td>\n      <td>0.001722</td>\n      <td>0.796122</td>\n      <td>0.202156</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000292</td>\n      <td>0.002875</td>\n      <td>0.996833</td>\n      <td>0.975167</td>\n      <td>0.021904</td>\n      <td>0.002929</td>\n      <td>0.965952</td>\n      <td>0.032748</td>\n      <td>0.001300</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 1 test data (including true labels)\nanli_r1_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r1.csv\"\nanli_r1_test_df = pd.read_csv(anli_r1_test_path)\n\n# Define file paths for ANLI Round 1 prediction files\nanli_r1_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r1_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r1_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r1_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r1 = \"/kaggle/working/combined_anli_r1_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r1_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r1_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r1_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r1_df['True_Label'] = anli_r1_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r1_df.to_csv(output_csv_path_anli_r1, index=False)\n\nprint(f\"Combined ANLI Round 1 predictions with true labels saved to {output_csv_path_anli_r1}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.610485Z","iopub.execute_input":"2024-08-20T13:53:32.610881Z","iopub.status.idle":"2024-08-20T13:53:32.658538Z","shell.execute_reply.started":"2024-08-20T13:53:32.610850Z","shell.execute_reply":"2024-08-20T13:53:32.657489Z"},"trusted":true},"execution_count":655,"outputs":[{"name":"stdout","text":"Combined ANLI Round 1 predictions with true labels saved to /kaggle/working/combined_anli_r1_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r1_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.659730Z","iopub.execute_input":"2024-08-20T13:53:32.660010Z","iopub.status.idle":"2024-08-20T13:53:32.673992Z","shell.execute_reply.started":"2024-08-20T13:53:32.659986Z","shell.execute_reply":"2024-08-20T13:53:32.673082Z"},"trusted":true},"execution_count":656,"outputs":[{"execution_count":656,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.015388         0.976305               0.008307   \n1            0.224603         0.501549               0.273848   \n2            0.006642         0.976690               0.016669   \n3            0.966494         0.032235               0.001272   \n4            0.880736         0.028293               0.090971   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.996714         0.000376               0.002910   \n1            0.875720         0.000724               0.123556   \n2            0.999484         0.000330               0.000186   \n3            0.000686         0.998181               0.001133   \n4            0.000378         0.000197               0.999425   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.322974        0.667628              0.009398           0  \n1           0.998526        0.000604              0.000869           0  \n2           0.783352        0.212241              0.004407           0  \n3           0.002134        0.989523              0.008343           1  \n4           0.023283        0.013253              0.963464           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.015388</td>\n      <td>0.976305</td>\n      <td>0.008307</td>\n      <td>0.996714</td>\n      <td>0.000376</td>\n      <td>0.002910</td>\n      <td>0.322974</td>\n      <td>0.667628</td>\n      <td>0.009398</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.224603</td>\n      <td>0.501549</td>\n      <td>0.273848</td>\n      <td>0.875720</td>\n      <td>0.000724</td>\n      <td>0.123556</td>\n      <td>0.998526</td>\n      <td>0.000604</td>\n      <td>0.000869</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.006642</td>\n      <td>0.976690</td>\n      <td>0.016669</td>\n      <td>0.999484</td>\n      <td>0.000330</td>\n      <td>0.000186</td>\n      <td>0.783352</td>\n      <td>0.212241</td>\n      <td>0.004407</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.966494</td>\n      <td>0.032235</td>\n      <td>0.001272</td>\n      <td>0.000686</td>\n      <td>0.998181</td>\n      <td>0.001133</td>\n      <td>0.002134</td>\n      <td>0.989523</td>\n      <td>0.008343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880736</td>\n      <td>0.028293</td>\n      <td>0.090971</td>\n      <td>0.000378</td>\n      <td>0.000197</td>\n      <td>0.999425</td>\n      <td>0.023283</td>\n      <td>0.013253</td>\n      <td>0.963464</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 2 test data (including true labels)\nanli_r2_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r2.csv\"\nanli_r2_test_df = pd.read_csv(anli_r2_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r2_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r2_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r2_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r2_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r2 = \"/kaggle/working/combined_anli_r2_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r2_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r2_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r2_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r2_df['True_Label'] = anli_r2_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r2_df.to_csv(output_csv_path_anli_r2, index=False)\n\nprint(f\"Combined ANLI Round 2 predictions with true labels saved to {output_csv_path_anli_r2}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.675295Z","iopub.execute_input":"2024-08-20T13:53:32.675586Z","iopub.status.idle":"2024-08-20T13:53:32.723266Z","shell.execute_reply.started":"2024-08-20T13:53:32.675561Z","shell.execute_reply":"2024-08-20T13:53:32.722309Z"},"trusted":true},"execution_count":657,"outputs":[{"name":"stdout","text":"Combined ANLI Round 2 predictions with true labels saved to /kaggle/working/combined_anli_r2_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r2_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.724541Z","iopub.execute_input":"2024-08-20T13:53:32.725193Z","iopub.status.idle":"2024-08-20T13:53:32.739325Z","shell.execute_reply.started":"2024-08-20T13:53:32.725157Z","shell.execute_reply":"2024-08-20T13:53:32.738356Z"},"trusted":true},"execution_count":658,"outputs":[{"execution_count":658,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.001309         0.029617               0.969075   \n1            0.724144         0.273676               0.002180   \n2            0.071604         0.917894               0.010503   \n3            0.066162         0.929179               0.004659   \n4            0.906199         0.089873               0.003928   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.999506         0.000264               0.000230   \n1            0.026951         0.054230               0.918819   \n2            0.001282         0.998108               0.000610   \n3            0.007091         0.992694               0.000215   \n4            0.006259         0.989432               0.004309   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.863365        0.133388              0.003246           0  \n1           0.072900        0.904344              0.022756           1  \n2           0.027402        0.972218              0.000380           0  \n3           0.632171        0.365194              0.002635           1  \n4           0.064109        0.234642              0.701249           2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001309</td>\n      <td>0.029617</td>\n      <td>0.969075</td>\n      <td>0.999506</td>\n      <td>0.000264</td>\n      <td>0.000230</td>\n      <td>0.863365</td>\n      <td>0.133388</td>\n      <td>0.003246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.724144</td>\n      <td>0.273676</td>\n      <td>0.002180</td>\n      <td>0.026951</td>\n      <td>0.054230</td>\n      <td>0.918819</td>\n      <td>0.072900</td>\n      <td>0.904344</td>\n      <td>0.022756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071604</td>\n      <td>0.917894</td>\n      <td>0.010503</td>\n      <td>0.001282</td>\n      <td>0.998108</td>\n      <td>0.000610</td>\n      <td>0.027402</td>\n      <td>0.972218</td>\n      <td>0.000380</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.066162</td>\n      <td>0.929179</td>\n      <td>0.004659</td>\n      <td>0.007091</td>\n      <td>0.992694</td>\n      <td>0.000215</td>\n      <td>0.632171</td>\n      <td>0.365194</td>\n      <td>0.002635</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.906199</td>\n      <td>0.089873</td>\n      <td>0.003928</td>\n      <td>0.006259</td>\n      <td>0.989432</td>\n      <td>0.004309</td>\n      <td>0.064109</td>\n      <td>0.234642</td>\n      <td>0.701249</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the ANLI Round 3 test data (including true labels)\nanli_r3_test_path = \"/kaggle/input/anli-a-large-scale-nli-benchmark-dataset/test_r3.csv\"\nanli_r3_test_df = pd.read_csv(anli_r3_test_path)\n\n# Define file paths for ANLI Round 2 prediction files\nanli_r3_predictions_paths = {\n    \"deberta\": \"/kaggle/input/deberta-nli/deberta_anli_r3_predictions.csv\",\n    \"roberta\": \"/kaggle/input/roberta/roberta_anli_r3_predictions.csv\",\n    \"albert\": \"/kaggle/input/albert/albert_anli_r3_predictions.csv\",\n}\n\n# Specify where you want to save the combined predictions CSV file\noutput_csv_path_anli_r3 = \"/kaggle/working/combined_anli_r3_df\"\n\n# Define the column names, placing True_Label at the end\ncolumns = [\n    'Deberta_Entailment', 'Deberta_Neutral', 'Deberta_Contradiction',\n    'Roberta_Entailment', 'Roberta_Neutral', 'Roberta_Contradiction',\n    'Albert_Entailment', 'Albert_Neutral', 'Albert_Contradiction',\n    'True_Label'  # Ensuring True_Label is the last column\n]\n\n# Initialize the DataFrame with specified columns\ncombined_anli_r3_df = pd.DataFrame(columns=columns)\n\n# Load and merge the predictions\nfor model, path in anli_r3_predictions_paths.items():\n    predictions_df = pd.read_csv(path)\n    for label in ['Entailment', 'Neutral', 'Contradiction']:\n        combined_anli_r3_df[f\"{model.capitalize()}_{label}\"] = predictions_df[label]\n\n# Assign the true labels to the True_Label column, now positioned at the end\ncombined_anli_r3_df['True_Label'] = anli_r3_test_df['label']\n\n# Save the combined DataFrame to CSV\ncombined_anli_r3_df.to_csv(output_csv_path_anli_r3, index=False)\n\nprint(f\"Combined ANLI Round 3 predictions with true labels saved to {output_csv_path_anli_r3}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.740546Z","iopub.execute_input":"2024-08-20T13:53:32.740833Z","iopub.status.idle":"2024-08-20T13:53:32.793509Z","shell.execute_reply.started":"2024-08-20T13:53:32.740807Z","shell.execute_reply":"2024-08-20T13:53:32.792591Z"},"trusted":true},"execution_count":659,"outputs":[{"name":"stdout","text":"Combined ANLI Round 3 predictions with true labels saved to /kaggle/working/combined_anli_r3_df\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_anli_r3_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.794759Z","iopub.execute_input":"2024-08-20T13:53:32.795411Z","iopub.status.idle":"2024-08-20T13:53:32.809314Z","shell.execute_reply.started":"2024-08-20T13:53:32.795376Z","shell.execute_reply":"2024-08-20T13:53:32.808432Z"},"trusted":true},"execution_count":660,"outputs":[{"execution_count":660,"output_type":"execute_result","data":{"text/plain":"   Deberta_Entailment  Deberta_Neutral  Deberta_Contradiction  \\\n0            0.005921         0.960529               0.033551   \n1            0.009586         0.934714               0.055700   \n2            0.003428         0.976393               0.020179   \n3            0.004633         0.023985               0.971382   \n4            0.017428         0.633695               0.348877   \n\n   Roberta_Entailment  Roberta_Neutral  Roberta_Contradiction  \\\n0            0.022959         0.976533               0.000509   \n1            0.999611         0.000205               0.000185   \n2            0.002020         0.997897               0.000083   \n3            0.974441         0.024459               0.001100   \n4            0.984416         0.011166               0.004419   \n\n   Albert_Entailment  Albert_Neutral  Albert_Contradiction  True_Label  \n0           0.001848        0.998084              0.000067           0  \n1           0.951772        0.048075              0.000153           0  \n2           0.001014        0.998984              0.000002           0  \n3           0.996749        0.000989              0.002262           0  \n4           0.000518        0.128416              0.871066           0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Deberta_Entailment</th>\n      <th>Deberta_Neutral</th>\n      <th>Deberta_Contradiction</th>\n      <th>Roberta_Entailment</th>\n      <th>Roberta_Neutral</th>\n      <th>Roberta_Contradiction</th>\n      <th>Albert_Entailment</th>\n      <th>Albert_Neutral</th>\n      <th>Albert_Contradiction</th>\n      <th>True_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005921</td>\n      <td>0.960529</td>\n      <td>0.033551</td>\n      <td>0.022959</td>\n      <td>0.976533</td>\n      <td>0.000509</td>\n      <td>0.001848</td>\n      <td>0.998084</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.009586</td>\n      <td>0.934714</td>\n      <td>0.055700</td>\n      <td>0.999611</td>\n      <td>0.000205</td>\n      <td>0.000185</td>\n      <td>0.951772</td>\n      <td>0.048075</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.003428</td>\n      <td>0.976393</td>\n      <td>0.020179</td>\n      <td>0.002020</td>\n      <td>0.997897</td>\n      <td>0.000083</td>\n      <td>0.001014</td>\n      <td>0.998984</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004633</td>\n      <td>0.023985</td>\n      <td>0.971382</td>\n      <td>0.974441</td>\n      <td>0.024459</td>\n      <td>0.001100</td>\n      <td>0.996749</td>\n      <td>0.000989</td>\n      <td>0.002262</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.017428</td>\n      <td>0.633695</td>\n      <td>0.348877</td>\n      <td>0.984416</td>\n      <td>0.011166</td>\n      <td>0.004419</td>\n      <td>0.000518</td>\n      <td>0.128416</td>\n      <td>0.871066</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for missing values\nmissing_values_anli1 = combined_anli_r1_df.isnull().sum()\n\nmissing_values_anli2 = combined_anli_r2_df.isnull().sum()\n\nmissing_values_anli3 = combined_anli_r3_df.isnull().sum()\n\nmissing_values_snli = combined_snli_df.isnull().sum()\n\nmissing_values_mnli_matched = combined_mnli_matched_df.isnull().sum()\n\nmissing_values_mnli_mismatched = combined_mnli_mismatched_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.810590Z","iopub.execute_input":"2024-08-20T13:53:32.810851Z","iopub.status.idle":"2024-08-20T13:53:32.822537Z","shell.execute_reply.started":"2024-08-20T13:53:32.810827Z","shell.execute_reply":"2024-08-20T13:53:32.821572Z"},"trusted":true},"execution_count":661,"outputs":[]},{"cell_type":"code","source":"missing_values_anli1","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.826872Z","iopub.execute_input":"2024-08-20T13:53:32.827178Z","iopub.status.idle":"2024-08-20T13:53:32.834574Z","shell.execute_reply.started":"2024-08-20T13:53:32.827155Z","shell.execute_reply":"2024-08-20T13:53:32.833719Z"},"trusted":true},"execution_count":662,"outputs":[{"execution_count":662,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli2","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.835643Z","iopub.execute_input":"2024-08-20T13:53:32.835901Z","iopub.status.idle":"2024-08-20T13:53:32.845386Z","shell.execute_reply.started":"2024-08-20T13:53:32.835878Z","shell.execute_reply":"2024-08-20T13:53:32.844458Z"},"trusted":true},"execution_count":663,"outputs":[{"execution_count":663,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_anli3","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.846405Z","iopub.execute_input":"2024-08-20T13:53:32.846675Z","iopub.status.idle":"2024-08-20T13:53:32.856158Z","shell.execute_reply.started":"2024-08-20T13:53:32.846650Z","shell.execute_reply":"2024-08-20T13:53:32.855163Z"},"trusted":true},"execution_count":664,"outputs":[{"execution_count":664,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_snli","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.857217Z","iopub.execute_input":"2024-08-20T13:53:32.857506Z","iopub.status.idle":"2024-08-20T13:53:32.866503Z","shell.execute_reply.started":"2024-08-20T13:53:32.857483Z","shell.execute_reply":"2024-08-20T13:53:32.865711Z"},"trusted":true},"execution_count":665,"outputs":[{"execution_count":665,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment         0\nDeberta_Neutral            0\nDeberta_Contradiction      0\nRoberta_Entailment         0\nRoberta_Neutral            0\nRoberta_Contradiction      0\nAlbert_Entailment          0\nAlbert_Neutral             0\nAlbert_Contradiction       0\nTrue_Label               176\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_matched","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.867432Z","iopub.execute_input":"2024-08-20T13:53:32.867765Z","iopub.status.idle":"2024-08-20T13:53:32.876453Z","shell.execute_reply.started":"2024-08-20T13:53:32.867740Z","shell.execute_reply":"2024-08-20T13:53:32.875563Z"},"trusted":true},"execution_count":666,"outputs":[{"execution_count":666,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"missing_values_mnli_mismatched","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.877547Z","iopub.execute_input":"2024-08-20T13:53:32.877808Z","iopub.status.idle":"2024-08-20T13:53:32.887720Z","shell.execute_reply.started":"2024-08-20T13:53:32.877785Z","shell.execute_reply":"2024-08-20T13:53:32.886784Z"},"trusted":true},"execution_count":667,"outputs":[{"execution_count":667,"output_type":"execute_result","data":{"text/plain":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"combined_snli_df.dropna(subset=['True_Label'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.888845Z","iopub.execute_input":"2024-08-20T13:53:32.889154Z","iopub.status.idle":"2024-08-20T13:53:32.899983Z","shell.execute_reply.started":"2024-08-20T13:53:32.889129Z","shell.execute_reply":"2024-08-20T13:53:32.899072Z"},"trusted":true},"execution_count":668,"outputs":[]},{"cell_type":"code","source":"# Verify missing values again after removal\nmissing_values_snli_after_removal = combined_snli_df.isnull().sum()\nprint(missing_values_snli_after_removal)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.901115Z","iopub.execute_input":"2024-08-20T13:53:32.901389Z","iopub.status.idle":"2024-08-20T13:53:32.911421Z","shell.execute_reply.started":"2024-08-20T13:53:32.901357Z","shell.execute_reply":"2024-08-20T13:53:32.910496Z"},"trusted":true},"execution_count":669,"outputs":[{"name":"stdout","text":"Deberta_Entailment       0\nDeberta_Neutral          0\nDeberta_Contradiction    0\nRoberta_Entailment       0\nRoberta_Neutral          0\nRoberta_Contradiction    0\nAlbert_Entailment        0\nAlbert_Neutral           0\nAlbert_Contradiction     0\nTrue_Label               0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_snli_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.912568Z","iopub.execute_input":"2024-08-20T13:53:32.912926Z","iopub.status.idle":"2024-08-20T13:53:32.925425Z","shell.execute_reply.started":"2024-08-20T13:53:32.912895Z","shell.execute_reply":"2024-08-20T13:53:32.924401Z"},"trusted":true},"execution_count":670,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 9824 entries, 0 to 9999\nData columns (total 10 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Deberta_Entailment     9824 non-null   float64\n 1   Deberta_Neutral        9824 non-null   float64\n 2   Deberta_Contradiction  9824 non-null   float64\n 3   Roberta_Entailment     9824 non-null   float64\n 4   Roberta_Neutral        9824 non-null   float64\n 5   Roberta_Contradiction  9824 non-null   float64\n 6   Albert_Entailment      9824 non-null   float64\n 7   Albert_Neutral         9824 non-null   float64\n 8   Albert_Contradiction   9824 non-null   float64\n 9   True_Label             9824 non-null   Int64  \ndtypes: Int64(1), float64(9)\nmemory usage: 853.8 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Function to split data into training and validation sets\ndef split_data(df):\n    X = df.drop(columns=['True_Label'])  # Features: the model predictions\n    y = df['True_Label']  # Target: the true labels\n    # Splitting the dataset into training (80%) and validation (20%) sets\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, X_val, y_train, y_val\n\n# Splitting MNLI Matched, MNLI Mismatched, and ANLI Rounds 1, 2, 3\nX_train_mnli_matched, X_val_mnli_matched, y_train_mnli_matched, y_val_mnli_matched = split_data(combined_mnli_matched_df)\nX_train_mnli_mismatched, X_val_mnli_mismatched, y_train_mnli_mismatched, y_val_mnli_mismatched = split_data(combined_mnli_mismatched_df)\nX_train_anli_r1, X_val_anli_r1, y_train_anli_r1, y_val_anli_r1 = split_data(combined_anli_r1_df)\nX_train_anli_r2, X_val_anli_r2, y_train_anli_r2, y_val_anli_r2 = split_data(combined_anli_r2_df)\nX_train_anli_r3, X_val_anli_r3, y_train_anli_r3, y_val_anli_r3 = split_data(combined_anli_r3_df)\nX_train_snli, X_val_snli, y_train_snli, y_val_snli = split_data(combined_snli_df)\n\n\n# Print the sizes of the training and validation sets\nprint(f\"MNLI Matched Training set size: {X_train_mnli_matched.shape[0]}, Validation set size: {X_val_mnli_matched.shape[0]}\")\nprint(f\"MNLI Mismatched Training set size: {X_train_mnli_mismatched.shape[0]}, Validation set size: {X_val_mnli_mismatched.shape[0]}\")\nprint(f\"ANLI Round 1 Training set size: {X_train_anli_r1.shape[0]}, Validation set size: {X_val_anli_r1.shape[0]}\")\nprint(f\"ANLI Round 2 Training set size: {X_train_anli_r2.shape[0]}, Validation set size: {X_val_anli_r2.shape[0]}\")\nprint(f\"ANLI Round 3 Training set size: {X_train_anli_r3.shape[0]}, Validation set size: {X_val_anli_r3.shape[0]}\")\nprint(f\"SNLI Training set size: {X_train_snli.shape[0]}, Validation set size: {X_val_snli.shape[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.927622Z","iopub.execute_input":"2024-08-20T13:53:32.927854Z","iopub.status.idle":"2024-08-20T13:53:32.956964Z","shell.execute_reply.started":"2024-08-20T13:53:32.927832Z","shell.execute_reply":"2024-08-20T13:53:32.956074Z"},"trusted":true},"execution_count":671,"outputs":[{"name":"stdout","text":"MNLI Matched Training set size: 7852, Validation set size: 1963\nMNLI Mismatched Training set size: 7865, Validation set size: 1967\nANLI Round 1 Training set size: 800, Validation set size: 200\nANLI Round 2 Training set size: 800, Validation set size: 200\nANLI Round 3 Training set size: 960, Validation set size: 240\nSNLI Training set size: 7859, Validation set size: 1965\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine all the datasets into one DataFrame\ncombined_all_tasks_df = pd.concat([\n    combined_snli_df,\n    combined_mnli_matched_df,\n    combined_mnli_mismatched_df,\n    combined_anli_r1_df,\n    combined_anli_r2_df,\n    combined_anli_r3_df\n], ignore_index=True)\n\n# Split the combined dataset\nX_train_all, X_val_all, y_train_all, y_val_all = split_data(combined_all_tasks_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.958127Z","iopub.execute_input":"2024-08-20T13:53:32.958478Z","iopub.status.idle":"2024-08-20T13:53:32.974130Z","shell.execute_reply.started":"2024-08-20T13:53:32.958444Z","shell.execute_reply":"2024-08-20T13:53:32.973088Z"},"trusted":true},"execution_count":672,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss, accuracy_score, confusion_matrix\nimport numpy as np\n\n\n# Function to tune and train the logistic regression meta-model\ndef tune_and_train_meta_model(X_train, y_train, task_name, model_name):\n    \"\"\"\n    Tuning and training logistic regression meta-model with GridSearchCV.\n\n    Parameters:\n    - X_train: Training features (predictions of base models)\n    - y_train: True labels for the training data\n    - task_name: A string describing the dataset or task (e.g., 'SNLI', 'MNLI Matched')\n    - model_name: A string describing the model being tuned and trained\n\n    Returns:\n    - best_model: The best logistic regression model found by GridSearchCV.\n    \"\"\"\n    print(f\"Starting hyperparameter tuning for {task_name} using {model_name}...\")\n\n    # Define the logistic regression model with a fixed random state for reproducibility\n    meta_model = LogisticRegression(random_state=42)\n\n    # Define the hyperparameters grid to search\n    param_grid = {\n        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n        'solver': ['liblinear', 'lbfgs'],\n        'penalty': ['l2']\n    }\n\n    # Setup GridSearchCV to search for the best hyperparameters\n    grid_search = GridSearchCV(meta_model, param_grid, cv=5, scoring='accuracy', verbose=1)\n\n    # Fit GridSearchCV to the training data\n    grid_search.fit(X_train, y_train)\n\n    # Calculate the best loss\n    best_model = grid_search.best_estimator_\n    best_score = grid_search.best_score_\n    best_loss = log_loss(y_train, best_model.predict_proba(X_train))\n\n    # Print the best parameters, score, and loss\n    print(f\"Best parameters for {task_name} using {model_name}: {grid_search.best_params_}\")\n    print(f\"Best score for {task_name} using {model_name}: {best_score}\")\n    print(f\"Best loss for {task_name} using {model_name}: {best_loss}\\n\")\n\n    return best_model","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:32.975892Z","iopub.execute_input":"2024-08-20T13:53:32.976210Z","iopub.status.idle":"2024-08-20T13:53:33.087234Z","shell.execute_reply.started":"2024-08-20T13:53:32.976183Z","shell.execute_reply":"2024-08-20T13:53:33.086231Z"},"trusted":true},"execution_count":673,"outputs":[]},{"cell_type":"code","source":"best_model_snli = tune_and_train_meta_model(X_train_snli, y_train_snli, \"SNLI\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:33.088467Z","iopub.execute_input":"2024-08-20T13:53:33.089111Z","iopub.status.idle":"2024-08-20T13:53:36.362788Z","shell.execute_reply.started":"2024-08-20T13:53:33.089078Z","shell.execute_reply":"2024-08-20T13:53:36.361807Z"},"trusted":true},"execution_count":674,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for SNLI using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for SNLI using Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for SNLI using Logistic Regression: 0.926961887130448\nBest loss for SNLI using Logistic Regression: 0.22371290691174736\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_mnli_matched = tune_and_train_meta_model(X_train_mnli_matched, y_train_mnli_matched, \"MNLI_matched\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:36.364090Z","iopub.execute_input":"2024-08-20T13:53:36.364450Z","iopub.status.idle":"2024-08-20T13:53:39.190105Z","shell.execute_reply.started":"2024-08-20T13:53:36.364413Z","shell.execute_reply":"2024-08-20T13:53:39.189104Z"},"trusted":true},"execution_count":675,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for MNLI_matched using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for MNLI_matched using Logistic Regression: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for MNLI_matched using Logistic Regression: 0.9183634100556665\nBest loss for MNLI_matched using Logistic Regression: 0.24568533433621007\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_mnli_mismatched = tune_and_train_meta_model(X_train_mnli_mismatched, y_train_mnli_mismatched, \"MNLI_mismatched\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:39.191368Z","iopub.execute_input":"2024-08-20T13:53:39.191639Z","iopub.status.idle":"2024-08-20T13:53:42.075046Z","shell.execute_reply.started":"2024-08-20T13:53:39.191615Z","shell.execute_reply":"2024-08-20T13:53:42.073890Z"},"trusted":true},"execution_count":676,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for MNLI_mismatched using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for MNLI_mismatched using Logistic Regression: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for MNLI_mismatched using Logistic Regression: 0.9168467895740623\nBest loss for MNLI_mismatched using Logistic Regression: 0.28140126212007255\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_anli_r1 = tune_and_train_meta_model(X_train_anli_r1, y_train_anli_r1, \"ANLI round 1\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:42.076435Z","iopub.execute_input":"2024-08-20T13:53:42.076761Z","iopub.status.idle":"2024-08-20T13:53:42.826576Z","shell.execute_reply.started":"2024-08-20T13:53:42.076734Z","shell.execute_reply":"2024-08-20T13:53:42.825495Z"},"trusted":true},"execution_count":677,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for ANLI round 1 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for ANLI round 1 using Logistic Regression: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for ANLI round 1 using Logistic Regression: 0.765\nBest loss for ANLI round 1 using Logistic Regression: 0.5928664549952005\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_anli_r2 = tune_and_train_meta_model(X_train_anli_r2, y_train_anli_r2, \"ANLI round 2\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:42.827763Z","iopub.execute_input":"2024-08-20T13:53:42.828074Z","iopub.status.idle":"2024-08-20T13:53:43.540482Z","shell.execute_reply.started":"2024-08-20T13:53:42.828046Z","shell.execute_reply":"2024-08-20T13:53:43.539453Z"},"trusted":true},"execution_count":678,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for ANLI round 2 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for ANLI round 2 using Logistic Regression: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for ANLI round 2 using Logistic Regression: 0.675\nBest loss for ANLI round 2 using Logistic Regression: 0.752836687143394\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_anli_r3 = tune_and_train_meta_model(X_train_anli_r3, y_train_anli_r3, \"ANLI round 3\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:43.541534Z","iopub.execute_input":"2024-08-20T13:53:43.543091Z","iopub.status.idle":"2024-08-20T13:53:44.301307Z","shell.execute_reply.started":"2024-08-20T13:53:43.543061Z","shell.execute_reply":"2024-08-20T13:53:44.300458Z"},"trusted":true},"execution_count":679,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for ANLI round 3 using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for ANLI round 3 using Logistic Regression: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\nBest score for ANLI round 3 using Logistic Regression: 0.6697916666666667\nBest loss for ANLI round 3 using Logistic Regression: 0.7517502313492069\n\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_all = tune_and_train_meta_model(X_train_all, y_train_all, \"Combined all tasks\", \"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:53:44.302486Z","iopub.execute_input":"2024-08-20T13:53:44.302766Z","iopub.status.idle":"2024-08-20T13:53:52.325257Z","shell.execute_reply.started":"2024-08-20T13:53:44.302741Z","shell.execute_reply":"2024-08-20T13:53:52.324146Z"},"trusted":true},"execution_count":680,"outputs":[{"name":"stdout","text":"Starting hyperparameter tuning for Combined all tasks using Logistic Regression...\nFitting 5 folds for each of 12 candidates, totalling 60 fits\nBest parameters for Combined all tasks using Logistic Regression: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\nBest score for Combined all tasks using Logistic Regression: 0.8972299529442866\nBest loss for Combined all tasks using Logistic Regression: 0.3084754511116011\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score, f1_score\n\n\n\n# Function to evaluate the model on the validation set, and return predictions, recall, and F1-score\ndef evaluate_model(X_train, y_train, X_val, y_val, task_name):\n    \"\"\"\n    Evaluate the model on the validation set, print recall and F1-score, and return the trained model and predictions.\n\n    Parameters:\n    - X_train: Training features (predictions of base models).\n    - y_train: True labels for the training data.\n    - X_val: Validation features (predictions of base models).\n    - y_val: True labels for the validation data.\n    - task_name: Name of the task/dataset.\n\n    Returns:\n    - y_pred: Predictions on the validation set (for confusion matrix).\n    - model: Trained logistic regression model.\n    - recall: Recall score on the validation set.\n    - f1: F1-score on the validation set.\n    \"\"\"\n    # Create and train a logistic regression model\n    model = LogisticRegression(random_state=42)\n    model.fit(X_train, y_train)\n\n    # Generate predictions on the validation set\n    y_pred = model.predict(X_val)\n\n    # Calculate recall and F1-score\n    recall = recall_score(y_val, y_pred, average='weighted')\n    f1 = f1_score(y_val, y_pred, average='weighted')\n\n    print(f\"Recall on {task_name}: {recall * 100:.2f}%\")\n    print(f\"F1-score on {task_name}: {f1 * 100:.2f}%\\n\")\n\n    return y_pred, model, recall, f1  # Return predictions for confusion matrix, trained model, recall, and F1-score\n\n# Evaluate and print recall and F1-score for each task\n\n# SNLI Task\ny_pred_snli, trained_model_snli, recall_snli, f1_snli = evaluate_model(X_train_snli, y_train_snli, X_val_snli, y_val_snli, \"SNLI\")\nconfusion_mtx_snli = confusion_matrix(y_val_snli, y_pred_snli)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:09.463764Z","iopub.execute_input":"2024-08-20T13:54:09.464442Z","iopub.status.idle":"2024-08-20T13:54:09.580856Z","shell.execute_reply.started":"2024-08-20T13:54:09.464404Z","shell.execute_reply":"2024-08-20T13:54:09.579870Z"},"trusted":true},"execution_count":682,"outputs":[{"name":"stdout","text":"Recall on SNLI: 93.13%\nF1-score on SNLI: 93.16%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# MNLI Matched Task\ny_pred_mnli_matched, trained_model_mnli_matched, recall_mnli_matched, f1_mnli_matched = evaluate_model(\n    X_train_mnli_matched, y_train_mnli_matched, X_val_mnli_matched, y_val_mnli_matched, \"MNLI Matched\"\n)\nconfusion_mtx_mnli_matched = confusion_matrix(y_val_mnli_matched, y_pred_mnli_matched)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:14.744846Z","iopub.execute_input":"2024-08-20T13:54:14.745783Z","iopub.status.idle":"2024-08-20T13:54:14.852455Z","shell.execute_reply.started":"2024-08-20T13:54:14.745745Z","shell.execute_reply":"2024-08-20T13:54:14.851369Z"},"trusted":true},"execution_count":683,"outputs":[{"name":"stdout","text":"Recall on MNLI Matched: 92.00%\nF1-score on MNLI Matched: 92.02%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# MNLI Mismatched Task\ny_pred_mnli_mismatched, trained_model_mnli_mismatched, recall_mnli_mismatched, f1_mnli_mismatched = evaluate_model(\n    X_train_mnli_mismatched, y_train_mnli_mismatched, X_val_mnli_mismatched, y_val_mnli_mismatched, \"MNLI Mismatched\"\n)\nconfusion_mtx_mnli_mismatched = confusion_matrix(y_val_mnli_mismatched, y_pred_mnli_mismatched)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:23.796917Z","iopub.execute_input":"2024-08-20T13:54:23.797295Z","iopub.status.idle":"2024-08-20T13:54:23.901812Z","shell.execute_reply.started":"2024-08-20T13:54:23.797266Z","shell.execute_reply":"2024-08-20T13:54:23.900860Z"},"trusted":true},"execution_count":684,"outputs":[{"name":"stdout","text":"Recall on MNLI Mismatched: 91.61%\nF1-score on MNLI Mismatched: 91.66%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# ANLI Round 1 Task\ny_pred_anli_r1, trained_model_anli_r1, recall_anli_r1, f1_anli_r1 = evaluate_model(\n    X_train_anli_r1, y_train_anli_r1, X_val_anli_r1, y_val_anli_r1, \"ANLI Round 1\"\n)\nconfusion_mtx_anli_r1 = confusion_matrix(y_val_anli_r1, y_pred_anli_r1)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:33.683112Z","iopub.execute_input":"2024-08-20T13:54:33.683855Z","iopub.status.idle":"2024-08-20T13:54:33.716293Z","shell.execute_reply.started":"2024-08-20T13:54:33.683823Z","shell.execute_reply":"2024-08-20T13:54:33.715266Z"},"trusted":true},"execution_count":685,"outputs":[{"name":"stdout","text":"Recall on ANLI Round 1: 70.50%\nF1-score on ANLI Round 1: 70.63%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# ANLI Round 2 Task\ny_pred_anli_r2, trained_model_anli_r2, recall_anli_r2, f1_anli_r2 = evaluate_model(\n    X_train_anli_r2, y_train_anli_r2, X_val_anli_r2, y_val_anli_r2, \"ANLI Round 2\"\n)\nconfusion_mtx_anli_r2 = confusion_matrix(y_val_anli_r2, y_pred_anli_r2)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:41.683561Z","iopub.execute_input":"2024-08-20T13:54:41.684250Z","iopub.status.idle":"2024-08-20T13:54:41.716192Z","shell.execute_reply.started":"2024-08-20T13:54:41.684215Z","shell.execute_reply":"2024-08-20T13:54:41.715241Z"},"trusted":true},"execution_count":686,"outputs":[{"name":"stdout","text":"Recall on ANLI Round 2: 73.50%\nF1-score on ANLI Round 2: 73.55%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# ANLI Round 3 Task\ny_pred_anli_r3, trained_model_anli_r3, recall_anli_r3, f1_anli_r3 = evaluate_model(\n    X_train_anli_r3, y_train_anli_r3, X_val_anli_r3, y_val_anli_r3, \"ANLI Round 3\"\n)\nconfusion_mtx_anli_r3 = confusion_matrix(y_val_anli_r3, y_pred_anli_r3)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:48.569815Z","iopub.execute_input":"2024-08-20T13:54:48.570302Z","iopub.status.idle":"2024-08-20T13:54:48.612097Z","shell.execute_reply.started":"2024-08-20T13:54:48.570261Z","shell.execute_reply":"2024-08-20T13:54:48.611171Z"},"trusted":true},"execution_count":687,"outputs":[{"name":"stdout","text":"Recall on ANLI Round 3: 69.58%\nF1-score on ANLI Round 3: 69.51%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# All Tasks Combined\ny_pred_all, trained_model_all, recall_all, f1_all = evaluate_model(\n    X_train_all, y_train_all, X_val_all, y_val_all, \"All Tasks Combined\"\n)\nconfusion_mtx_all = confusion_matrix(y_val_all, y_pred_all)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T13:54:57.801110Z","iopub.execute_input":"2024-08-20T13:54:57.801711Z","iopub.status.idle":"2024-08-20T13:54:57.952844Z","shell.execute_reply.started":"2024-08-20T13:54:57.801673Z","shell.execute_reply":"2024-08-20T13:54:57.951864Z"},"trusted":true},"execution_count":688,"outputs":[{"name":"stdout","text":"Recall on All Tasks Combined: 89.32%\nF1-score on All Tasks Combined: 89.35%\n\n","output_type":"stream"}]}]}