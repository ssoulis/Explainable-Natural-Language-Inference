# Explainable-Natural-Language-Inference

This repository contains the code and datasets used for the paper "Natural Language Inference with Transformer Ensembles and Explainability Techniques" by Isidoros Perikos and Spyro Souli.

## Getting Started

* [Introduction](#introduction)
* [Features](#features)
* [Project Structure](#project-structure)
* [Datasets](#datasets)
* [Installation](#installation)
* [Results](#results)
* [Explainability Methods](#explainability-methods)
* [To Do - Future Work](#To-Do---Future-Work)

## Introduction

Natural Language Inference (NLI) is a challenging task in Natural Language Processing (NLP) that involves determining whether a given hypothesis can be inferred from a given premise. This repository provides the implementation of transformer-based models, such as  ALBERT, RoBERTa and DeBERTa, for NLI tasks across several datasets including SNLI, GLUE, and ANLI.
We also incorporate explainability techniques such as LIME and SHAP to interpret the decision-making processes of the models. Ensemble methods like stacking are utilized to improve accuracy and robustness.


## Features

*  Implementation of multiple transformer models: ALBERT, RoBERTa and DeBERTa
*  Stacking ensemble methods for improved inference accuracy.
*  Explainability with LIME and SHAP to interpret how models make decisions.
*  Support for MNLI, ANLI, and SNLI datasets for NLI tasks.
*  Detailed result analysis and performance comparisons.

  



